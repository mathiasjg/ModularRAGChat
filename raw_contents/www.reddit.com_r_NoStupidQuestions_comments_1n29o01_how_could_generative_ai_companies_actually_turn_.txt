Correct me if I'm wrong, but I understand it's a kind of venture capital. Where you invest a lot of investor money into the product, so the customers get a cheap and good experience, until you're able to adjust your stream (What is commonly enshittification) so that you can become a profitable model. Supermarkets famously did this by tanking huge losses to establish a monopoly on sales, then they put the prices up once the small shops are gone. So you take the losses which are covered by wealthy investors until the business/industry becomes profitable. Am I right enough so far?


Anyway. I hear that generative AI and LLMs don't just not make any money, they cost enormous amounts of money to the companies like OpenAI. Some kid doing their homework or some gooner making pics of Emma Watson in a Slytherin nightie aren't bringing in an income. So how do these companies expect they'll be able to turn their models into ones that are, or happen upon circumstances, that are profitable? This cannot be sustainable?You nailed it with “enshittification.” The strategy is:

1. Burn investor money to make AI cheap and magical.
2. Get everyone hooked on it.
3. Slowly crank up the price, gate features, shove ads, and sell data once there’s no alternative.

That’s the playbook. It’s gross, but it works.

On the flip side, if you want to actually benefit from AI instead of just being the product, I recommend checking out [Mercor](https://work.mercor.com/?referralCode=ac12ca4d-618a-4e1a-ae6d-ea39fe3a3dba). It's a way to get in on the startup grind early. AI is like the “dot com” companies of the 90s. There is probably a bubble that will end with most companies at zero dollars, but in the aftermath there is a good chance there will be some existing and a lot of new companies worth a lot. Like the 90s, we’re still figuring out what will stick. How do gen-AI companies profit?   
Same as any gold rush: sell shovels (compute/API), sell maps (niche, fine-tuned SaaS for docs/support/ads), or own the mine (enterprise seats + SLAs + compliance).  
 Bonus move: call it “Pro,” bill in “tokens,” and everyone nods like they understand the invoice. Brand recognition. 

Being the "first company that did it really well" is the fastest way to make a trillion dollar company - just look at Apple. 

It almost always fails, but if there's a 1% chance your billion dollar investment will turn into a trillion in 20 years, that's a 12% ROI year over year - *if* you make that investment enough times.

Their actual models and the hardware they were trained on will be obsolete, and better replacements vastly cheaper.

Edit to clarify: to be clear, Apple took a lot longer than twenty years to go from a billion to a trillion. Ads.

You probably have already noticed yourself and your friends using ChatGPT et al for a lot of things that you previously would use Google for.

OpenAI and friends will open ad marketplaces. And when you ask ChatGPT "Hey what's the best bike for a 6 year old to learn on?" you will get the AI answer and a bunch of Ads for bikes, etc.

API access will likely continuing to get expensive. And there's also the possibility that someone finally realizes we're seeing extremely marginal returns from bigger and bigger training models and they will start focusing more on productizing their existing models (\*cough\* GPT-5) instead of burning trillions on training. There are to this, and one is the one you'll hear most often. Basically, a LOT of investment in AI is speculation based on buzzwords and bubbles. 90% of companies WILL fail. 

The answer you wont hear is much is that the profit is not meant to be realized right away. There is practical application of LLMs that far exceed text generation, and the exact implementation of those applications is what MOST AI companies are selling. Most of these companies will go under. 

Now, the companies developing the models themselves are in a bit of a space race. What theyre racing too is a subject of debate, but owning the BRAIN that these applications are built on top of is going to be an ENORMOUS amount of power in the future. People.rightly compare this to the dotcom bubble, but they only bring up half the picture. Microsoft, Apple, and Google were forged by the bubble, and for them, Id hardly say they didnt make back their investments. 

So is it a bubble and are investors about to be fucked? Abosultely. Is their no path to profitability for companies like OpenAi? In my opinion, the avenues for success and profit for SOTA Model developers is unimaginable to us now, it would be like trying to understand googles business model today 25 years ago. The only folk making money off AI are:

* Nvidia
* Server hardware companies How can they turn a profit? By spending less on capital expenditure and keeping more money. 

You are mistaken. AI services are already taking it vast sums of money. Many billions per year. Companies with AI features are paying cloud services to leverage them. And regular people pay money monthly for access to better versions. 

I spend money both personally and at a company level. 

They’re not losing all their money giving free tiers of model with limited query access away. The money is being spent building physical stuff and training new tech. 

A parallel to this would be Amazon. People think of Amazon as constantly not making a profit for years, but they forget or don’t know that they were just re-investing hundreds of billions of dollars of revenue into expanding Amazon Web Services around the world.

AWS now has an operating income of $40B/year. God I hope their whole industry collapses and we enter an AI recession. 

Or, acceptable alternative, AI tech companies invest in clean nuclear energy because it's essential to power their servers, and humanity accidentally moves on from coal and gasoline. A huge part is a bubble Plenty of AI companies are already profitable if you exclude R&amp;D. It would be a bad thing for OpenAI to be profitable right now because that would mean they're not spending enough on research. If AI research turns out to be a dead end and we only ever get models that are moderately better than the ones we have now (this is the worst-case scenario) then AI companies would still be able to turn a profit by not spending anything on research and focusing just on serving their customers with inference.

Of course, another way they'll turn a profit is by enshittification - such is the nature of corporations. It's going to burst because there are free models and software that are as good if not better than these platforms, and they can run on hardware from 4 years ago. Since then Nvidia has nerfed available VRAM for consumers to prop up the paid platform market. But open source coders and other companies in other countries without as much bubble pressure are giving away code. Google was also built on open source software but the difference is you couldn't run google on your old PC and get almost as much value. Targeted niche services with an well engineered solution I think it's still way too early to know just how pervasive AI will become in our society.

Just the other day, I was talking with a friend of mine who is a **school psychologist**.  She said she was in fear for her job because of AI.

"AI?" I said, "How the heck is AI going to take your job?  Who wants their kid to be counseled by an AI?"

But she corrected me.

Only about 40% of what she does is actual, face-to-face counseling.  The other 60% is spent writing case summaries, writing treatment plans, writing down notes from sessions, doing insurance and legal paperwork.

AI can do those things pretty well.  You ask AI to "listen in" on a counseling session, and it can generate summaries.  You ask AI to write out or fill out an often-repeated form or letter, and it can do that too.  Other kinds of doctors are using AI to do diagnosis, so this is likely to be done here too.

So if there are 3 psychologists employed by the district, and 60% of their work can be replaced by an AI, that means they can hire fewer psychologists.  

And that is exactly what they are doing.  My friend's superiors are making her incorporate AI in those gruntwork tasks.

**MY POINT IS** ... who knew that AI could "replace" psychologists?  I certainly didn't.  You'd think that psychology would be safe from AI, and while the actual counseling is likely safe, if you reduce the mundane gruntwork, you need fewer psychologists.

It's those kinds of things that we're learning about daily now.  Once we learn more ways to use AI in everyday life and common tasks, who knows where it will go?

For that reason alone, I don't see this bubble bursting.  And getting in early is going to be crucial for these AI companies. Ed Zitron has a bunch of good articles (both paid and free) over on his site about the AI bubble and the AI landscape https://www.wheresyoured.at/ AI companies do not have any intention of making money off of end users like you or I paying a subscription fee to mess around with their chat model for fun. The only reason they offer that is because it makes AI normal, common, and establishes market share.

They want to make money from big companies. My company has a lot of big plans for AI (eugh), and I am in some of these meetings. We are talking about yearly contracts in the tens of millions of dollars for services like AI doing automated checks on transcripts from customer service phone calls to look for bad customer service or trends. 

The only reason each company wants their name to be associate with AI for you personally is so they can convince the big companies that they're the biggest and beat AI producers. It's actually really simple. AI is a tool, like a hammer. People or companies that find that tool useful with pay money for it. That's how they will turn a profit in the future.

Stuff like image generation, yes that's not making any money right now, but already had it's used, for example in research doing stuff like predicting protein folds or predicting the actions of drugs, and will only develop more applications as time goes on.

But Reddit is very anti-AI, and most don't know what is does beyond chat bots, and image generation so this post will no doubt become a circlejerk of how AI does nothing useful and will go nowhere It’s not true that the companies can’t make a profit. The vast majority of the cost goes into R&amp;D. If you were to freeze LLMs the way they are and just serve them at the price points these companies have, they would make a profit. It's going to be profitable. And their main clients will be companies, not individuals. **$$$ Product response Ads:** Let's say you ask ChatGPT what do the Stocks look like this year? OpenAI could charge a local  Financial Planner to respond with his name and sales pitch about his investment plan for you. If you ask about how to repair your car -- ChatGPT could respond with a local garage ad. All this is similar to Google today. A subscription service might work for specialized industries. ai will have to be good, cheap, and reliable enough that a company is willing to pay for ai services to replace the jobs normally done by expensive workers. if that doesn't happen, ai companies will never actually make money. ChadGPT already charges money right? There is a future where AI gen is very cheap. Unfortunately there is very little research done into creating fundamentally stronger actual AI, instead pushing for larger datasets with current LLM models which are basically glorified algorithms.

Eventually someone will invent that next level and the cost of running an LLM will plummet. What I suspect is happening is that people are assuming that AI will be a tight oligopoly, so there won't be many of these companies because the bat to stay up will be very high. 

So people are betting on these companies figuring that whichever is left at the end will be printing money. I don’t know about that. I can host a pretty good model in a couple hundred bucks a month bare metal server. The improvements are coming from proper indexing / scraping, tools around inference etc.. so all that taking into account you don’t need premium inference (100b+ models) for thousands a month for consumer grade applications. Running 20-70B models more than fine and margins are really good. Any upgrade over what we currently have will sell like hot cakes.

Some people would pay a fortune for an AI that does not suck at drawing hands. Or even one that just knows how to hide them.

But enshittification will still happen because the idiots in suits don't realise that. AI is in the competition phase right now. OpenAI, Anthropic and others are competing for who can grab the most market share and who can create the best model. This is similar to the days when 4-5 major browsers were out there, or when multiple social media sites competed for glory.

Right now they are burning investor cash to develop models and grab market share. Eventually we will enter the consolidation phase: companies will fold, patents/people will be acquired and one or two major players will remain. 

Generative AI companies make money a variety of ways - but a big money maker will be charging API fees for integrations. This is how other APIs like Plaid work: companies that want to integrate a chatbot or AI summarize will pay a fee per use to the GenAI companies. We're going to ask GPT9 how to make money I work as an AI engineer in Silicon Valley with lots of friends in different aspects of this space.

* likely the most profitable companies will be ones that do very novel and not necessarily consumer-facing products 
* it’s very likely this will be a dot com level boom-bust, meaning many companies will fail but the ones that succeed will be the next Google, Amazon, Cisco. VCs are expecting it and investing accordingly 
* Many companies are already making profit with AI. But they are not close to IPO, aren’t looking for more VC funding, and don’t need a media blitz so most people don’t hear about them 
* Many employees are having massive improvements in productivity with AI. With the right tools, I can produce weeks worth of development within a couple of days. I know many people personally who report the same. The issue is that it’s not even as others are struggling to change development practices so aren’t seeing these gains 
* Employers are adapting rapidly, concentrating resources on fewer more senior employees and less junior level employees. This is why many new grads are struggling to find jobs, but I see recruiting for jobs $400k+ for senior level engineers who can pass
* models keep getting cheaper, more accurate, and better very quickly. Pricing keeps dropping by 20-100%, I read that AI developer capability doubles every 4 months, and hallucinations keep falling. So in even a short amount of time, many of the issues with AI will be mitigated (I see this in my work all the time)
* I have heard of some companies that are in track to make $1B APR with less than 100 employees, and with all of this together I believe them. Even with data center costs, it’s way cheaper than skilled employees, so AI will be profitable 


Overall, I personally believe (but could be wrong) that this will result in fewer winners (companies and employees) but the winners will be making much much more money. That’s why VCs are investing absurd levels of money; they really want to be on the winning side and are afraid to lose out. I’m seeing similar behavior with my colleagues: some friends getting great offers or moving to companies they are really confident in, but also many who are struggling to find a job

But do not count out AI. It will definitely be a winning tech, unlike the IoT or crypto or Web3.0 hype [OpenAI raises $8.3 billion as paid ChatGPT business users reach 5 million](https://www.cnbc.com/2025/08/01/openai-raise-chatgpt-users.html?__source=iosappshare%7Ccom.apple.UIKit.activity.CopyToPasteboard)

“Annual recurring revenue jumped to $13 billion, up from $10 billion in June, said the person, who spoke on condition of anonymity to discuss confidential financial information, and is projected to top $20 billion by year-end.”

That’s impressively legit revenue given how early we are in the hype cycle but we don’t know the costs. It all hinges on how much higher and for how long. If it’s unsustainable for too long then the independents will not make it when VC money dries up. The mega cap techs will swoop in for the deeply discounted distressed assets and dominate from there. 

As for new revenue specifically for gen AI, it’s far early to know for sure how it’ll evolve between enterprise and consumer. My bet is on enterprise if they can figure out how to make agentic programs worth the investment. Not sure how much value it can create for a consumer market. Personally I'd rather talk to chatGPT than reddit. At least there, I know I'm talking to bots. Here, I'm usually on the fence, and if it's not a bot, its a commie. And chatGPT doesn't hate me, and can give good feedback on my music. And I say this as one of the main haters of AI, AI's not going anywhere.

BUT, upgrading to 5 was a huge step back from what it used to be. Of course, that means now you are FORCED to pay for the better previous model. So that's how at least that company's making money. Only reason I don't is I'm broke, and can handle the loneliness rather than pay for the AI-fren. If I had more expendable money, I'd pay. &gt;How could generative AI companies actually turn a profit

"put in the coin to ask a question / make an image"

They do this right now. [They charge per token](https://openai.com/api/pricing/).  Those prices will almost certainly go up once competition goes down and someone eventually wins the rat race.   

This is FAR more direct than google or facebook's scheme of attracting eyeballs to sell ads to. 

&gt; venture capital. Where you invest a lot of investor money into the product, so the customers get a cheap and good experience, until you're able to adjust your stream (What is commonly enshittification)

That's not exactly how enshittification happens. Even Doctrow missed an essential aspect:  Once they win the market and lock in their users, they don't give a fuck how good the service is.   Suuuuure, they claw-back profit and charge customers and what was a free or cheap service is now costly.   But the reason things turn to shit like this is that all the effort they were putting into attracting users (which was the not-shit times) is dropped or redirected towards attracting advertisers.  

What are you going to do, google something on some other search engine? Even bing just used google on the backend. Not buy through amazon?  Switch to a social network that no one is on?   (And the answer is YES, YOU SHOULD BLOODY WELL DO THAT! But you won't.)

The enshiffification happens simply because the owners stop maintaining the place once they know you're not going to leave. 

LLMs won't get shitty as long as there's competition.  If Grok does a better job than GPT, then openAI is fucked. Apples product will eventually cost one gorillion dollars a question, but it'll have rounded corners in the chatbox so the users will swear it's worth it. 


&gt;I hear that generative AI and LLMs don't just not make any money, they cost enormous amounts of money to the companies like OpenAI.

Yeah, currently. That's the "So you take the losses which are covered by wealthy investors" part you just said.   And they pivot to profit once they win the rat-race and dominate the market and/or other competitors run out of investor money. 

Once they're the only serious game in town, they charge whatever they want.   That's been the general plan behind all tech companies for at least 40 years. These models are being built into companies software. Each use of it costs a “token”

They are embedding it natively into devices.  Like the recent Apple announcement.  

They aren’t making a profit from just Schmoes making action figure pics.it they corporate and embedded uses that let them grow.

If I sold my software to a firm and told them diagnosing the likely fault in your car engine will take 90% less time and increase probability of being correct to 99.8%, how would they not say yes to that? ROI is clear. So I think the narrative around AI falls into two camps and both of them could potentially be true at the same time. 

1: AI is a revolutionary technology that will affect almost every industry and ultimately, replace alot of jobs. 

2: AI is such a buzzword that a bunch of worthless companies are being propped up by venture capital and they will never delivery on what they promised and since they are AI engines, they cost a ton to maintain and the bubble will pop when investors start running away from them. 

Keep in mind we had a dot.com bubble in the 90’s. Similar circumstances. The internet was this exciting new technology that was going to change the world. Everyone with any money wanted to find websites to invest in. A ton of capital flooded into web-based businesses that were doomed to fail and the bottom fell out and caused a recession. 

Obviously, the internet wasn’t a fad. The hype just grew faster than the tech and a lot of investors hitched their wagon to dead horses.  The same thing is probably happening with AI. It’s a new tech that has the promise of reducing a company payroll massively by using AI engines to do some of the work. A lot of studies are starting to emerge that are showing most of them are completely worthless. They end up working so poorly that you need as much staff to babysit them as you used to have doing the same job. Additionally, these AI startups are able to offer companies low prices because they are operating at a loss floated by ventures capital. 

So there’s an increasingly likely chance that a bubble is going to burst. But my hunch is that we have still laid the groundwork for probabilistic computer models being able to do alot of jobs humans usually do and the real AI wave, where it actually works properly and isn’t so energy and cost-intensive, is coming. It was just rushed to market way before it was actually ready Enterprise subscriptions. Companies will happily pay 5k a month if it means one guy can do the job of three or four guys. They wait for industries to fire everyone, or at least eliminate entry level positions so that there’s no longer a flow of talented people gaining experience.  Then - viola! - they flip a switch and the price to subscribe soars.  Company’s will be happy to pay 30% of a real person’s salary for an equivalent amount of LLM usage if the LLM gets results that are 80-90% as good as the real person. If they manage to get AGI then they make obsene amounts of money, as in going bad to feudal lords with fiefs kind of money.

  
If they don't, they have to find a way to make money and that will be with enshittification. It's probably going to be like standard search, most of the income will be from ads.

Ad-free subscriptions, mostly for business. i think it will become profititable, the end goal for AI is for it to control robotic bodies so the company can sell it as a worker to other companys for millions each. the current goal is to get it to replace lots of non labor jobs. Open ai can sell their AI to apple for billions once it can do a better job than the avg person thats where the profit is. They generate more effective ads. This is a big one for Facebook and Google already you've pretty much described 95% of everything under the umbrella of capitalism. Unsustainable One trillion market cap on $20 billion in revenue. Sell it to enterprises. eg My employer that’s decided to buy subscirptions to various AI tools for hundreds of dollars per user per month. We have around 5,000 users. Almost nobody but the CEO and top level management believe this was a good idea. The military industry is one idea If they do it well enough that 90% of advertisement is AI created, they can make a profit. Companies still spend a fortune on advertising. It is profitable. The reason why the major AI companies are burning money is because they are continually training bigger and better models with more and more compute, so on paper these companies are losing money, but it's an investment into their future. If they stopped making new models they'd be profitable but only until their competitors surpass them with even better models. It's going to be a bubble that bursts There are many ocupations that could be replaced right now or are already slowly been replaced. Translation services, phone costumer assistance,  doorman, marketing, graphic designer,  special effects, copy writers, jorunalist, song writers, admin assistant, travel agent, etc. You can either pay a human several tens of thousands of dollars or you can pay an ai agent to do the work for you. Sure some of those technologies are not 100 percent, but they are.. 70%? In a year or two it could be 98 percent. Humans are not 100 percent anyways. Here is an example, my company release its own AI, it's not their ai is licensed from another company, but train using our data. Is it good? Is ok. Is it perfect? No. It's getting better. Yes. In no time it will replace the Indian dudes.  I'll be honest I didn't read your whole post, but to answer your title question...

I was trying to find a silversmith in a new city. ChatGPT told me where to go. Ranked them and everything. I mentioned this to the silversmith. He was delighted for the free advertising but a bit uneasy that AI was talking about him.

AI is a bubble for sure. It is also the new way people are going to interact with the web. Google search will be Google AI Search, and it will recommend the businesses that pay.

It's only unprofitable right now cos we're in the market capture stage, not the "milk the customers" stage.

Most AI companies will fail, but the ones that don't will be the next generation of tech behemoths. They’re hoping well all subscribe before the servers explode