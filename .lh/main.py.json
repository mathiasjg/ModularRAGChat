{
    "sourceFile": "main.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 55,
            "patches": [
                {
                    "date": 1756857001278,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1756857543854,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,8 +3,9 @@\n from chat_utils import chat_bot\r\n from crawl_utils import start_crawl\r\n from view_utils import view_db, view_vectorstore, refresh_tasks\r\n from config import MODEL_NAME\r\n+import os\r\n \r\n conn = init_db()\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n"
                },
                {
                    "date": 1756858552938,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,9 +3,9 @@\n from chat_utils import chat_bot\r\n from crawl_utils import start_crawl\r\n from view_utils import view_db, view_vectorstore, refresh_tasks\r\n from config import MODEL_NAME\r\n-import os\r\n+import os \r\n \r\n conn = init_db()\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n"
                },
                {
                    "date": 1756858909331,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,27 +1,33 @@\n+import os\r\n import gradio as gr\r\n from db_utils import init_db\r\n from chat_utils import chat_bot\r\n from crawl_utils import start_crawl\r\n from view_utils import view_db, view_vectorstore, refresh_tasks\r\n from config import MODEL_NAME\r\n-import os \r\n \r\n conn = init_db()\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     tasks_state = gr.State([])\r\n+    completed_crawls_state = gr.State([])\r\n     \r\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n+            gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n+            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n-            submit_btn.click(lambda m, h: chat_bot(m, h, conn=conn), [msg, chatbot], [msg, chatbot])\r\n+            def update_dropdown(completed_crawls):\r\n+                return gr.update(choices=[c['name'] for c in completed_crawls])\r\n+            completed_crawls_state.change(update_dropdown, completed_crawls_state, source_dropdown)\r\n+            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s else None), [msg, chatbot, source_dropdown], [msg, chatbot])\r\n             clear.click(lambda: (\"\", None), None, [msg, chatbot], queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n             subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n@@ -30,9 +36,9 @@\n             crawl_btn = gr.Button(\"Crawl\")\r\n             status = gr.Textbox(label=\"Status\")\r\n             refresh_btn = gr.Button(\"Refresh Tasks\")\r\n             tasks_df = gr.Dataframe(label=\"Tasks\")\r\n-            crawl_btn.click(lambda s, t, q, ts: start_crawl(s, t, q, ts, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state], [status, tasks_state])\r\n+            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n             refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n"
                },
                {
                    "date": 1756859312478,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,13 +2,16 @@\n import gradio as gr\r\n from db_utils import init_db\r\n from chat_utils import chat_bot\r\n from crawl_utils import start_crawl\r\n-from view_utils import view_db, view_vectorstore, refresh_tasks\r\n+from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n from config import MODEL_NAME\r\n \r\n conn = init_db()\r\n \r\n+def update_dropdown(completed_crawls):\r\n+    return gr.Dropdown(update=choices=[c['name'] for c in completed_crawls])\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     tasks_state = gr.State([])\r\n@@ -17,18 +20,18 @@\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n             source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n+            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n-            def update_dropdown(completed_crawls):\r\n-                return gr.update(choices=[c['name'] for c in completed_crawls])\r\n-            completed_crawls_state.change(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s else None), [msg, chatbot, source_dropdown], [msg, chatbot])\r\n-            clear.click(lambda: (\"\", None), None, [msg, chatbot], queue=False)\r\n+            refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n+            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s else None), [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            clear.click(lambda: None, None, chatbot, queue=False)\r\n+            clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n             subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n             timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n@@ -36,10 +39,17 @@\n             crawl_btn = gr.Button(\"Crawl\")\r\n             status = gr.Textbox(label=\"Status\")\r\n             refresh_btn = gr.Button(\"Refresh Tasks\")\r\n             tasks_df = gr.Dataframe(label=\"Tasks\")\r\n+            with gr.Accordion(\"Task Detail\", open=False):\r\n+                task_id_input = gr.Number(label=\"Task ID\")\r\n+                view_detail_btn = gr.Button(\"View Detail\")\r\n+                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n+                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n+                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n             crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n             refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n+            view_detail_btn.click(show_task_detail, [task_id_input, tasks_state, gr.State(conn)], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n"
                },
                {
                    "date": 1756859404358,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,9 +8,9 @@\n \r\n conn = init_db()\r\n \r\n def update_dropdown(completed_crawls):\r\n-    return gr.Dropdown(update=choices=[c['name'] for c in completed_crawls])\r\n+    return gr.update(choices=[c['name'] for c in completed_crawls])\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n"
                },
                {
                    "date": 1756859489970,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,9 +47,9 @@\n                 detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n                 detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n             crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n             refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n-            view_detail_btn.click(show_task_detail, [task_id_input, tasks_state, gr.State(conn)], [detail_content, detail_summary, detail_answer])\r\n+            view_detail_btn.click(show_task_detail, [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n"
                },
                {
                    "date": 1756859566172,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,9 +47,9 @@\n                 detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n                 detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n             crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n             refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n-            view_detail_btn.click(show_task_detail, [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n+            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n"
                },
                {
                    "date": 1756859944416,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,8 +10,12 @@\n \r\n def update_dropdown(completed_crawls):\r\n     return gr.update(choices=[c['name'] for c in completed_crawls])\r\n \r\n+def submit_chat(m, h, s):\r\n+    for chat_out, msg_out in chat_bot(m, h, conn=conn, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s else None):\r\n+        yield chat_out, msg_out\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     tasks_state = gr.State([])\r\n@@ -27,9 +31,9 @@\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s else None), [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n"
                },
                {
                    "date": 1756860194424,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,14 +8,10 @@\n \r\n conn = init_db()\r\n \r\n def update_dropdown(completed_crawls):\r\n-    return gr.update(choices=[c['name'] for c in completed_crawls])\r\n+    return gr.update(choices=[\"Web Search\"] + [c['name'] for c in completed_crawls])\r\n \r\n-def submit_chat(m, h, s):\r\n-    for chat_out, msg_out in chat_bot(m, h, conn=conn, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s else None):\r\n-        yield chat_out, msg_out\r\n-\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     tasks_state = gr.State([])\r\n@@ -23,17 +19,17 @@\n     \r\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n+            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[\"Web Search\"], value=None, interactive=True)\r\n             refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s != \"Web Search\" else None), [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n"
                },
                {
                    "date": 1756860368830,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,8 +10,13 @@\n \r\n def update_dropdown(completed_crawls):\r\n     return gr.update(choices=[\"Web Search\"] + [c['name'] for c in completed_crawls])\r\n \r\n+def submit_chat(m, h, s):\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s != \"Web Search\" else None)\r\n+    for chat_out, msg_out in gen:\r\n+        yield chat_out, msg_out\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     tasks_state = gr.State([])\r\n@@ -19,17 +24,17 @@\n     \r\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[\"Web Search\"], value=None, interactive=True)\r\n+            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n             refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s != \"Web Search\" else None), [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n"
                },
                {
                    "date": 1756861513548,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,15 +8,10 @@\n \r\n conn = init_db()\r\n \r\n def update_dropdown(completed_crawls):\r\n-    return gr.update(choices=[\"Web Search\"] + [c['name'] for c in completed_crawls])\r\n+    return gr.update(choices=[\"No RAG\", \"Web Search\"] + [c['name'] for c in completed_crawls])\r\n \r\n-def submit_chat(m, h, s):\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s != \"Web Search\" else None)\r\n-    for chat_out, msg_out in gen:\r\n-        yield chat_out, msg_out\r\n-\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     tasks_state = gr.State([])\r\n@@ -32,9 +27,9 @@\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\"] else None), [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n"
                },
                {
                    "date": 1756861893495,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,10 +8,15 @@\n \r\n conn = init_db()\r\n \r\n def update_dropdown(completed_crawls):\r\n-    return gr.update(choices=[\"No RAG\", \"Web Search\"] + [c['name'] for c in completed_crawls])\r\n+    return gr.update(choices=[\"No RAG\", \"Web Search\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n \r\n+def submit_chat(m, h, s):\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\"] else None)\r\n+    for chat_out, msg_out in gen:\r\n+        yield chat_out, msg_out\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     tasks_state = gr.State([])\r\n@@ -19,17 +24,17 @@\n     \r\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n+            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=\"No RAG\", interactive=True)\r\n             refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\"] else None), [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n@@ -53,9 +58,10 @@\n         with gr.Tab(\"View Database\"):\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n             chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n-            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n+            completed_crawls_df = gr.Dataframe(label=\"Completed Crawls (Subreddits/Queries)\")\r\n+            load_db_btn.click(lambda cs: (view_db(conn)[0], view_db(conn)[1], pd.DataFrame(cs)), completed_crawls_state, [urls_df, chunks_df, completed_crawls_df])\r\n         \r\n         with gr.Tab(\"View Vector Store\"):\r\n             show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n             vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n"
                },
                {
                    "date": 1756862079951,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,13 +10,8 @@\n \r\n def update_dropdown(completed_crawls):\r\n     return gr.update(choices=[\"No RAG\", \"Web Search\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n \r\n-def submit_chat(m, h, s):\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\"] else None)\r\n-    for chat_out, msg_out in gen:\r\n-        yield chat_out, msg_out\r\n-\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     tasks_state = gr.State([])\r\n@@ -24,17 +19,18 @@\n     \r\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=\"No RAG\", interactive=True)\r\n+            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n             refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n+            demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n             refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\"] else None), [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n@@ -58,10 +54,9 @@\n         with gr.Tab(\"View Database\"):\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n             chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n-            completed_crawls_df = gr.Dataframe(label=\"Completed Crawls (Subreddits/Queries)\")\r\n-            load_db_btn.click(lambda cs: (view_db(conn)[0], view_db(conn)[1], pd.DataFrame(cs)), completed_crawls_state, [urls_df, chunks_df, completed_crawls_df])\r\n+            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n         \r\n         with gr.Tab(\"View Vector Store\"):\r\n             show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n             vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n"
                },
                {
                    "date": 1756862790440,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,8 +10,13 @@\n \r\n def update_dropdown(completed_crawls):\r\n     return gr.update(choices=[\"No RAG\", \"Web Search\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n \r\n+def submit_chat(m, h, s):\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\"] else None)\r\n+    for chat_out, msg_out in gen:\r\n+        yield chat_out, msg_out\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     tasks_state = gr.State([])\r\n@@ -28,9 +33,9 @@\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n             refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(lambda m, h, s: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\"] else None), [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n"
                },
                {
                    "date": 1756863204976,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,8 +3,9 @@\n from db_utils import init_db\r\n from chat_utils import chat_bot\r\n from crawl_utils import start_crawl\r\n from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n+from process_utils import ingest_local_file, ingest_youtube\r\n from config import MODEL_NAME\r\n \r\n conn = init_db()\r\n \r\n@@ -55,8 +56,22 @@\n             crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n             refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n+        with gr.Tab(\"Ingest Local File\"):\r\n+            file_upload = gr.File(label=\"Upload TXT or PDF\")\r\n+            local_tag_input = gr.Textbox(label=\"Tag for this ingestion (e.g., my_document)\")\r\n+            ingest_local_btn = gr.Button(\"Ingest File\")\r\n+            local_status = gr.Textbox(label=\"Ingestion Status\")\r\n+            ingest_local_btn.click(lambda f, tag: ingest_local_file(f, source_tag=tag, conn=conn), [file_upload, local_tag_input], local_status)\r\n+        \r\n+        with gr.Tab(\"Ingest YouTube\"):\r\n+            youtube_url_input = gr.Textbox(label=\"YouTube URL\")\r\n+            youtube_tag_input = gr.Textbox(label=\"Tag for this ingestion (e.g., video_transcript)\")\r\n+            ingest_youtube_btn = gr.Button(\"Ingest Transcript\")\r\n+            youtube_status = gr.Textbox(label=\"Ingestion Status\")\r\n+            ingest_youtube_btn.click(lambda u, tag: ingest_youtube(u, source_tag=tag, conn=conn), [youtube_url_input, youtube_tag_input], youtube_status)\r\n+        \r\n         with gr.Tab(\"View Database\"):\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n             chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n"
                },
                {
                    "date": 1756865711798,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,18 +3,17 @@\n from db_utils import init_db\r\n from chat_utils import chat_bot\r\n from crawl_utils import start_crawl\r\n from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n-from process_utils import ingest_local_file, ingest_youtube\r\n from config import MODEL_NAME\r\n \r\n conn = init_db()\r\n \r\n def update_dropdown(completed_crawls):\r\n-    return gr.update(choices=[\"No RAG\", \"Web Search\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n+    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n \r\n def submit_chat(m, h, s):\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\"] else None)\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None)\r\n     for chat_out, msg_out in gen:\r\n         yield chat_out, msg_out\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n@@ -56,22 +55,8 @@\n             crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n             refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n-        with gr.Tab(\"Ingest Local File\"):\r\n-            file_upload = gr.File(label=\"Upload TXT or PDF\")\r\n-            local_tag_input = gr.Textbox(label=\"Tag for this ingestion (e.g., my_document)\")\r\n-            ingest_local_btn = gr.Button(\"Ingest File\")\r\n-            local_status = gr.Textbox(label=\"Ingestion Status\")\r\n-            ingest_local_btn.click(lambda f, tag: ingest_local_file(f, source_tag=tag, conn=conn), [file_upload, local_tag_input], local_status)\r\n-        \r\n-        with gr.Tab(\"Ingest YouTube\"):\r\n-            youtube_url_input = gr.Textbox(label=\"YouTube URL\")\r\n-            youtube_tag_input = gr.Textbox(label=\"Tag for this ingestion (e.g., video_transcript)\")\r\n-            ingest_youtube_btn = gr.Button(\"Ingest Transcript\")\r\n-            youtube_status = gr.Textbox(label=\"Ingestion Status\")\r\n-            ingest_youtube_btn.click(lambda u, tag: ingest_youtube(u, source_tag=tag, conn=conn), [youtube_url_input, youtube_tag_input], youtube_status)\r\n-        \r\n         with gr.Tab(\"View Database\"):\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n             chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n"
                },
                {
                    "date": 1756875855123,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,80 @@\n+import os\r\n+import gradio as gr\r\n+from db_utils import init_db, get_unique_tags\r\n+from chat_utils import chat_bot\r\n+from crawl_utils import start_crawl\r\n+from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n+from config import MODEL_NAME, DEFAULT_CONTEXT_LENGTH, DEFAULT_BATCH_SIZE, DEFAULT_PRECISION\r\n+\r\n+conn = init_db()\r\n+\r\n+def update_dropdown(completed_crawls):\r\n+    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n+\r\n+def update_embedding_dropdown():\r\n+    return gr.update(choices=get_unique_tags(conn))\r\n+\r\n+with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n+    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n+    \r\n+    tasks_state = gr.State([])\r\n+    completed_crawls_state = gr.State([])\r\n+    \r\n+    with gr.Tabs():\r\n+        with gr.Tab(\"Chat\"):\r\n+            gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n+            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n+            embedding_dropdown = gr.Dropdown(label=\"Select Saved Embedding (optional)\", choices=[], value=None, interactive=True)\r\n+            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n+            refresh_embeddings_btn = gr.Button(\"Refresh Embeddings\")\r\n+            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n+            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n+            with gr.Row():\r\n+                submit_btn = gr.Button(\"Submit\")\r\n+                clear = gr.Button(\"Clear\")\r\n+            demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n+            demo.load(update_embedding_dropdown, None, embedding_dropdown)\r\n+            refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n+            refresh_embeddings_btn.click(update_embedding_dropdown, None, embedding_dropdown)\r\n+            submit_btn.click(lambda m, h, s, e: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=e or next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None), [msg, chatbot, source_dropdown, embedding_dropdown], [chatbot, msg])\r\n+            clear.click(lambda: None, None, chatbot, queue=False)\r\n+            clear.click(lambda: \"\", None, msg, queue=False)\r\n+        \r\n+        with gr.Tab(\"Crawl Subreddit\"):\r\n+            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n+            timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            crawl_btn = gr.Button(\"Crawl\")\r\n+            status = gr.Textbox(label=\"Status\")\r\n+            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n+            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n+            with gr.Accordion(\"Task Detail\", open=False):\r\n+                task_id_input = gr.Number(label=\"Task ID\")\r\n+                view_detail_btn = gr.Button(\"View Detail\")\r\n+                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n+                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n+                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n+            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n+            refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n+            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n+        \r\n+        with gr.Tab(\"View Database\"):\r\n+            load_db_btn = gr.Button(\"Load Database Contents\")\r\n+            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n+            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n+            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n+        \r\n+        with gr.Tab(\"View Vector Store\"):\r\n+            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n+            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n+            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n+\r\n+        with gr.Tab(\"Settings\"):\r\n+            context_length_slider = gr.Slider(minimum=512, maximum=131072, value=DEFAULT_CONTEXT_LENGTH, label=\"LLM Context Length (tokens)\")\r\n+            batch_size_slider = gr.Slider(minimum=1, maximum=4, value=DEFAULT_BATCH_SIZE, label=\"Batch Size\")\r\n+            precision_dropdown = gr.Dropdown([\"fp16\", \"bf16\", \"fp32\"], value=DEFAULT_PRECISION, label=\"Precision\")\r\n+            save_settings_btn = gr.Button(\"Save Settings\")\r\n+            settings_status = gr.Textbox(label=\"Settings Status\")\r\n+            save_settings_btn.click(lambda cl, bs, p: f\"Settings saved: Context {cl}, Batch {bs}, Precision {p}\", [context_length_slider, batch_size_slider, precision_dropdown], settings_status)\r\n+\r\n+demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756876038841,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,243 @@\n+import os\r\n+from config import MODEL_NAME\r\n+from langchain_ollama import OllamaLLM\r\n+from langchain_core.messages import HumanMessage, AIMessage\r\n+from langchain.chains import create_retrieval_chain, create_history_aware_retriever\r\n+from langchain.chains.combine_documents import create_stuff_documents_chain\r\n+from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\r\n+from langchain.retrievers import EnsembleRetriever\r\n+from langchain_community.retrievers import BM25Retriever\r\n+from langchain.text_splitter import RecursiveCharacterTextSplitter\r\n+from langchain_core.documents import Document\r\n+from web_utils import search_web\r\n+from config import MAX_URLS\r\n+from process_utils import process_urls\r\n+from vectorstore_utils import vectorstore\r\n+from db_utils import add_chunk_if_new\r\n+from utils import lock\r\n+import re\r\n+import requests\r\n+import json\r\n+from xml.etree import ElementTree as ET\r\n+import time\r\n+\r\n+def chat_bot(message, history, conn=None, selected_source=None, selected_tag=None):\r\n+    print(f\"Starting chat_bot with message: {message}, selected_source: {selected_source}, selected_tag: {selected_tag}\")\r\n+    history.append({\"role\": \"user\", \"content\": message})\r\n+    yield history, \"\"\r\n+\r\n+    response = \"\"\r\n+    history.append({\"role\": \"assistant\", \"content\": response})\r\n+    yield history, \"\"\r\n+\r\n+    chat_history = []\r\n+    for h in history[:-1]:\r\n+        if h[\"role\"] == \"user\":\r\n+            chat_history.append(HumanMessage(content=h[\"content\"]))\r\n+        elif h[\"role\"] == \"assistant\":\r\n+            chat_history.append(AIMessage(content=h[\"content\"]))\r\n+\r\n+    llm = OllamaLLM(model=MODEL_NAME)\r\n+\r\n+    retriever = None\r\n+    sources = []\r\n+    if selected_source == \"No RAG\":\r\n+        selected_source = None\r\n+    if selected_source:\r\n+        if selected_source == \"Web Search\":\r\n+            response += \"**Processing Status:**\\n\"\r\n+            response += f\"Searching web for query: {message}\\n\"\r\n+            history[-1][\"content\"] = response\r\n+            yield history, \"\"\r\n+\r\n+            google_urls = search_web(message)\r\n+\r\n+            response += f\"Found {len(google_urls)} Google URLs: {', '.join(google_urls)}\\n\\n\"\r\n+            history[-1][\"content\"] = response\r\n+            yield history, \"\"\r\n+\r\n+            response += f\"Searching Reddit for query: {message}\\n\"\r\n+            history[-1][\"content\"] = response\r\n+            yield history, \"\"\r\n+\r\n+            reddit_urls = search_web(message, site=\"reddit.com\")\r\n+\r\n+            response += f\"Found {len(reddit_urls)} Reddit URLs: {', '.join(reddit_urls)}\\n\\n\"\r\n+            history[-1][\"content\"] = response\r\n+            yield history, \"\"\r\n+\r\n+            all_urls = list(set(google_urls + reddit_urls))[:MAX_URLS]\r\n+            response += f\"All unique URLs to process (limited to {MAX_URLS}): {', '.join(all_urls)}\\n\\n\"\r\n+            history[-1][\"content\"] = response\r\n+            yield history, \"\"\r\n+\r\n+            process_gen = process_urls(all_urls, response, history, message, conn=conn)\r\n+            for upd in process_gen:\r\n+                yield upd\r\n+\r\n+            try:\r\n+                sources, response, history = next(process_gen)\r\n+            except StopIteration as e:\r\n+                if e.value:\r\n+                    sources, response, history = e.value\r\n+                else:\r\n+                    sources = []\r\n+\r\n+            search_kwargs = {\"k\": 5}\r\n+            if 'lyrics' in message.lower():\r\n+                search_kwargs[\"filter\"] = {\"source_type\": \"lyrics\"}\r\n+            dense_retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)\r\n+            bm25_retriever = BM25Retriever.from_documents(vectorstore.similarity_search(\" \", k=vectorstore.index.ntotal))\r\n+            retriever = EnsembleRetriever(retrievers=[dense_retriever, bm25_retriever], weights=[0.7, 0.3])\r\n+        elif selected_source == \"YouTube\":\r\n+            response += \"**Processing Status:**\\n\"\r\n+            response += f\"Searching YouTube for query: {message}\\n\"\r\n+            history[-1][\"content\"] = response\r\n+            yield history, \"\"\r\n+\r\n+            youtube_urls = search_web(message, site=\"youtube.com\")\r\n+\r\n+            response += f\"Found {len(youtube_urls)} YouTube URLs: {', '.join(youtube_urls)}\\n\\n\"\r\n+            history[-1][\"content\"] = response\r\n+            yield history, \"\"\r\n+\r\n+            all_urls = list(set(youtube_urls))[:5]  # Limit to 5 to avoid rate limiting\r\n+            response += f\"All unique URLs to process (limited to 5): {', '.join(all_urls)}\\n\\n\"\r\n+            history[-1][\"content\"] = response\r\n+            yield history, \"\"\r\n+\r\n+            transcripts = []\r\n+            for url in all_urls:\r\n+                match = re.search(r\"v=([^&]+)\", url)\r\n+                if match:\r\n+                    video_id = match.group(1)\r\n+                    try:\r\n+                        api_url = f\"https://www.youtube.com/api/timedtext?v={video_id}&lang=en&fmt=json3\"\r\n+                        api_response = requests.get(api_url)\r\n+                        print(f\"Debug: Timedtext API status: {api_response.status_code}, content: {api_response.text[:200]}\")\r\n+                        if api_response.status_code == 200:\r\n+                            if api_response.text.startswith('{'):\r\n+                                json_data = api_response.json()\r\n+                                if 'events' in json_data:\r\n+                                    transcript_text = \" \".join([event['segs'][0]['utf8'] for event in json_data['events'] if 'segs' in event and event['segs'] and 'utf8' in event['segs'][0]])\r\n+                                    transcripts.append(transcript_text)\r\n+                                    response += f\"Transcript fetched for {url} (direct timedtext API - JSON)\\n\"\r\n+                                else:\r\n+                                    response += f\"Debug: No 'events' in JSON for {url}.\\n\"\r\n+                            elif api_response.text.startswith('<'):\r\n+                                # Handle XML fallback\r\n+                                root = ET.fromstring(api_response.text)\r\n+                                transcript_text = \" \".join([elem.text for elem in root.findall('.//text') if elem.text])\r\n+                                transcripts.append(transcript_text)\r\n+                                response += f\"Transcript fetched for {url} (direct timedtext API - XML fallback)\\n\"\r\n+                            else:\r\n+                                response += f\"Debug: Unknown format for {url}.\\n\"\r\n+                        else:\r\n+                            response += f\"Debug: Status {api_response.status_code} for {url}.\\n\"\r\n+                            response += f\"Error fetching transcript for {url}: Failed to get transcript.\\n\"\r\n+                    except Exception as e:\r\n+                        response += f\"Error fetching transcript for {url}: {e}\\n\"\r\n+                    history[-1][\"content\"] = response\r\n+                    yield history, \"\"\r\n+                    time.sleep(2)  # Delay to avoid rate limiting\r\n+\r\n+            combined_transcript = \" \".join(transcripts)\r\n+            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\r\n+            chunks = text_splitter.split_text(combined_transcript)\r\n+            new_docs = []\r\n+            for chunk in chunks:\r\n+                if add_chunk_if_new(conn, chunk, \"YouTube transcripts\"):\r\n+                    metadata = {\"source\": \"YouTube\", \"tag\": \"youtube_\" + message.replace(\" \", \"_\")}\r\n+                    new_docs.append(Document(page_content=chunk, metadata=metadata))\r\n+\r\n+            if new_docs:\r\n+                with lock:\r\n+                    vectorstore.add_documents(new_docs)\r\n+                    vectorstore.save_local(FAISS_PATH)\r\n+\r\n+            search_kwargs = {\"k\": 5, \"filter\": {\"tag\": \"youtube_\" + message.replace(\" \", \"_\")}}\r\n+            dense_retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)\r\n+            bm25_retriever = BM25Retriever.from_documents(vectorstore.similarity_search(\" \", k=vectorstore.index.ntotal))\r\n+            retriever = EnsembleRetriever(retrievers=[dense_retriever, bm25_retriever], weights=[0.7, 0.3])\r\n+        else:\r\n+            response += \"**Processing Status:**\\n\"\r\n+            search_kwargs = {\"k\": 5, \"filter\": {\"tag\": selected_tag}}\r\n+            if 'lyrics' in message.lower():\r\n+                search_kwargs[\"filter\"][\"source_type\"] = \"lyrics\"\r\n+            dense_retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)\r\n+            bm25_retriever = BM25Retriever.from_documents(vectorstore.similarity_search(\" \", k=vectorstore.index.ntotal))\r\n+            retriever = EnsembleRetriever(retrievers=[dense_retriever, bm25_retriever], weights=[0.7, 0.3])\r\n+\r\n+    if retriever is None:\r\n+        # Direct LLM call without retrieval\r\n+        qa_prompt = ChatPromptTemplate.from_template(\r\n+            \"Answer the question:\\n\\nQuestion: {input}\"\r\n+        )\r\n+        qa_chain = qa_prompt | llm\r\n+        answer = qa_chain.invoke({\"input\": message})\r\n+        response = f\"**Specific Answer:**\\n{answer}\\n\\n\"\r\n+        history[-1][\"content\"] = response\r\n+        yield history, \"\"\r\n+    else:\r\n+        if vectorstore.index.ntotal == 0:\r\n+            response += \"No relevant content in vectorstore.\\n\\n**Specific Answer:**\\nSorry, I couldn't find any information.\"\r\n+            history[-1][\"content\"] = response\r\n+            yield history, \"\"\r\n+            return\r\n+\r\n+        response += \"Creating/Updating vector store...\\n\"\r\n+        history[-1][\"content\"] = response\r\n+        yield history, \"\"\r\n+\r\n+        response += \"Vector store ready.\\n\\n\"\r\n+        history[-1][\"content\"] = response\r\n+        yield history, \"\"\r\n+\r\n+        response += \"Generating summarization of the found content...\\n\"\r\n+        history[-1][\"content\"] = response\r\n+        yield history, \"\"\r\n+\r\n+        summary_prompt = ChatPromptTemplate.from_template(\r\n+            \"Summarize the following retrieved content related to the question '{input}' in a concise manner:\\n\\n{context}\"\r\n+        )\r\n+        summary_chain = create_stuff_documents_chain(llm, summary_prompt)\r\n+        summary_chain_with_docs = create_retrieval_chain(retriever, summary_chain)\r\n+        summary_response = summary_chain_with_docs.invoke({\"input\": message})\r\n+        summary = summary_response[\"answer\"]\r\n+\r\n+        response += f\"**Summarization of Found Content:**\\n{summary}\\n\\n\"\r\n+        history[-1][\"content\"] = response\r\n+        yield history, \"\"\r\n+\r\n+        response += \"Generating specific answer to the prompt...\\n\"\r\n+        history[-1][\"content\"] = response\r\n+        yield history, \"\"\r\n+\r\n+        rephrase_prompt = ChatPromptTemplate.from_messages(\r\n+            [\r\n+                MessagesPlaceholder(variable_name=\"chat_history\"),\r\n+                (\"human\", \"{input}\"),\r\n+                (\"human\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\"),\r\n+            ]\r\n+        )\r\n+        history_aware_retriever = create_history_aware_retriever(llm, retriever, rephrase_prompt)\r\n+\r\n+        qa_prompt = ChatPromptTemplate.from_template(\r\n+            \"Use the context to answer the question as accurately as possible. If lyrics are present, extract and format them clearly with verses, chorus, etc., and ignore non-lyric content like discussions. If uncertain or incomplete, note limitations but provide what's available:\\n\\n{context}\\n\\nQuestion: {input}\"\r\n+        )\r\n+        qa_chain = create_stuff_documents_chain(llm, qa_prompt)\r\n+        qa_chain_with_docs = create_retrieval_chain(history_aware_retriever, qa_chain)\r\n+        qa_response = qa_chain_with_docs.invoke({\"input\": message, \"chat_history\": chat_history})\r\n+        answer = qa_response[\"answer\"]\r\n+\r\n+        response += f\"**Specific Answer:**\\n{answer}\\n\\n\"\r\n+        history[-1][\"content\"] = response\r\n+        yield history, \"\"\r\n+\r\n+    if selected_source in [\"Web Search\", \"YouTube\"]:\r\n+        sources_str = \"\\n\".join([f\"- {url}\" for url in sources])\r\n+        response += f\"**Sources Crawled:**\\n{sources_str}\"\r\n+        history[-1][\"content\"] = response\r\n+        yield history, \"\"\r\n+\r\n+    print(\"chat_bot completed.\")\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756876060012,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -239,155 +239,5 @@\n         response += f\"**Sources Crawled:**\\n{sources_str}\"\r\n         history[-1][\"content\"] = response\r\n         yield history, \"\"\r\n \r\n-    print(\"chat_bot completed.\")\n-import os\r\n-import gradio as gr\r\n-from db_utils import init_db, get_unique_tags\r\n-from chat_utils import chat_bot\r\n-from crawl_utils import start_crawl\r\n-from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n-from config import MODEL_NAME, DEFAULT_CONTEXT_LENGTH, DEFAULT_BATCH_SIZE, DEFAULT_PRECISION\r\n-\r\n-conn = init_db()\r\n-\r\n-def update_dropdown(completed_crawls):\r\n-    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n-\r\n-def update_embedding_dropdown():\r\n-    return gr.update(choices=get_unique_tags(conn))\r\n-\r\n-with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n-    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n-    \r\n-    tasks_state = gr.State([])\r\n-    completed_crawls_state = gr.State([])\r\n-    \r\n-    with gr.Tabs():\r\n-        with gr.Tab(\"Chat\"):\r\n-            gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n-            embedding_dropdown = gr.Dropdown(label=\"Select Saved Embedding (optional)\", choices=[], value=None, interactive=True)\r\n-            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n-            refresh_embeddings_btn = gr.Button(\"Refresh Embeddings\")\r\n-            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n-            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n-            with gr.Row():\r\n-                submit_btn = gr.Button(\"Submit\")\r\n-                clear = gr.Button(\"Clear\")\r\n-            demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            demo.load(update_embedding_dropdown, None, embedding_dropdown)\r\n-            refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            refresh_embeddings_btn.click(update_embedding_dropdown, None, embedding_dropdown)\r\n-            submit_btn.click(lambda m, h, s, e: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=e or next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None), [msg, chatbot, source_dropdown, embedding_dropdown], [chatbot, msg])\r\n-            clear.click(lambda: None, None, chatbot, queue=False)\r\n-            clear.click(lambda: \"\", None, msg, queue=False)\r\n-        \r\n-        with gr.Tab(\"Crawl Subreddit\"):\r\n-            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n-            timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n-            crawl_btn = gr.Button(\"Crawl\")\r\n-            status = gr.Textbox(label=\"Status\")\r\n-            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n-            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n-            with gr.Accordion(\"Task Detail\", open=False):\r\n-                task_id_input = gr.Number(label=\"Task ID\")\r\n-                view_detail_btn = gr.Button(\"View Detail\")\r\n-                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n-                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n-                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n-            refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n-            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n-        \r\n-        with gr.Tab(\"View Database\"):\r\n-            load_db_btn = gr.Button(\"Load Database Contents\")\r\n-            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n-            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n-            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n-        \r\n-        with gr.Tab(\"View Vector Store\"):\r\n-            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n-            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n-            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n-\r\n-        with gr.Tab(\"Settings\"):\r\n-            context_length_slider = gr.Slider(minimum=512, maximum=131072, value=DEFAULT_CONTEXT_LENGTH, label=\"LLM Context Length (tokens)\")\r\n-            batch_size_slider = gr.Slider(minimum=1, maximum=4, value=DEFAULT_BATCH_SIZE, label=\"Batch Size\")\r\n-            precision_dropdown = gr.Dropdown([\"fp16\", \"bf16\", \"fp32\"], value=DEFAULT_PRECISION, label=\"Precision\")\r\n-            save_settings_btn = gr.Button(\"Save Settings\")\r\n-            settings_status = gr.Textbox(label=\"Settings Status\")\r\n-            save_settings_btn.click(lambda cl, bs, p: f\"Settings saved: Context {cl}, Batch {bs}, Precision {p}\", [context_length_slider, batch_size_slider, precision_dropdown], settings_status)\r\n-\r\n-demo.queue(default_concurrency_limit=5).launch()\n-import os\r\n-import gradio as gr\r\n-from db_utils import init_db\r\n-from chat_utils import chat_bot\r\n-from crawl_utils import start_crawl\r\n-from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n-from config import MODEL_NAME\r\n-\r\n-conn = init_db()\r\n-\r\n-def update_dropdown(completed_crawls):\r\n-    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n-\r\n-def submit_chat(m, h, s):\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None)\r\n-    for chat_out, msg_out in gen:\r\n-        yield chat_out, msg_out\r\n-\r\n-with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n-    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n-    \r\n-    tasks_state = gr.State([])\r\n-    completed_crawls_state = gr.State([])\r\n-    \r\n-    with gr.Tabs():\r\n-        with gr.Tab(\"Chat\"):\r\n-            gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n-            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n-            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n-            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n-            with gr.Row():\r\n-                submit_btn = gr.Button(\"Submit\")\r\n-                clear = gr.Button(\"Clear\")\r\n-            demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n-            clear.click(lambda: None, None, chatbot, queue=False)\r\n-            clear.click(lambda: \"\", None, msg, queue=False)\r\n-        \r\n-        with gr.Tab(\"Crawl Subreddit\"):\r\n-            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n-            timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n-            crawl_btn = gr.Button(\"Crawl\")\r\n-            status = gr.Textbox(label=\"Status\")\r\n-            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n-            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n-            with gr.Accordion(\"Task Detail\", open=False):\r\n-                task_id_input = gr.Number(label=\"Task ID\")\r\n-                view_detail_btn = gr.Button(\"View Detail\")\r\n-                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n-                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n-                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n-            refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n-            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n-        \r\n-        with gr.Tab(\"View Database\"):\r\n-            load_db_btn = gr.Button(\"Load Database Contents\")\r\n-            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n-            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n-            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n-        \r\n-        with gr.Tab(\"View Vector Store\"):\r\n-            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n-            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n-            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n-\r\n-demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n+    print(\"chat_bot completed.\")\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756876082698,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,243 +1,80 @@\n import os\r\n-from config import MODEL_NAME\r\n-from langchain_ollama import OllamaLLM\r\n-from langchain_core.messages import HumanMessage, AIMessage\r\n-from langchain.chains import create_retrieval_chain, create_history_aware_retriever\r\n-from langchain.chains.combine_documents import create_stuff_documents_chain\r\n-from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\r\n-from langchain.retrievers import EnsembleRetriever\r\n-from langchain_community.retrievers import BM25Retriever\r\n-from langchain.text_splitter import RecursiveCharacterTextSplitter\r\n-from langchain_core.documents import Document\r\n-from web_utils import search_web\r\n-from config import MAX_URLS\r\n-from process_utils import process_urls\r\n-from vectorstore_utils import vectorstore\r\n-from db_utils import add_chunk_if_new\r\n-from utils import lock\r\n-import re\r\n-import requests\r\n-import json\r\n-from xml.etree import ElementTree as ET\r\n-import time\r\n+import gradio as gr\r\n+from db_utils import init_db, get_unique_tags\r\n+from chat_utils import chat_bot\r\n+from crawl_utils import start_crawl\r\n+from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n+from config import MODEL_NAME, DEFAULT_CONTEXT_LENGTH, DEFAULT_BATCH_SIZE, DEFAULT_PRECISION\r\n \r\n-def chat_bot(message, history, conn=None, selected_source=None, selected_tag=None):\r\n-    print(f\"Starting chat_bot with message: {message}, selected_source: {selected_source}, selected_tag: {selected_tag}\")\r\n-    history.append({\"role\": \"user\", \"content\": message})\r\n-    yield history, \"\"\r\n+conn = init_db()\r\n \r\n-    response = \"\"\r\n-    history.append({\"role\": \"assistant\", \"content\": response})\r\n-    yield history, \"\"\r\n+def update_dropdown(completed_crawls):\r\n+    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n \r\n-    chat_history = []\r\n-    for h in history[:-1]:\r\n-        if h[\"role\"] == \"user\":\r\n-            chat_history.append(HumanMessage(content=h[\"content\"]))\r\n-        elif h[\"role\"] == \"assistant\":\r\n-            chat_history.append(AIMessage(content=h[\"content\"]))\r\n+def update_embedding_dropdown():\r\n+    return gr.update(choices=get_unique_tags(conn))\r\n \r\n-    llm = OllamaLLM(model=MODEL_NAME)\r\n+with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n+    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n+    \r\n+    tasks_state = gr.State([])\r\n+    completed_crawls_state = gr.State([])\r\n+    \r\n+    with gr.Tabs():\r\n+        with gr.Tab(\"Chat\"):\r\n+            gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n+            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n+            embedding_dropdown = gr.Dropdown(label=\"Select Saved Embedding (optional)\", choices=[], value=None, interactive=True)\r\n+            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n+            refresh_embeddings_btn = gr.Button(\"Refresh Embeddings\")\r\n+            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n+            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n+            with gr.Row():\r\n+                submit_btn = gr.Button(\"Submit\")\r\n+                clear = gr.Button(\"Clear\")\r\n+            demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n+            demo.load(update_embedding_dropdown, None, embedding_dropdown)\r\n+            refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n+            refresh_embeddings_btn.click(update_embedding_dropdown, None, embedding_dropdown)\r\n+            submit_btn.click(lambda m, h, s, e: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=e or next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None), [msg, chatbot, source_dropdown, embedding_dropdown], [chatbot, msg])\r\n+            clear.click(lambda: None, None, chatbot, queue=False)\r\n+            clear.click(lambda: \"\", None, msg, queue=False)\r\n+        \r\n+        with gr.Tab(\"Crawl Subreddit\"):\r\n+            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n+            timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            crawl_btn = gr.Button(\"Crawl\")\r\n+            status = gr.Textbox(label=\"Status\")\r\n+            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n+            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n+            with gr.Accordion(\"Task Detail\", open=False):\r\n+                task_id_input = gr.Number(label=\"Task ID\")\r\n+                view_detail_btn = gr.Button(\"View Detail\")\r\n+                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n+                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n+                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n+            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n+            refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n+            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n+        \r\n+        with gr.Tab(\"View Database\"):\r\n+            load_db_btn = gr.Button(\"Load Database Contents\")\r\n+            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n+            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n+            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n+        \r\n+        with gr.Tab(\"View Vector Store\"):\r\n+            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n+            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n+            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n \r\n-    retriever = None\r\n-    sources = []\r\n-    if selected_source == \"No RAG\":\r\n-        selected_source = None\r\n-    if selected_source:\r\n-        if selected_source == \"Web Search\":\r\n-            response += \"**Processing Status:**\\n\"\r\n-            response += f\"Searching web for query: {message}\\n\"\r\n-            history[-1][\"content\"] = response\r\n-            yield history, \"\"\r\n+        with gr.Tab(\"Settings\"):\r\n+            context_length_slider = gr.Slider(minimum=512, maximum=131072, value=DEFAULT_CONTEXT_LENGTH, label=\"LLM Context Length (tokens)\")\r\n+            batch_size_slider = gr.Slider(minimum=1, maximum=4, value=DEFAULT_BATCH_SIZE, label=\"Batch Size\")\r\n+            precision_dropdown = gr.Dropdown([\"fp16\", \"bf16\", \"fp32\"], value=DEFAULT_PRECISION, label=\"Precision\")\r\n+            save_settings_btn = gr.Button(\"Save Settings\")\r\n+            settings_status = gr.Textbox(label=\"Settings Status\")\r\n+            save_settings_btn.click(lambda cl, bs, p: f\"Settings saved: Context {cl}, Batch {bs}, Precision {p}\", [context_length_slider, batch_size_slider, precision_dropdown], settings_status)\r\n \r\n-            google_urls = search_web(message)\r\n-\r\n-            response += f\"Found {len(google_urls)} Google URLs: {', '.join(google_urls)}\\n\\n\"\r\n-            history[-1][\"content\"] = response\r\n-            yield history, \"\"\r\n-\r\n-            response += f\"Searching Reddit for query: {message}\\n\"\r\n-            history[-1][\"content\"] = response\r\n-            yield history, \"\"\r\n-\r\n-            reddit_urls = search_web(message, site=\"reddit.com\")\r\n-\r\n-            response += f\"Found {len(reddit_urls)} Reddit URLs: {', '.join(reddit_urls)}\\n\\n\"\r\n-            history[-1][\"content\"] = response\r\n-            yield history, \"\"\r\n-\r\n-            all_urls = list(set(google_urls + reddit_urls))[:MAX_URLS]\r\n-            response += f\"All unique URLs to process (limited to {MAX_URLS}): {', '.join(all_urls)}\\n\\n\"\r\n-            history[-1][\"content\"] = response\r\n-            yield history, \"\"\r\n-\r\n-            process_gen = process_urls(all_urls, response, history, message, conn=conn)\r\n-            for upd in process_gen:\r\n-                yield upd\r\n-\r\n-            try:\r\n-                sources, response, history = next(process_gen)\r\n-            except StopIteration as e:\r\n-                if e.value:\r\n-                    sources, response, history = e.value\r\n-                else:\r\n-                    sources = []\r\n-\r\n-            search_kwargs = {\"k\": 5}\r\n-            if 'lyrics' in message.lower():\r\n-                search_kwargs[\"filter\"] = {\"source_type\": \"lyrics\"}\r\n-            dense_retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)\r\n-            bm25_retriever = BM25Retriever.from_documents(vectorstore.similarity_search(\" \", k=vectorstore.index.ntotal))\r\n-            retriever = EnsembleRetriever(retrievers=[dense_retriever, bm25_retriever], weights=[0.7, 0.3])\r\n-        elif selected_source == \"YouTube\":\r\n-            response += \"**Processing Status:**\\n\"\r\n-            response += f\"Searching YouTube for query: {message}\\n\"\r\n-            history[-1][\"content\"] = response\r\n-            yield history, \"\"\r\n-\r\n-            youtube_urls = search_web(message, site=\"youtube.com\")\r\n-\r\n-            response += f\"Found {len(youtube_urls)} YouTube URLs: {', '.join(youtube_urls)}\\n\\n\"\r\n-            history[-1][\"content\"] = response\r\n-            yield history, \"\"\r\n-\r\n-            all_urls = list(set(youtube_urls))[:5]  # Limit to 5 to avoid rate limiting\r\n-            response += f\"All unique URLs to process (limited to 5): {', '.join(all_urls)}\\n\\n\"\r\n-            history[-1][\"content\"] = response\r\n-            yield history, \"\"\r\n-\r\n-            transcripts = []\r\n-            for url in all_urls:\r\n-                match = re.search(r\"v=([^&]+)\", url)\r\n-                if match:\r\n-                    video_id = match.group(1)\r\n-                    try:\r\n-                        api_url = f\"https://www.youtube.com/api/timedtext?v={video_id}&lang=en&fmt=json3\"\r\n-                        api_response = requests.get(api_url)\r\n-                        print(f\"Debug: Timedtext API status: {api_response.status_code}, content: {api_response.text[:200]}\")\r\n-                        if api_response.status_code == 200:\r\n-                            if api_response.text.startswith('{'):\r\n-                                json_data = api_response.json()\r\n-                                if 'events' in json_data:\r\n-                                    transcript_text = \" \".join([event['segs'][0]['utf8'] for event in json_data['events'] if 'segs' in event and event['segs'] and 'utf8' in event['segs'][0]])\r\n-                                    transcripts.append(transcript_text)\r\n-                                    response += f\"Transcript fetched for {url} (direct timedtext API - JSON)\\n\"\r\n-                                else:\r\n-                                    response += f\"Debug: No 'events' in JSON for {url}.\\n\"\r\n-                            elif api_response.text.startswith('<'):\r\n-                                # Handle XML fallback\r\n-                                root = ET.fromstring(api_response.text)\r\n-                                transcript_text = \" \".join([elem.text for elem in root.findall('.//text') if elem.text])\r\n-                                transcripts.append(transcript_text)\r\n-                                response += f\"Transcript fetched for {url} (direct timedtext API - XML fallback)\\n\"\r\n-                            else:\r\n-                                response += f\"Debug: Unknown format for {url}.\\n\"\r\n-                        else:\r\n-                            response += f\"Debug: Status {api_response.status_code} for {url}.\\n\"\r\n-                            response += f\"Error fetching transcript for {url}: Failed to get transcript.\\n\"\r\n-                    except Exception as e:\r\n-                        response += f\"Error fetching transcript for {url}: {e}\\n\"\r\n-                    history[-1][\"content\"] = response\r\n-                    yield history, \"\"\r\n-                    time.sleep(2)  # Delay to avoid rate limiting\r\n-\r\n-            combined_transcript = \" \".join(transcripts)\r\n-            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\r\n-            chunks = text_splitter.split_text(combined_transcript)\r\n-            new_docs = []\r\n-            for chunk in chunks:\r\n-                if add_chunk_if_new(conn, chunk, \"YouTube transcripts\"):\r\n-                    metadata = {\"source\": \"YouTube\", \"tag\": \"youtube_\" + message.replace(\" \", \"_\")}\r\n-                    new_docs.append(Document(page_content=chunk, metadata=metadata))\r\n-\r\n-            if new_docs:\r\n-                with lock:\r\n-                    vectorstore.add_documents(new_docs)\r\n-                    vectorstore.save_local(FAISS_PATH)\r\n-\r\n-            search_kwargs = {\"k\": 5, \"filter\": {\"tag\": \"youtube_\" + message.replace(\" \", \"_\")}}\r\n-            dense_retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)\r\n-            bm25_retriever = BM25Retriever.from_documents(vectorstore.similarity_search(\" \", k=vectorstore.index.ntotal))\r\n-            retriever = EnsembleRetriever(retrievers=[dense_retriever, bm25_retriever], weights=[0.7, 0.3])\r\n-        else:\r\n-            response += \"**Processing Status:**\\n\"\r\n-            search_kwargs = {\"k\": 5, \"filter\": {\"tag\": selected_tag}}\r\n-            if 'lyrics' in message.lower():\r\n-                search_kwargs[\"filter\"][\"source_type\"] = \"lyrics\"\r\n-            dense_retriever = vectorstore.as_retriever(search_kwargs=search_kwargs)\r\n-            bm25_retriever = BM25Retriever.from_documents(vectorstore.similarity_search(\" \", k=vectorstore.index.ntotal))\r\n-            retriever = EnsembleRetriever(retrievers=[dense_retriever, bm25_retriever], weights=[0.7, 0.3])\r\n-\r\n-    if retriever is None:\r\n\\ No newline at end of file\n-        # Direct LLM call without retrieval\r\n-        qa_prompt = ChatPromptTemplate.from_template(\r\n-            \"Answer the question:\\n\\nQuestion: {input}\"\r\n-        )\r\n-        qa_chain = qa_prompt | llm\r\n-        answer = qa_chain.invoke({\"input\": message})\r\n-        response = f\"**Specific Answer:**\\n{answer}\\n\\n\"\r\n-        history[-1][\"content\"] = response\r\n-        yield history, \"\"\r\n-    else:\r\n-        if vectorstore.index.ntotal == 0:\r\n-            response += \"No relevant content in vectorstore.\\n\\n**Specific Answer:**\\nSorry, I couldn't find any information.\"\r\n-            history[-1][\"content\"] = response\r\n-            yield history, \"\"\r\n-            return\r\n-\r\n-        response += \"Creating/Updating vector store...\\n\"\r\n-        history[-1][\"content\"] = response\r\n-        yield history, \"\"\r\n-\r\n-        response += \"Vector store ready.\\n\\n\"\r\n-        history[-1][\"content\"] = response\r\n-        yield history, \"\"\r\n-\r\n-        response += \"Generating summarization of the found content...\\n\"\r\n-        history[-1][\"content\"] = response\r\n-        yield history, \"\"\r\n-\r\n-        summary_prompt = ChatPromptTemplate.from_template(\r\n-            \"Summarize the following retrieved content related to the question '{input}' in a concise manner:\\n\\n{context}\"\r\n-        )\r\n-        summary_chain = create_stuff_documents_chain(llm, summary_prompt)\r\n-        summary_chain_with_docs = create_retrieval_chain(retriever, summary_chain)\r\n-        summary_response = summary_chain_with_docs.invoke({\"input\": message})\r\n-        summary = summary_response[\"answer\"]\r\n-\r\n-        response += f\"**Summarization of Found Content:**\\n{summary}\\n\\n\"\r\n-        history[-1][\"content\"] = response\r\n-        yield history, \"\"\r\n-\r\n-        response += \"Generating specific answer to the prompt...\\n\"\r\n-        history[-1][\"content\"] = response\r\n-        yield history, \"\"\r\n-\r\n-        rephrase_prompt = ChatPromptTemplate.from_messages(\r\n-            [\r\n-                MessagesPlaceholder(variable_name=\"chat_history\"),\r\n-                (\"human\", \"{input}\"),\r\n-                (\"human\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\"),\r\n-            ]\r\n-        )\r\n-        history_aware_retriever = create_history_aware_retriever(llm, retriever, rephrase_prompt)\r\n-\r\n-        qa_prompt = ChatPromptTemplate.from_template(\r\n-            \"Use the context to answer the question as accurately as possible. If lyrics are present, extract and format them clearly with verses, chorus, etc., and ignore non-lyric content like discussions. If uncertain or incomplete, note limitations but provide what's available:\\n\\n{context}\\n\\nQuestion: {input}\"\r\n-        )\r\n-        qa_chain = create_stuff_documents_chain(llm, qa_prompt)\r\n-        qa_chain_with_docs = create_retrieval_chain(history_aware_retriever, qa_chain)\r\n-        qa_response = qa_chain_with_docs.invoke({\"input\": message, \"chat_history\": chat_history})\r\n-        answer = qa_response[\"answer\"]\r\n-\r\n-        response += f\"**Specific Answer:**\\n{answer}\\n\\n\"\r\n-        history[-1][\"content\"] = response\r\n-        yield history, \"\"\r\n-\r\n-    if selected_source in [\"Web Search\", \"YouTube\"]:\r\n-        sources_str = \"\\n\".join([f\"- {url}\" for url in sources])\r\n-        response += f\"**Sources Crawled:**\\n{sources_str}\"\r\n-        history[-1][\"content\"] = response\r\n-        yield history, \"\"\r\n-\r\n-    print(\"chat_bot completed.\")\n+demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756876215046,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,19 +1,21 @@\n import os\r\n import gradio as gr\r\n-from db_utils import init_db, get_unique_tags\r\n+from db_utils import init_db\r\n from chat_utils import chat_bot\r\n from crawl_utils import start_crawl\r\n from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n-from config import MODEL_NAME, DEFAULT_CONTEXT_LENGTH, DEFAULT_BATCH_SIZE, DEFAULT_PRECISION\r\n+from config import MODEL_NAME\r\n \r\n conn = init_db()\r\n \r\n def update_dropdown(completed_crawls):\r\n     return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n \r\n-def update_embedding_dropdown():\r\n-    return gr.update(choices=get_unique_tags(conn))\r\n+def submit_chat(m, h, s):\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None)\r\n+    for chat_out, msg_out in gen:\r\n+        yield chat_out, msg_out\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n@@ -23,21 +25,17 @@\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n             source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n-            embedding_dropdown = gr.Dropdown(label=\"Select Saved Embedding (optional)\", choices=[], value=None, interactive=True)\r\n             refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n-            refresh_embeddings_btn = gr.Button(\"Refresh Embeddings\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            demo.load(update_embedding_dropdown, None, embedding_dropdown)\r\n             refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            refresh_embeddings_btn.click(update_embedding_dropdown, None, embedding_dropdown)\r\n-            submit_btn.click(lambda m, h, s, e: chat_bot(m, h, conn=conn, selected_source=s, selected_tag=e or next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None), [msg, chatbot, source_dropdown, embedding_dropdown], [chatbot, msg])\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n@@ -68,13 +66,5 @@\n             show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n             vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n             show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n \r\n-        with gr.Tab(\"Settings\"):\r\n-            context_length_slider = gr.Slider(minimum=512, maximum=131072, value=DEFAULT_CONTEXT_LENGTH, label=\"LLM Context Length (tokens)\")\r\n-            batch_size_slider = gr.Slider(minimum=1, maximum=4, value=DEFAULT_BATCH_SIZE, label=\"Batch Size\")\r\n-            precision_dropdown = gr.Dropdown([\"fp16\", \"bf16\", \"fp32\"], value=DEFAULT_PRECISION, label=\"Precision\")\r\n-            save_settings_btn = gr.Button(\"Save Settings\")\r\n-            settings_status = gr.Textbox(label=\"Settings Status\")\r\n-            save_settings_btn.click(lambda cl, bs, p: f\"Settings saved: Context {cl}, Batch {bs}, Precision {p}\", [context_length_slider, batch_size_slider, precision_dropdown], settings_status)\r\n-\r\n demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756876254807,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,70 @@\n+import os\r\n+import gradio as gr\r\n+from db_utils import init_db\r\n+from chat_utils import chat_bot\r\n+from crawl_utils import start_crawl\r\n+from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n+from config import MODEL_NAME\r\n+\r\n+conn = init_db()\r\n+\r\n+def update_dropdown(completed_crawls):\r\n+    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n+\r\n+def submit_chat(m, h, s):\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None)\r\n+    for chat_out, msg_out in gen:\r\n+        yield chat_out, msg_out\r\n+\r\n+with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n+    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n+    \r\n+    tasks_state = gr.State([])\r\n+    completed_crawls_state = gr.State([])\r\n+    \r\n+    with gr.Tabs():\r\n+        with gr.Tab(\"Chat\"):\r\n+            gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n+            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n+            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n+            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n+            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n+            with gr.Row():\r\n+                submit_btn = gr.Button(\"Submit\")\r\n+                clear = gr.Button(\"Clear\")\r\n+            demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n+            refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            clear.click(lambda: None, None, chatbot, queue=False)\r\n+            clear.click(lambda: \"\", None, msg, queue=False)\r\n+        \r\n+        with gr.Tab(\"Crawl Subreddit\"):\r\n+            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n+            timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            crawl_btn = gr.Button(\"Crawl\")\r\n+            status = gr.Textbox(label=\"Status\")\r\n+            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n+            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n+            with gr.Accordion(\"Task Detail\", open=False):\r\n+                task_id_input = gr.Number(label=\"Task ID\")\r\n+                view_detail_btn = gr.Button(\"View Detail\")\r\n+                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n+                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n+                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n+            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n+            refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n+            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n+        \r\n+        with gr.Tab(\"View Database\"):\r\n+            load_db_btn = gr.Button(\"Load Database Contents\")\r\n+            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n+            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n+            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n+        \r\n+        with gr.Tab(\"View Vector Store\"):\r\n+            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n+            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n+            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n+\r\n+demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756876616066,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -41,8 +41,10 @@\n         with gr.Tab(\"Crawl Subreddit\"):\r\n             subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n             timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            max_threads_input = gr.Number(label=\"Max Threads\", value=20)\r\n+            max_comments_input = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n             crawl_btn = gr.Button(\"Crawl\")\r\n             status = gr.Textbox(label=\"Status\")\r\n             refresh_btn = gr.Button(\"Refresh Tasks\")\r\n             tasks_df = gr.Dataframe(label=\"Tasks\")\r\n@@ -51,9 +53,9 @@\n                 view_detail_btn = gr.Button(\"View Detail\")\r\n                 detail_content = gr.Markdown(label=\"Scraped Content\")\r\n                 detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n                 detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n+            crawl_btn.click(lambda s, t, q, ts, cs, mt, mc: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn, max_threads=mt, max_comments=mc), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state, max_threads_input, max_comments_input], [status, tasks_state, completed_crawls_state])\r\n             refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n@@ -66,75 +68,5 @@\n             show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n             vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n             show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n \r\n-demo.queue(default_concurrency_limit=5).launch()\n-import os\r\n-import gradio as gr\r\n-from db_utils import init_db\r\n-from chat_utils import chat_bot\r\n-from crawl_utils import start_crawl\r\n-from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n-from config import MODEL_NAME\r\n-\r\n-conn = init_db()\r\n-\r\n-def update_dropdown(completed_crawls):\r\n-    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n-\r\n-def submit_chat(m, h, s):\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None)\r\n-    for chat_out, msg_out in gen:\r\n-        yield chat_out, msg_out\r\n-\r\n-with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n-    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n-    \r\n-    tasks_state = gr.State([])\r\n-    completed_crawls_state = gr.State([])\r\n-    \r\n-    with gr.Tabs():\r\n-        with gr.Tab(\"Chat\"):\r\n-            gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n-            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n-            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n-            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n-            with gr.Row():\r\n-                submit_btn = gr.Button(\"Submit\")\r\n-                clear = gr.Button(\"Clear\")\r\n-            demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n-            clear.click(lambda: None, None, chatbot, queue=False)\r\n-            clear.click(lambda: \"\", None, msg, queue=False)\r\n-        \r\n-        with gr.Tab(\"Crawl Subreddit\"):\r\n-            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n-            timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n-            crawl_btn = gr.Button(\"Crawl\")\r\n-            status = gr.Textbox(label=\"Status\")\r\n-            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n-            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n-            with gr.Accordion(\"Task Detail\", open=False):\r\n-                task_id_input = gr.Number(label=\"Task ID\")\r\n-                view_detail_btn = gr.Button(\"View Detail\")\r\n-                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n-                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n-                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n-            refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n-            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n-        \r\n-        with gr.Tab(\"View Database\"):\r\n-            load_db_btn = gr.Button(\"Load Database Contents\")\r\n-            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n-            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n-            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n-        \r\n-        with gr.Tab(\"View Vector Store\"):\r\n-            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n-            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n-            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n-\r\n demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756932188656,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,4 +1,5 @@\n+# main.py\r\n import os\r\n import gradio as gr\r\n from db_utils import init_db\r\n from chat_utils import chat_bot\r\n@@ -8,12 +9,19 @@\n \r\n conn = init_db()\r\n \r\n def update_dropdown(completed_crawls):\r\n-    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n+    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\", \"Reddit\", \"Subreddit\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n \r\n-def submit_chat(m, h, s):\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\"] else None)\r\n+def show_subreddit_inputs(selected_source):\r\n+    if selected_source == \"Subreddit\":\r\n+        return gr.update(visible=True), gr.update(visible=True)\r\n+    else:\r\n+        return gr.update(visible=False), gr.update(visible=False)\r\n+\r\n+def submit_chat(m, h, s, use_ollama, subr, timel):\r\n+    tag = next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\", \"Reddit\", \"Subreddit\"] else None\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag, use_ollama=use_ollama, selected_subreddit=subr, selected_timelimit=timel)\r\n     for chat_out, msg_out in gen:\r\n         yield chat_out, msg_out\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n@@ -25,23 +33,28 @@\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n             source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n+            with gr.Row(visible=False) as subreddit_row:\r\n+                subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\", value=\"\")\r\n+                timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_checkbox = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n             refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            source_dropdown.change(show_subreddit_inputs, source_dropdown, [subreddit_input, timelimit_input])\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown, use_ollama_checkbox, subreddit_input, timelimit_input], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Crawl Subreddit\"):\r\n-            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n-            timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            subreddit_input_crawl = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n+            timelimit_input_crawl = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n             max_threads_input = gr.Number(label=\"Max Threads\", value=20)\r\n             max_comments_input = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n             crawl_btn = gr.Button(\"Crawl\")\r\n@@ -53,9 +66,9 @@\n                 view_detail_btn = gr.Button(\"View Detail\")\r\n                 detail_content = gr.Markdown(label=\"Scraped Content\")\r\n                 detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n                 detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            crawl_btn.click(lambda s, t, q, ts, cs, mt, mc: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn, max_threads=mt, max_comments=mc), [subreddit_input, timelimit_input, query_input, tasks_state, completed_crawls_state, max_threads_input, max_comments_input], [status, tasks_state, completed_crawls_state])\r\n+            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input_crawl, timelimit_input_crawl, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n             refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n"
                },
                {
                    "date": 1756935155227,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,75 +2,94 @@\n import os\r\n import gradio as gr\r\n from db_utils import init_db\r\n from chat_utils import chat_bot\r\n-from crawl_utils import start_crawl\r\n+from web_utils import start_web_collection\r\n+from youtube_utils import start_youtube_collection\r\n+from reddit_utils import start_reddit_collection\r\n+from subreddit_utils import start_subreddit_collection\r\n from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n from config import MODEL_NAME\r\n \r\n conn = init_db()\r\n \r\n-def update_dropdown(completed_crawls):\r\n-    return gr.update(choices=[\"No RAG\", \"Web Search\", \"YouTube\", \"Reddit\", \"Subreddit\"] + [c['name'] for c in completed_crawls], value=\"No RAG\")\r\n+def update_dropdown(completed_collections):\r\n+    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\")\r\n \r\n def show_subreddit_inputs(selected_source):\r\n-    if selected_source == \"Subreddit\":\r\n-        return gr.update(visible=True), gr.update(visible=True)\r\n-    else:\r\n-        return gr.update(visible=False), gr.update(visible=False)\r\n+    return gr.update(visible=False), gr.update(visible=False)  # No longer needed\r\n \r\n-def submit_chat(m, h, s, use_ollama, subr, timel):\r\n-    tag = next((c['tag'] for c in completed_crawls_state.value if c['name'] == s), None) if s and s not in [\"Web Search\", \"No RAG\", \"YouTube\", \"Reddit\", \"Subreddit\"] else None\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag, use_ollama=use_ollama, selected_subreddit=subr, selected_timelimit=timel)\r\n+def submit_chat(m, h, s):\r\n+    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == s), None) if s != \"No RAG\" else None\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n     for chat_out, msg_out in gen:\r\n         yield chat_out, msg_out\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n-    tasks_state = gr.State([])\r\n-    completed_crawls_state = gr.State([])\r\n+    collection_tasks_state = gr.State([])\r\n+    completed_collections_state = gr.State([])\r\n     \r\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n-            gr.Markdown(\"\"\"**Instructions:** Select a source below to augment your query with data from that crawl. In your prompt, you can reference the source by asking questions about it (e.g., \"Based on the wallstreetbets data, what are the best stocks?\"). The bot will use the selected source's embeddings for RAG.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select Source (optional)\", choices=[], value=None, interactive=True)\r\n-            with gr.Row(visible=False) as subreddit_row:\r\n-                subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\", value=\"\")\r\n-                timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            use_ollama_checkbox = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n+            source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n             refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n-            demo.load(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            refresh_sources_btn.click(update_dropdown, completed_crawls_state, source_dropdown)\r\n-            source_dropdown.change(show_subreddit_inputs, source_dropdown, [subreddit_input, timelimit_input])\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown, use_ollama_checkbox, subreddit_input, timelimit_input], [chatbot, msg])\r\n+            demo.load(update_dropdown, completed_collections_state, source_dropdown)\r\n+            refresh_sources_btn.click(update_dropdown, completed_collections_state, source_dropdown)\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n-        with gr.Tab(\"Crawl Subreddit\"):\r\n-            subreddit_input_crawl = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n-            timelimit_input_crawl = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n-            max_threads_input = gr.Number(label=\"Max Threads\", value=20)\r\n-            max_comments_input = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n-            crawl_btn = gr.Button(\"Crawl\")\r\n-            status = gr.Textbox(label=\"Status\")\r\n+        with gr.Tab(\"Web Collection\"):\r\n+            query_input_web = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_web = gr.Button(\"Start Collection\")\r\n+            status_web = gr.Textbox(label=\"Status\")\r\n+            collect_btn_web.click(start_web_collection, [query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"YouTube Collection\"):\r\n+            query_input_yt = gr.Textbox(label=\"Search Query\")\r\n+            use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_yt = gr.Button(\"Start Collection\")\r\n+            status_yt = gr.Textbox(label=\"Status\")\r\n+            collect_btn_yt.click(start_youtube_collection, [query_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Reddit Collection\"):\r\n+            query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_reddit = gr.Button(\"Start Collection\")\r\n+            status_reddit = gr.Textbox(label=\"Status\")\r\n+            collect_btn_reddit.click(start_reddit_collection, [query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Subreddit Collection\"):\r\n+            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n+            timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_sub = gr.Button(\"Start Collection\")\r\n+            status_sub = gr.Textbox(label=\"Status\")\r\n             refresh_btn = gr.Button(\"Refresh Tasks\")\r\n             tasks_df = gr.Dataframe(label=\"Tasks\")\r\n             with gr.Accordion(\"Task Detail\", open=False):\r\n                 task_id_input = gr.Number(label=\"Task ID\")\r\n                 view_detail_btn = gr.Button(\"View Detail\")\r\n                 detail_content = gr.Markdown(label=\"Scraped Content\")\r\n                 detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n                 detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            crawl_btn.click(lambda s, t, q, ts, cs: start_crawl(s, t, q, ts, completed_crawls=cs, conn=conn), [subreddit_input_crawl, timelimit_input_crawl, query_input, tasks_state, completed_crawls_state], [status, tasks_state, completed_crawls_state])\r\n-            refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n-            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, tasks_state], [detail_content, detail_summary, detail_answer])\r\n+            collect_btn_sub.click(start_subreddit_collection, [subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+            refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n+            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n"
                },
                {
                    "date": 1756935794697,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -14,11 +14,8 @@\n \r\n def update_dropdown(completed_collections):\r\n     return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\")\r\n \r\n-def show_subreddit_inputs(selected_source):\r\n-    return gr.update(visible=False), gr.update(visible=False)  # No longer needed\r\n-\r\n def submit_chat(m, h, s):\r\n     tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == s), None) if s != \"No RAG\" else None\r\n     gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n     for chat_out, msg_out in gen:\r\n@@ -51,25 +48,25 @@\n             timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_web = gr.Button(\"Start Collection\")\r\n             status_web = gr.Textbox(label=\"Status\")\r\n-            collect_btn_web.click(start_web_collection, [query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_web.click(lambda q, tl, u, ts, cs: start_web_collection(q, tl, u, ts, cs, conn=conn), [query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"YouTube Collection\"):\r\n             query_input_yt = gr.Textbox(label=\"Search Query\")\r\n             use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_yt = gr.Button(\"Start Collection\")\r\n             status_yt = gr.Textbox(label=\"Status\")\r\n-            collect_btn_yt.click(start_youtube_collection, [query_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_yt.click(lambda q, u, ts, cs: start_youtube_collection(q, u, ts, cs, conn=conn), [query_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Reddit Collection\"):\r\n             query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n             timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n             collect_btn_reddit = gr.Button(\"Start Collection\")\r\n             status_reddit = gr.Textbox(label=\"Status\")\r\n-            collect_btn_reddit.click(start_reddit_collection, [query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_reddit.click(lambda q, tl, u, mc, ts, cs: start_reddit_collection(q, tl, u, mc, ts, cs, conn=conn), [query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Subreddit Collection\"):\r\n             subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n             timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n@@ -85,9 +82,9 @@\n                 view_detail_btn = gr.Button(\"View Detail\")\r\n                 detail_content = gr.Markdown(label=\"Scraped Content\")\r\n                 detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n                 detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            collect_btn_sub.click(start_subreddit_collection, [subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_sub.click(lambda s, tl, q, u, mc, ts, cs: start_subreddit_collection(s, tl, q, u, mc, ts, cs, conn=conn), [subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n             refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n"
                },
                {
                    "date": 1756936258170,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,25 +48,25 @@\n             timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_web = gr.Button(\"Start Collection\")\r\n             status_web = gr.Textbox(label=\"Status\")\r\n-            collect_btn_web.click(lambda q, tl, u, ts, cs: start_web_collection(q, tl, u, ts, cs, conn=conn), [query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_web.click(lambda q, tl, u, ts, cs: start_web_collection(q, tl, u, ts, cs), [query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"YouTube Collection\"):\r\n             query_input_yt = gr.Textbox(label=\"Search Query\")\r\n             use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_yt = gr.Button(\"Start Collection\")\r\n             status_yt = gr.Textbox(label=\"Status\")\r\n-            collect_btn_yt.click(lambda q, u, ts, cs: start_youtube_collection(q, u, ts, cs, conn=conn), [query_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_yt.click(lambda q, u, ts, cs: start_youtube_collection(q, u, ts, cs), [query_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Reddit Collection\"):\r\n             query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n             timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n             collect_btn_reddit = gr.Button(\"Start Collection\")\r\n             status_reddit = gr.Textbox(label=\"Status\")\r\n-            collect_btn_reddit.click(lambda q, tl, u, mc, ts, cs: start_reddit_collection(q, tl, u, mc, ts, cs, conn=conn), [query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_reddit.click(lambda q, tl, u, mc, ts, cs: start_reddit_collection(q, tl, u, mc, ts, cs), [query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Subreddit Collection\"):\r\n             subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n             timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n@@ -82,9 +82,9 @@\n                 view_detail_btn = gr.Button(\"View Detail\")\r\n                 detail_content = gr.Markdown(label=\"Scraped Content\")\r\n                 detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n                 detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            collect_btn_sub.click(lambda s, tl, q, u, mc, ts, cs: start_subreddit_collection(s, tl, q, u, mc, ts, cs, conn=conn), [subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_sub.click(lambda s, tl, q, u, mc, ts, cs: start_subreddit_collection(s, tl, q, u, mc, ts, cs), [subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n             refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n"
                },
                {
                    "date": 1756936639028,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,9 +6,9 @@\n from web_utils import start_web_collection\r\n from youtube_utils import start_youtube_collection\r\n from reddit_utils import start_reddit_collection\r\n from subreddit_utils import start_subreddit_collection\r\n-from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail\r\n+from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail, view_available_tags\r\n from config import MODEL_NAME\r\n \r\n conn = init_db()\r\n \r\n@@ -91,8 +91,11 @@\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n             chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n             load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n+            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n+            tags_output = gr.Markdown(label=\"Available Tags\")\r\n+            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n         \r\n         with gr.Tab(\"View Vector Store\"):\r\n             show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n             vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n"
                },
                {
                    "date": 1756937324692,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,8 +20,14 @@\n     gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n     for chat_out, msg_out in gen:\r\n         yield chat_out, msg_out\r\n \r\n+def toggle_youtube_inputs(mode):\r\n+    if mode == \"Search Query\":\r\n+        return gr.update(visible=True), gr.update(visible=False)\r\n+    else:\r\n+        return gr.update(visible=False), gr.update(visible=True)\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n@@ -51,13 +57,16 @@\n             status_web = gr.Textbox(label=\"Status\")\r\n             collect_btn_web.click(lambda q, tl, u, ts, cs: start_web_collection(q, tl, u, ts, cs), [query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"YouTube Collection\"):\r\n-            query_input_yt = gr.Textbox(label=\"Search Query\")\r\n+            mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n+            query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n+            urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n             use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_yt = gr.Button(\"Start Collection\")\r\n             status_yt = gr.Textbox(label=\"Status\")\r\n-            collect_btn_yt.click(lambda q, u, ts, cs: start_youtube_collection(q, u, ts, cs), [query_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+            mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n+            collect_btn_yt.click(lambda m, q, urls, u, ts, cs: start_youtube_collection(m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Reddit Collection\"):\r\n             query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n             timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n"
                },
                {
                    "date": 1756937969944,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,35 +49,39 @@\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Web Collection\"):\r\n+            name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             query_input_web = gr.Textbox(label=\"Search Query\")\r\n             timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_web = gr.Button(\"Start Collection\")\r\n             status_web = gr.Textbox(label=\"Status\")\r\n-            collect_btn_web.click(lambda q, tl, u, ts, cs: start_web_collection(q, tl, u, ts, cs), [query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"YouTube Collection\"):\r\n+            name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n             query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n             urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n             use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_yt = gr.Button(\"Start Collection\")\r\n             status_yt = gr.Textbox(label=\"Status\")\r\n             mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n-            collect_btn_yt.click(lambda m, q, urls, u, ts, cs: start_youtube_collection(m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Reddit Collection\"):\r\n+            name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n             timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n             collect_btn_reddit = gr.Button(\"Start Collection\")\r\n             status_reddit = gr.Textbox(label=\"Status\")\r\n-            collect_btn_reddit.click(lambda q, tl, u, mc, ts, cs: start_reddit_collection(q, tl, u, mc, ts, cs), [query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Subreddit Collection\"):\r\n+            name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n             timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n             use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n@@ -91,9 +95,9 @@\n                 view_detail_btn = gr.Button(\"View Detail\")\r\n                 detail_content = gr.Markdown(label=\"Scraped Content\")\r\n                 detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n                 detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            collect_btn_sub.click(lambda s, tl, q, u, mc, ts, cs: start_subreddit_collection(s, tl, q, u, mc, ts, cs), [subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n             refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n"
                },
                {
                    "date": 1756938464655,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,8 +26,14 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n+def refresh_youtube_status(tasks):\r\n+    for task in tasks:\r\n+        if task['type'] == 'youtube' and task['status'] == 'running':\r\n+            return task['message']\r\n+    return \"No active YouTube collection.\"\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n@@ -65,10 +71,12 @@\n             urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n             use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_yt = gr.Button(\"Start Collection\")\r\n             status_yt = gr.Textbox(label=\"Status\")\r\n+            refresh_status_yt = gr.Button(\"Refresh Status\")\r\n             mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n             collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+            refresh_status_yt.click(refresh_youtube_status, collection_tasks_state, status_yt)\r\n         \r\n         with gr.Tab(\"Reddit Collection\"):\r\n             name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n"
                },
                {
                    "date": 1756939012013,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,14 +26,8 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n-def refresh_youtube_status(tasks):\r\n-    for task in tasks:\r\n-        if task['type'] == 'youtube' and task['status'] == 'running':\r\n-            return task['message']\r\n-    return \"No active YouTube collection.\"\r\n-\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n@@ -71,12 +65,10 @@\n             urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n             use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_yt = gr.Button(\"Start Collection\")\r\n             status_yt = gr.Textbox(label=\"Status\")\r\n-            refresh_status_yt = gr.Button(\"Refresh Status\")\r\n             mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n             collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n-            refresh_status_yt.click(refresh_youtube_status, collection_tasks_state, status_yt)\r\n         \r\n         with gr.Tab(\"Reddit Collection\"):\r\n             name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n@@ -95,17 +87,19 @@\n             use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n             collect_btn_sub = gr.Button(\"Start Collection\")\r\n             status_sub = gr.Textbox(label=\"Status\")\r\n+            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Tasks\"):\r\n             refresh_btn = gr.Button(\"Refresh Tasks\")\r\n             tasks_df = gr.Dataframe(label=\"Tasks\")\r\n             with gr.Accordion(\"Task Detail\", open=False):\r\n                 task_id_input = gr.Number(label=\"Task ID\")\r\n                 view_detail_btn = gr.Button(\"View Detail\")\r\n                 detail_content = gr.Markdown(label=\"Scraped Content\")\r\n                 detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n                 detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n             refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n"
                },
                {
                    "date": 1756939357128,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,128 @@\n+# main.py\r\n+import os\r\n+import gradio as gr\r\n+from db_utils import init_db\r\n+from chat_utils import chat_bot\r\n+from web_utils import start_web_collection\r\n+from youtube_utils import start_youtube_collection\r\n+from reddit_utils import start_reddit_collection\r\n+from subreddit_utils import start_subreddit_collection\r\n+from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n+from config import MODEL_NAME\r\n+\r\n+conn = init_db()\r\n+\r\n+def update_dropdown(completed_collections):\r\n+    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\")\r\n+\r\n+def submit_chat(m, h, s):\r\n+    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == s), None) if s != \"No RAG\" else None\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n+    for chat_out, msg_out in gen:\r\n+        yield chat_out, msg_out\r\n+\r\n+def toggle_youtube_inputs(mode):\r\n+    if mode == \"Search Query\":\r\n+        return gr.update(visible=True), gr.update(visible=False)\r\n+    else:\r\n+        return gr.update(visible=False), gr.update(visible=True)\r\n+\r\n+with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n+    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n+    \r\n+    collection_tasks_state = gr.State([])\r\n+    completed_collections_state = gr.State([])\r\n+    \r\n+    with gr.Tabs():\r\n+        with gr.Tab(\"Chat\"):\r\n+            gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n+            source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n+            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n+            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n+            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n+            with gr.Row():\r\n+                submit_btn = gr.Button(\"Submit\")\r\n+                clear = gr.Button(\"Clear\")\r\n+            demo.load(update_dropdown, completed_collections_state, source_dropdown)\r\n+            refresh_sources_btn.click(update_dropdown, completed_collections_state, source_dropdown)\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            clear.click(lambda: None, None, chatbot, queue=False)\r\n+            clear.click(lambda: \"\", None, msg, queue=False)\r\n+        \r\n+        with gr.Tab(\"Web Collection\"):\r\n+            name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            query_input_web = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_web = gr.Button(\"Start Collection\")\r\n+            status_web = gr.Textbox(label=\"Status\")\r\n+            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"YouTube Collection\"):\r\n+            name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n+            query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n+            urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n+            use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_yt = gr.Button(\"Start Collection\")\r\n+            status_yt = gr.Textbox(label=\"Status\")\r\n+            mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n+            collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Reddit Collection\"):\r\n+            name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_reddit = gr.Button(\"Start Collection\")\r\n+            status_reddit = gr.Textbox(label=\"Status\")\r\n+            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Subreddit Collection\"):\r\n+            name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n+            timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_sub = gr.Button(\"Start Collection\")\r\n+            status_sub = gr.Textbox(label=\"Status\")\r\n+            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Tasks\"):\r\n+            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n+            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n+            with gr.Accordion(\"Task Detail\", open=False):\r\n+                task_id_input = gr.Number(label=\"Task ID\")\r\n+                view_detail_btn = gr.Button(\"View Detail\")\r\n+                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n+                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n+                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n+            refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n+            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n+        \r\n+        with gr.Tab(\"View Database\"):\r\n+            load_db_btn = gr.Button(\"Load Database Contents\")\r\n+            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n+            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n+            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n+            sql_query_input = gr.Textbox(label=\"Custom SQL Query (e.g., SELECT * FROM urls LIMIT 5)\")\r\n+            execute_query_btn = gr.Button(\"Execute Query\")\r\n+            query_output = gr.Markdown(label=\"Query Results\")\r\n+            query_error = gr.Textbox(label=\"Error\")\r\n+            execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n+            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n+            tags_output = gr.Markdown(label=\"Available Tags\")\r\n+            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n+        \r\n+        with gr.Tab(\"View Vector Store\"):\r\n+            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n+            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n+            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n+            similarity_query_input = gr.Textbox(label=\"Similarity Search Query\")\r\n+            similarity_search_btn = gr.Button(\"Perform Similarity Search\")\r\n+            similarity_results = gr.Markdown(label=\"Similarity Search Results\")\r\n+            similarity_search_btn.click(perform_similarity_search, similarity_query_input, similarity_results)\r\n+\r\n+demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756939649324,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,8 +6,9 @@\n from web_utils import start_web_collection\r\n from youtube_utils import start_youtube_collection\r\n from reddit_utils import start_reddit_collection\r\n from subreddit_utils import start_subreddit_collection\r\n+from file_utils import start_file_ingestion\r\n from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n from config import MODEL_NAME\r\n \r\n conn = init_db()\r\n@@ -89,8 +90,16 @@\n             collect_btn_sub = gr.Button(\"Start Collection\")\r\n             status_sub = gr.Textbox(label=\"Status\")\r\n             collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n         \r\n+        with gr.Tab(\"File Ingestion\"):\r\n+            name_input_file = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            file_upload = gr.File(label=\"Upload TXT or PDF file\", file_types=['.txt', '.pdf'], type=\"filepath\")\r\n+            use_ollama_file = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            ingest_btn = gr.Button(\"Start Ingestion\")\r\n+            status_file = gr.Textbox(label=\"Status\")\r\n+            ingest_btn.click(lambda n, fp, u, ts, cs: start_file_ingestion(n, fp, u, ts, cs), [name_input_file, file_upload, use_ollama_file, collection_tasks_state, completed_collections_state], [status_file, collection_tasks_state, completed_collections_state])\r\n+        \r\n         with gr.Tab(\"Tasks\"):\r\n             refresh_btn = gr.Button(\"Refresh Tasks\")\r\n             tasks_df = gr.Dataframe(label=\"Tasks\")\r\n             with gr.Accordion(\"Task Detail\", open=False):\r\n@@ -124,124 +133,5 @@\n             similarity_search_btn = gr.Button(\"Perform Similarity Search\")\r\n             similarity_results = gr.Markdown(label=\"Similarity Search Results\")\r\n             similarity_search_btn.click(perform_similarity_search, similarity_query_input, similarity_results)\r\n \r\n-demo.queue(default_concurrency_limit=5).launch()\n-# main.py\r\n-import os\r\n-import gradio as gr\r\n-from db_utils import init_db\r\n-from chat_utils import chat_bot\r\n-from web_utils import start_web_collection\r\n-from youtube_utils import start_youtube_collection\r\n-from reddit_utils import start_reddit_collection\r\n-from subreddit_utils import start_subreddit_collection\r\n-from view_utils import view_db, view_vectorstore, refresh_tasks, show_task_detail, view_available_tags\r\n-from config import MODEL_NAME\r\n-\r\n-conn = init_db()\r\n-\r\n-def update_dropdown(completed_collections):\r\n-    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\")\r\n-\r\n-def submit_chat(m, h, s):\r\n-    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == s), None) if s != \"No RAG\" else None\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n-    for chat_out, msg_out in gen:\r\n-        yield chat_out, msg_out\r\n-\r\n-def toggle_youtube_inputs(mode):\r\n-    if mode == \"Search Query\":\r\n-        return gr.update(visible=True), gr.update(visible=False)\r\n-    else:\r\n-        return gr.update(visible=False), gr.update(visible=True)\r\n-\r\n-with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n-    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n-    \r\n-    collection_tasks_state = gr.State([])\r\n-    completed_collections_state = gr.State([])\r\n-    \r\n-    with gr.Tabs():\r\n-        with gr.Tab(\"Chat\"):\r\n-            gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n-            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n-            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n-            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n-            with gr.Row():\r\n-                submit_btn = gr.Button(\"Submit\")\r\n-                clear = gr.Button(\"Clear\")\r\n-            demo.load(update_dropdown, completed_collections_state, source_dropdown)\r\n-            refresh_sources_btn.click(update_dropdown, completed_collections_state, source_dropdown)\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n-            clear.click(lambda: None, None, chatbot, queue=False)\r\n-            clear.click(lambda: \"\", None, msg, queue=False)\r\n-        \r\n-        with gr.Tab(\"Web Collection\"):\r\n-            name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            query_input_web = gr.Textbox(label=\"Search Query\")\r\n-            timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            collect_btn_web = gr.Button(\"Start Collection\")\r\n-            status_web = gr.Textbox(label=\"Status\")\r\n-            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"YouTube Collection\"):\r\n-            name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n-            query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n-            urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n-            use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            collect_btn_yt = gr.Button(\"Start Collection\")\r\n-            status_yt = gr.Textbox(label=\"Status\")\r\n-            mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n-            collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Reddit Collection\"):\r\n-            name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n-            timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n-            collect_btn_reddit = gr.Button(\"Start Collection\")\r\n-            status_reddit = gr.Textbox(label=\"Status\")\r\n-            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Subreddit Collection\"):\r\n-            name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n-            timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n-            use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n-            collect_btn_sub = gr.Button(\"Start Collection\")\r\n-            status_sub = gr.Textbox(label=\"Status\")\r\n-            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Tasks\"):\r\n-            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n-            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n-            with gr.Accordion(\"Task Detail\", open=False):\r\n-                task_id_input = gr.Number(label=\"Task ID\")\r\n-                view_detail_btn = gr.Button(\"View Detail\")\r\n-                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n-                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n-                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n-            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n-        \r\n-        with gr.Tab(\"View Database\"):\r\n-            load_db_btn = gr.Button(\"Load Database Contents\")\r\n-            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n-            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n-            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n-            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n-            tags_output = gr.Markdown(label=\"Available Tags\")\r\n-            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n-        \r\n-        with gr.Tab(\"View Vector Store\"):\r\n-            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n-            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n-            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n-\r\n demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756941847947,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,12 +13,14 @@\n \r\n conn = init_db()\r\n \r\n def update_dropdown(completed_collections):\r\n+    print(\"Completed collections:\", completed_collections)  # Debug print\r\n     return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\")\r\n \r\n def submit_chat(m, h, s):\r\n     tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == s), None) if s != \"No RAG\" else None\r\n+    print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n     gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n     for chat_out, msg_out in gen:\r\n         yield chat_out, msg_out\r\n \r\n"
                },
                {
                    "date": 1756942455924,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,8 +16,16 @@\n def update_dropdown(completed_collections):\r\n     print(\"Completed collections:\", completed_collections)  # Debug print\r\n     return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\")\r\n \r\n+def update_tags_dropdown():\r\n+    tags = view_available_tags()\r\n+    tag_list = tags.split(\"\\n\")[1:] if tags.startswith(\"**\") else []\r\n+    return gr.update(choices=tag_list)\r\n+\r\n+def insert_tag_into_prompt(msg, selected_tag):\r\n+    return msg + f\" [use tag: {selected_tag}]\"\r\n+\r\n def submit_chat(m, h, s):\r\n     tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == s), None) if s != \"No RAG\" else None\r\n     print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n     gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n@@ -40,15 +48,20 @@\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n             source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n             refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n+            tags_dropdown = gr.Dropdown(label=\"Available Tags (insert into prompt)\", choices=[], value=None, interactive=True)\r\n+            refresh_tags_btn = gr.Button(\"Refresh Tags\")\r\n+            insert_tag_btn = gr.Button(\"Insert Selected Tag into Prompt\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, completed_collections_state, source_dropdown)\r\n             refresh_sources_btn.click(update_dropdown, completed_collections_state, source_dropdown)\r\n+            refresh_tags_btn.click(update_tags_dropdown, outputs=tags_dropdown)\r\n+            insert_tag_btn.click(insert_tag_into_prompt, [msg, tags_dropdown], msg)\r\n             submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n"
                },
                {
                    "date": 1756942784884,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,139 @@\n+# main.py\r\n+import os\r\n+import gradio as gr\r\n+from db_utils import init_db\r\n+from chat_utils import chat_bot\r\n+from web_utils import start_web_collection\r\n+from youtube_utils import start_youtube_collection\r\n+from reddit_utils import start_reddit_collection\r\n+from subreddit_utils import start_subreddit_collection\r\n+from file_utils import start_file_ingestion\r\n+from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n+from config import MODEL_NAME\r\n+\r\n+conn = init_db()\r\n+\r\n+def update_dropdown(completed_collections):\r\n+    print(\"Completed collections:\", completed_collections)  # Debug print\r\n+    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\")\r\n+\r\n+def submit_chat(m, h, s):\r\n+    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == s), None) if s != \"No RAG\" else None\r\n+    print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n+    for chat_out, msg_out in gen:\r\n+        yield chat_out, msg_out\r\n+\r\n+def toggle_youtube_inputs(mode):\r\n+    if mode == \"Search Query\":\r\n+        return gr.update(visible=True), gr.update(visible=False)\r\n+    else:\r\n+        return gr.update(visible=False), gr.update(visible=True)\r\n+\r\n+with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n+    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n+    \r\n+    collection_tasks_state = gr.State([])\r\n+    completed_collections_state = gr.State([])\r\n+    \r\n+    with gr.Tabs():\r\n+        with gr.Tab(\"Chat\"):\r\n+            gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n+            source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n+            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n+            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n+            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n+            with gr.Row():\r\n+                submit_btn = gr.Button(\"Submit\")\r\n+                clear = gr.Button(\"Clear\")\r\n+            demo.load(update_dropdown, completed_collections_state, source_dropdown)\r\n+            refresh_sources_btn.click(update_dropdown, completed_collections_state, source_dropdown)\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            clear.click(lambda: None, None, chatbot, queue=False)\r\n+            clear.click(lambda: \"\", None, msg, queue=False)\r\n+        \r\n+        with gr.Tab(\"Web Collection\"):\r\n+            name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            query_input_web = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_web = gr.Button(\"Start Collection\")\r\n+            status_web = gr.Textbox(label=\"Status\")\r\n+            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"YouTube Collection\"):\r\n+            name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n+            query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n+            urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n+            use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_yt = gr.Button(\"Start Collection\")\r\n+            status_yt = gr.Textbox(label=\"Status\")\r\n+            mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n+            collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Reddit Collection\"):\r\n+            name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_reddit = gr.Button(\"Start Collection\")\r\n+            status_reddit = gr.Textbox(label=\"Status\")\r\n+            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Subreddit Collection\"):\r\n+            name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n+            timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_sub = gr.Button(\"Start Collection\")\r\n+            status_sub = gr.Textbox(label=\"Status\")\r\n+            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"File Ingestion\"):\r\n+            name_input_file = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            file_upload = gr.File(label=\"Upload TXT or PDF file\", file_types=['.txt', '.pdf'], type=\"filepath\")\r\n+            use_ollama_file = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            ingest_btn = gr.Button(\"Start Ingestion\")\r\n+            status_file = gr.Textbox(label=\"Status\")\r\n+            ingest_btn.click(lambda n, fp, u, ts, cs: start_file_ingestion(n, fp, u, ts, cs), [name_input_file, file_upload, use_ollama_file, collection_tasks_state, completed_collections_state], [status_file, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Tasks\"):\r\n+            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n+            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n+            with gr.Accordion(\"Task Detail\", open=False):\r\n+                task_id_input = gr.Number(label=\"Task ID\")\r\n+                view_detail_btn = gr.Button(\"View Detail\")\r\n+                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n+                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n+                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n+            refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n+            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n+        \r\n+        with gr.Tab(\"View Database\"):\r\n+            load_db_btn = gr.Button(\"Load Database Contents\")\r\n+            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n+            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n+            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n+            sql_query_input = gr.Textbox(label=\"Custom SQL Query (e.g., SELECT * FROM urls LIMIT 5)\")\r\n+            execute_query_btn = gr.Button(\"Execute Query\")\r\n+            query_output = gr.Markdown(label=\"Query Results\")\r\n+            query_error = gr.Textbox(label=\"Error\")\r\n+            execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n+            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n+            tags_output = gr.Markdown(label=\"Available Tags\")\r\n+            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n+        \r\n+        with gr.Tab(\"View Vector Store\"):\r\n+            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n+            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n+            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n+            similarity_query_input = gr.Textbox(label=\"Similarity Search Query\")\r\n+            similarity_search_btn = gr.Button(\"Perform Similarity Search\")\r\n+            similarity_results = gr.Markdown(label=\"Similarity Search Results\")\r\n+            similarity_search_btn.click(perform_similarity_search, similarity_query_input, similarity_results)\r\n+\r\n+demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756944589820,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n # main.py\r\n import os\r\n import gradio as gr\r\n-from db_utils import init_db\r\n+from db_utils import init_db, get_collections\r\n from chat_utils import chat_bot\r\n from web_utils import start_web_collection\r\n from youtube_utils import start_youtube_collection\r\n from reddit_utils import start_reddit_collection\r\n@@ -12,161 +12,18 @@\n from config import MODEL_NAME\r\n \r\n conn = init_db()\r\n \r\n-def update_dropdown(completed_collections):\r\n-    print(\"Completed collections:\", completed_collections)  # Debug print\r\n-    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\")\r\n+def load_completed_collections():\r\n+    return get_collections(conn)\r\n \r\n-def submit_chat(m, h, s):\r\n-    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == s), None) if s != \"No RAG\" else None\r\n-    print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n-    for chat_out, msg_out in gen:\r\n-        yield chat_out, msg_out\r\n+def update_dropdown():\r\n+    completed_collections = load_completed_collections()\r\n+    print(\"Loaded collections:\", completed_collections)  # Debug\r\n+    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\"), completed_collections\r\n \r\n-def toggle_youtube_inputs(mode):\r\n-    if mode == \"Search Query\":\r\n-        return gr.update(visible=True), gr.update(visible=False)\r\n-    else:\r\n-        return gr.update(visible=False), gr.update(visible=True)\r\n-\r\n-with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n-    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n-    \r\n-    collection_tasks_state = gr.State([])\r\n-    completed_collections_state = gr.State([])\r\n-    \r\n-    with gr.Tabs():\r\n-        with gr.Tab(\"Chat\"):\r\n-            gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n-            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n-            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n-            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n-            with gr.Row():\r\n-                submit_btn = gr.Button(\"Submit\")\r\n-                clear = gr.Button(\"Clear\")\r\n-            demo.load(update_dropdown, completed_collections_state, source_dropdown)\r\n-            refresh_sources_btn.click(update_dropdown, completed_collections_state, source_dropdown)\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n-            clear.click(lambda: None, None, chatbot, queue=False)\r\n-            clear.click(lambda: \"\", None, msg, queue=False)\r\n-        \r\n-        with gr.Tab(\"Web Collection\"):\r\n-            name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            query_input_web = gr.Textbox(label=\"Search Query\")\r\n-            timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            collect_btn_web = gr.Button(\"Start Collection\")\r\n-            status_web = gr.Textbox(label=\"Status\")\r\n-            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"YouTube Collection\"):\r\n-            name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n-            query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n-            urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n-            use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            collect_btn_yt = gr.Button(\"Start Collection\")\r\n-            status_yt = gr.Textbox(label=\"Status\")\r\n-            mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n-            collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Reddit Collection\"):\r\n-            name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n-            timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n-            collect_btn_reddit = gr.Button(\"Start Collection\")\r\n-            status_reddit = gr.Textbox(label=\"Status\")\r\n-            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Subreddit Collection\"):\r\n-            name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n-            timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n-            use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n-            collect_btn_sub = gr.Button(\"Start Collection\")\r\n-            status_sub = gr.Textbox(label=\"Status\")\r\n-            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"File Ingestion\"):\r\n-            name_input_file = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            file_upload = gr.File(label=\"Upload TXT or PDF file\", file_types=['.txt', '.pdf'], type=\"filepath\")\r\n-            use_ollama_file = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            ingest_btn = gr.Button(\"Start Ingestion\")\r\n-            status_file = gr.Textbox(label=\"Status\")\r\n-            ingest_btn.click(lambda n, fp, u, ts, cs: start_file_ingestion(n, fp, u, ts, cs), [name_input_file, file_upload, use_ollama_file, collection_tasks_state, completed_collections_state], [status_file, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Tasks\"):\r\n-            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n-            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n-            with gr.Accordion(\"Task Detail\", open=False):\r\n-                task_id_input = gr.Number(label=\"Task ID\")\r\n-                view_detail_btn = gr.Button(\"View Detail\")\r\n-                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n-                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n-                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n-            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n-        \r\n-        with gr.Tab(\"View Database\"):\r\n-            load_db_btn = gr.Button(\"Load Database Contents\")\r\n-            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n-            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n-            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n-            sql_query_input = gr.Textbox(label=\"Custom SQL Query (e.g., SELECT * FROM urls LIMIT 5)\")\r\n-            execute_query_btn = gr.Button(\"Execute Query\")\r\n-            query_output = gr.Markdown(label=\"Query Results\")\r\n-            query_error = gr.Textbox(label=\"Error\")\r\n-            execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n-            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n-            tags_output = gr.Markdown(label=\"Available Tags\")\r\n-            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n-        \r\n-        with gr.Tab(\"View Vector Store\"):\r\n-            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n-            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n-            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n-            similarity_query_input = gr.Textbox(label=\"Similarity Search Query\")\r\n-            similarity_search_btn = gr.Button(\"Perform Similarity Search\")\r\n-            similarity_results = gr.Markdown(label=\"Similarity Search Results\")\r\n-            similarity_search_btn.click(perform_similarity_search, similarity_query_input, similarity_results)\r\n-\r\n-demo.queue(default_concurrency_limit=5).launch()\n-# main.py\r\n-import os\r\n-import gradio as gr\r\n-from db_utils import init_db\r\n-from chat_utils import chat_bot\r\n-from web_utils import start_web_collection\r\n-from youtube_utils import start_youtube_collection\r\n-from reddit_utils import start_reddit_collection\r\n-from subreddit_utils import start_subreddit_collection\r\n-from file_utils import start_file_ingestion\r\n-from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n-from config import MODEL_NAME\r\n-\r\n-conn = init_db()\r\n-\r\n-def update_dropdown(completed_collections):\r\n-    print(\"Completed collections:\", completed_collections)  # Debug print\r\n-    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\")\r\n-\r\n-def update_tags_dropdown():\r\n-    tags = view_available_tags()\r\n-    tag_list = tags.split(\"\\n\")[1:] if tags.startswith(\"**\") else []\r\n-    return gr.update(choices=tag_list)\r\n-\r\n-def insert_tag_into_prompt(msg, selected_tag):\r\n-    return msg + f\" [use tag: {selected_tag}]\"\r\n-\r\n-def submit_chat(m, h, s):\r\n-    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == s), None) if s != \"No RAG\" else None\r\n+def submit_chat(m, h, s, completed_collections):\r\n+    tag = next((c['tag'] for c in completed_collections if c['name'] == s), None) if s != \"No RAG\" else None\r\n     print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n     gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n     for chat_out, msg_out in gen:\r\n         yield chat_out, msg_out\r\n@@ -180,28 +37,23 @@\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n-    completed_collections_state = gr.State([])\r\n+    completed_collections_state = gr.State(load_completed_collections())\r\n     \r\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n             source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n             refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n-            tags_dropdown = gr.Dropdown(label=\"Available Tags (insert into prompt)\", choices=[], value=None, interactive=True)\r\n-            refresh_tags_btn = gr.Button(\"Refresh Tags\")\r\n-            insert_tag_btn = gr.Button(\"Insert Selected Tag into Prompt\")\r\n             chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n             msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n             with gr.Row():\r\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n-            demo.load(update_dropdown, completed_collections_state, source_dropdown)\r\n-            refresh_sources_btn.click(update_dropdown, completed_collections_state, source_dropdown)\r\n-            refresh_tags_btn.click(update_tags_dropdown, outputs=tags_dropdown)\r\n-            insert_tag_btn.click(insert_tag_into_prompt, [msg, tags_dropdown], msg)\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown], [chatbot, msg])\r\n+            demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n+            refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n+            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs.value), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Web Collection\"):\r\n"
                },
                {
                    "date": 1756946856813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,8 +9,9 @@\n from subreddit_utils import start_subreddit_collection\r\n from file_utils import start_file_ingestion\r\n from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n from config import MODEL_NAME\r\n+import threading\r\n \r\n conn = init_db()\r\n \r\n def load_completed_collections():\r\n@@ -33,13 +34,24 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n+def cancel_task(task_id, tasks):\r\n+    if task_id < 0 or task_id >= len(tasks):\r\n+        return \"Invalid task ID\"\r\n+    task = tasks[task_id]\r\n+    if 'event' in task and task['status'] == 'running':\r\n+        task['event'].set()\r\n+        task['status'] = 'cancelled'\r\n+        task['message'] = \"Task cancelled by user.\"\r\n+        return \"Task cancelled.\"\r\n+    return \"Task not running or cannot be cancelled.\"\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n-    completed_collections_state = gr.State(load_completed_collections())\r\n+    completed_collections_state = gr.State([])\r\n     \r\n     with gr.Tabs():\r\n         with gr.Tab(\"Chat\"):\r\n             gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n@@ -117,8 +129,11 @@\n             refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n+            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n+            tags_output = gr.Markdown(label=\"Available Tags\")\r\n+            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n             chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n             load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n@@ -126,11 +141,8 @@\n             execute_query_btn = gr.Button(\"Execute Query\")\r\n             query_output = gr.Markdown(label=\"Query Results\")\r\n             query_error = gr.Textbox(label=\"Error\")\r\n             execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n-            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n-            tags_output = gr.Markdown(label=\"Available Tags\")\r\n-            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n         \r\n         with gr.Tab(\"View Vector Store\"):\r\n             show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n             vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n"
                },
                {
                    "date": 1756950408613,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,9 +9,9 @@\n from subreddit_utils import start_subreddit_collection\r\n from file_utils import start_file_ingestion\r\n from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n from config import MODEL_NAME\r\n-import threading\r\n+from db_utils import rename_collection, delete_collection\r\n \r\n conn = init_db()\r\n \r\n def load_completed_collections():\r\n@@ -34,19 +34,31 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n-def cancel_task(task_id, tasks):\r\n-    if task_id < 0 or task_id >= len(tasks):\r\n-        return \"Invalid task ID\"\r\n-    task = tasks[task_id]\r\n-    if 'event' in task and task['status'] == 'running':\r\n-        task['event'].set()\r\n-        task['status'] = 'cancelled'\r\n-        task['message'] = \"Task cancelled by user.\"\r\n-        return \"Task cancelled.\"\r\n-    return \"Task not running or cannot be cancelled.\"\r\n+def load_data_source_details(selected_source, completed_collections):\r\n+    if selected_source == \"No RAG\":\r\n+        return \"\", \"\"\r\n+    tag = next((c['tag'] for c in completed_collections if c['name'] == selected_source), None)\r\n+    if tag:\r\n+        df_chunks = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n+        return selected_source, df_chunks\r\n+    return \"\", pd.DataFrame()\r\n \r\n+def rename_data_source(old_name, new_name):\r\n+    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == old_name), None)\r\n+    if tag:\r\n+        rename_collection(conn, old_name, new_name)\r\n+        return \"Renamed successfully. Refresh sources.\"\r\n+    return \"Error renaming.\"\r\n+\r\n+def delete_data_source(name):\r\n+    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == name), None)\r\n+    if tag:\r\n+        delete_collection(conn, name, tag)\r\n+        return \"Deleted successfully. Refresh sources.\"\r\n+    return \"Error deleting.\"\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n@@ -129,11 +141,8 @@\n             refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n-            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n-            tags_output = gr.Markdown(label=\"Available Tags\")\r\n-            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n             chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n             load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n@@ -141,8 +150,11 @@\n             execute_query_btn = gr.Button(\"Execute Query\")\r\n             query_output = gr.Markdown(label=\"Query Results\")\r\n             query_error = gr.Textbox(label=\"Error\")\r\n             execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n+            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n+            tags_output = gr.Markdown(label=\"Available Tags\")\r\n+            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n         \r\n         with gr.Tab(\"View Vector Store\"):\r\n             show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n             vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n"
                },
                {
                    "date": 1756950621271,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,9 +9,9 @@\n from subreddit_utils import start_subreddit_collection\r\n from file_utils import start_file_ingestion\r\n from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n from config import MODEL_NAME\r\n-from db_utils import rename_collection, delete_collection\r\n+import pandas as pd\r\n \r\n conn = init_db()\r\n \r\n def load_completed_collections():\r\n@@ -34,31 +34,8 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n-def load_data_source_details(selected_source, completed_collections):\r\n-    if selected_source == \"No RAG\":\r\n-        return \"\", \"\"\r\n-    tag = next((c['tag'] for c in completed_collections if c['name'] == selected_source), None)\r\n-    if tag:\r\n-        df_chunks = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n-        return selected_source, df_chunks\r\n-    return \"\", pd.DataFrame()\r\n-\r\n-def rename_data_source(old_name, new_name):\r\n-    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == old_name), None)\r\n-    if tag:\r\n-        rename_collection(conn, old_name, new_name)\r\n-        return \"Renamed successfully. Refresh sources.\"\r\n-    return \"Error renaming.\"\r\n-\r\n-def delete_data_source(name):\r\n-    tag = next((c['tag'] for c in completed_collections_state.value if c['name'] == name), None)\r\n-    if tag:\r\n-        delete_collection(conn, name, tag)\r\n-        return \"Deleted successfully. Refresh sources.\"\r\n-    return \"Error deleting.\"\r\n-\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n"
                },
                {
                    "date": 1756950896250,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,186 @@\n+# main.py\r\n+import os\r\n+import gradio as gr\r\n+from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n+from chat_utils import chat_bot\r\n+from web_utils import start_web_collection\r\n+from youtube_utils import start_youtube_collection\r\n+from reddit_utils import start_reddit_collection\r\n+from subreddit_utils import start_subreddit_collection\r\n+from file_utils import start_file_ingestion\r\n+from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n+from config import MODEL_NAME\r\n+import pandas as pd\r\n+\r\n+conn = init_db()\r\n+\r\n+def load_completed_collections():\r\n+    return get_collections(conn)\r\n+\r\n+def update_dropdown():\r\n+    completed_collections = load_completed_collections()\r\n+    print(\"Loaded collections:\", completed_collections)  # Debug\r\n+    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\"), completed_collections\r\n+\r\n+def submit_chat(m, h, s, completed_collections):\r\n+    tag = next((c['tag'] for c in completed_collections if c['name'] == s), None) if s != \"No RAG\" else None\r\n+    print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n+    for chat_out, msg_out in gen:\r\n+        yield chat_out, msg_out\r\n+\r\n+def toggle_youtube_inputs(mode):\r\n+    if mode == \"Search Query\":\r\n+        return gr.update(visible=True), gr.update(visible=False)\r\n+    else:\r\n+        return gr.update(visible=False), gr.update(visible=True)\r\n+\r\n+def load_data_sources():\r\n+    collections = load_completed_collections()\r\n+    df = pd.DataFrame(collections)\r\n+    return df\r\n+\r\n+def select_data_source(selected_index, collections):\r\n+    if selected_index is None:\r\n+        return \"\", pd.DataFrame()\r\n+    name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n+    return name, chunks_df\r\n+\r\n+def rename_data_source(selected_index, new_name, collections):\r\n+    if selected_index is None:\r\n+        return \"No source selected\", collections\r\n+    old_name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    rename_collection(conn, old_name, new_name)\r\n+    collections[selected_index]['name'] = new_name\r\n+    return \"Renamed successfully. Refresh to see changes.\", collections\r\n+\r\n+def confirm_delete_data_source(selected_index, collections):\r\n+    if selected_index is None:\r\n+        return \"No source selected\"\r\n+    name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    delete_collection(conn, name, tag)\r\n+    del collections[selected_index]\r\n+    return \"Deleted successfully. Refresh to see changes.\", collections\r\n+\r\n+with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n+    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n+    \r\n+    collection_tasks_state = gr.State([])\r\n+    completed_collections_state = gr.State([])\r\n+    \r\n+    with gr.Tabs():\r\n+        with gr.Tab(\"Chat\"):\r\n+            gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n+            source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n+            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n+            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n+            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n+            with gr.Row():\r\n+                submit_btn = gr.Button(\"Submit\")\r\n+                clear = gr.Button(\"Clear\")\r\n+            demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n+            refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n+            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs.value), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n+            clear.click(lambda: None, None, chatbot, queue=False)\r\n+            clear.click(lambda: \"\", None, msg, queue=False)\r\n+        \r\n+        with gr.Tab(\"Web Collection\"):\r\n+            name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            query_input_web = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_web = gr.Button(\"Start Collection\")\r\n+            status_web = gr.Textbox(label=\"Status\")\r\n+            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"YouTube Collection\"):\r\n+            name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n+            query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n+            urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n+            use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_yt = gr.Button(\"Start Collection\")\r\n+            status_yt = gr.Textbox(label=\"Status\")\r\n+            mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n+            collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Reddit Collection\"):\r\n+            name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_reddit = gr.Button(\"Start Collection\")\r\n+            status_reddit = gr.Textbox(label=\"Status\")\r\n+            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Subreddit Collection\"):\r\n+            name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n+            timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_sub = gr.Button(\"Start Collection\")\r\n+            status_sub = gr.Textbox(label=\"Status\")\r\n+            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"File Ingestion\"):\r\n+            name_input_file = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            file_upload = gr.File(label=\"Upload TXT or PDF file\", file_types=['.txt', '.pdf'], type=\"filepath\")\r\n+            use_ollama_file = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            ingest_btn = gr.Button(\"Start Ingestion\")\r\n+            status_file = gr.Textbox(label=\"Status\")\r\n+            ingest_btn.click(lambda n, fp, u, ts, cs: start_file_ingestion(n, fp, u, ts, cs), [name_input_file, file_upload, use_ollama_file, collection_tasks_state, completed_collections_state], [status_file, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Tasks\"):\r\n+            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n+            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n+            with gr.Accordion(\"Task Detail\", open=False):\r\n+                task_id_input = gr.Number(label=\"Task ID\")\r\n+                view_detail_btn = gr.Button(\"View Detail\")\r\n+                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n+                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n+                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n+            refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n+            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n+        \r\n+        with gr.Tab(\"View Database\"):\r\n+            sources_df = gr.Dataframe(label=\"Available Data Sources\", interactive=False)\r\n+            load_sources_btn = gr.Button(\"Load Data Sources\")\r\n+            selected_source = gr.State(None)\r\n+            selected_source_text = gr.Textbox(label=\"Selected Data Source\", interactive=False)\r\n+            source_contents_df = gr.Dataframe(label=\"Data Source Contents\")\r\n+            new_name_input = gr.Textbox(label=\"New Name for Selected Source\")\r\n+            rename_btn = gr.Button(\"Rename Selected Source\")\r\n+            delete_btn = gr.Button(\"Delete Selected Source (Confirm)\")\r\n+            delete_confirm = gr.Checkbox(label=\"Confirm Deletion\", value=False)\r\n+            load_sources_btn.click(load_data_sources, outputs=sources_df)\r\n+            sources_df.change(select_data_source, [sources_df, completed_collections_state], [selected_source_text, source_contents_df])\r\n+            rename_btn.click(lambda idx, new_name, cs: rename_data_source(idx, new_name, cs.value), [sources_df, new_name_input, completed_collections_state], outputs=rename_status)\r\n+            delete_btn.click(lambda idx, confirm, cs: confirm_delete_data_source(idx, confirm, cs.value) if confirm else \"Please confirm deletion.\", [sources_df, delete_confirm, completed_collections_state], outputs=delete_status)\r\n+        \r\n+        with gr.Tab(\"Admin\"):\r\n+            # Moved advanced features here\r\n+            load_db_btn = gr.Button(\"Load Database Contents\")\r\n+            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n+            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n+            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n+            sql_query_input = gr.Textbox(label=\"Custom SQL Query (e.g., SELECT * FROM urls LIMIT 5)\")\r\n+            execute_query_btn = gr.Button(\"Execute Query\")\r\n+            query_output = gr.Markdown(label=\"Query Results\")\r\n+            query_error = gr.Textbox(label=\"Error\")\r\n+            execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n+            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n+            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n+            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n+            similarity_query_input = gr.Textbox(label=\"Similarity Search Query\")\r\n+            similarity_search_btn = gr.Button(\"Perform Similarity Search\")\r\n+            similarity_results = gr.Markdown(label=\"Similarity Search Results\")\r\n+            similarity_search_btn.click(perform_similarity_search, similarity_query_input, similarity_results)\r\n+\r\n+demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756951128023,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,23 +49,23 @@\n     return name, chunks_df\r\n \r\n def rename_data_source(selected_index, new_name, collections):\r\n     if selected_index is None:\r\n-        return \"No source selected\", collections\r\n+        return \"No source selected\"\r\n     old_name = collections[selected_index]['name']\r\n     tag = collections[selected_index]['tag']\r\n     rename_collection(conn, old_name, new_name)\r\n     collections[selected_index]['name'] = new_name\r\n-    return \"Renamed successfully. Refresh to see changes.\", collections\r\n+    return \"Renamed successfully. Refresh to see changes.\"\r\n \r\n def confirm_delete_data_source(selected_index, collections):\r\n     if selected_index is None:\r\n         return \"No source selected\"\r\n     name = collections[selected_index]['name']\r\n     tag = collections[selected_index]['tag']\r\n     delete_collection(conn, name, tag)\r\n     del collections[selected_index]\r\n-    return \"Deleted successfully. Refresh to see changes.\", collections\r\n+    return \"Deleted successfully. Refresh to see changes.\"\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n@@ -149,21 +149,22 @@\n             refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n-            sources_df = gr.Dataframe(label=\"Available Data Sources\", interactive=False)\r\n+            sources_df = gr.Dataframe(label=\"Available Data Sources\", interactive=True)\r\n             load_sources_btn = gr.Button(\"Load Data Sources\")\r\n-            selected_source = gr.State(None)\r\n-            selected_source_text = gr.Textbox(label=\"Selected Data Source\", interactive=False)\r\n+            selected_source = gr.Textbox(label=\"Selected Data Source\", interactive=False)\r\n             source_contents_df = gr.Dataframe(label=\"Data Source Contents\")\r\n             new_name_input = gr.Textbox(label=\"New Name for Selected Source\")\r\n             rename_btn = gr.Button(\"Rename Selected Source\")\r\n-            delete_btn = gr.Button(\"Delete Selected Source (Confirm)\")\r\n-            delete_confirm = gr.Checkbox(label=\"Confirm Deletion\", value=False)\r\n+            rename_status = gr.Textbox(label=\"Rename Status\")\r\n+            delete_btn = gr.Button(\"Delete Selected Source\")\r\n+            delete_confirm = gr.Checkbox(label=\"Confirm Deletion\")\r\n+            delete_status = gr.Textbox(label=\"Delete Status\")\r\n             load_sources_btn.click(load_data_sources, outputs=sources_df)\r\n-            sources_df.change(select_data_source, [sources_df, completed_collections_state], [selected_source_text, source_contents_df])\r\n-            rename_btn.click(lambda idx, new_name, cs: rename_data_source(idx, new_name, cs.value), [sources_df, new_name_input, completed_collections_state], outputs=rename_status)\r\n-            delete_btn.click(lambda idx, confirm, cs: confirm_delete_data_source(idx, confirm, cs.value) if confirm else \"Please confirm deletion.\", [sources_df, delete_confirm, completed_collections_state], outputs=delete_status)\r\n+            sources_df.change(select_data_source, [sources_df, completed_collections_state], [selected_source, source_contents_df])\r\n+            rename_btn.click(lambda idx, new_name, cs: rename_data_source(idx, new_name, cs.value), [sources_df, new_name_input, completed_collections_state], rename_status)\r\n+            delete_btn.click(lambda idx, confirm, cs: confirm_delete_data_source(idx, confirm, cs.value) if confirm else \"Please confirm deletion.\", [sources_df, delete_confirm, completed_collections_state], delete_status)\r\n         \r\n         with gr.Tab(\"Admin\"):\r\n             # Moved advanced features here\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n@@ -182,149 +183,5 @@\n             similarity_search_btn = gr.Button(\"Perform Similarity Search\")\r\n             similarity_results = gr.Markdown(label=\"Similarity Search Results\")\r\n             similarity_search_btn.click(perform_similarity_search, similarity_query_input, similarity_results)\r\n \r\n-demo.queue(default_concurrency_limit=5).launch()\n-# main.py\r\n-import os\r\n-import gradio as gr\r\n-from db_utils import init_db, get_collections\r\n-from chat_utils import chat_bot\r\n-from web_utils import start_web_collection\r\n-from youtube_utils import start_youtube_collection\r\n-from reddit_utils import start_reddit_collection\r\n-from subreddit_utils import start_subreddit_collection\r\n-from file_utils import start_file_ingestion\r\n-from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n-from config import MODEL_NAME\r\n-import pandas as pd\r\n-\r\n-conn = init_db()\r\n-\r\n-def load_completed_collections():\r\n-    return get_collections(conn)\r\n-\r\n-def update_dropdown():\r\n-    completed_collections = load_completed_collections()\r\n-    print(\"Loaded collections:\", completed_collections)  # Debug\r\n-    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\"), completed_collections\r\n-\r\n-def submit_chat(m, h, s, completed_collections):\r\n-    tag = next((c['tag'] for c in completed_collections if c['name'] == s), None) if s != \"No RAG\" else None\r\n-    print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n-    for chat_out, msg_out in gen:\r\n-        yield chat_out, msg_out\r\n-\r\n-def toggle_youtube_inputs(mode):\r\n-    if mode == \"Search Query\":\r\n-        return gr.update(visible=True), gr.update(visible=False)\r\n-    else:\r\n-        return gr.update(visible=False), gr.update(visible=True)\r\n-\r\n-with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n-    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n-    \r\n-    collection_tasks_state = gr.State([])\r\n-    completed_collections_state = gr.State([])\r\n-    \r\n-    with gr.Tabs():\r\n-        with gr.Tab(\"Chat\"):\r\n-            gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n-            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n-            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n-            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n-            with gr.Row():\r\n-                submit_btn = gr.Button(\"Submit\")\r\n-                clear = gr.Button(\"Clear\")\r\n-            demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs.value), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n-            clear.click(lambda: None, None, chatbot, queue=False)\r\n-            clear.click(lambda: \"\", None, msg, queue=False)\r\n-        \r\n-        with gr.Tab(\"Web Collection\"):\r\n-            name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            query_input_web = gr.Textbox(label=\"Search Query\")\r\n-            timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            collect_btn_web = gr.Button(\"Start Collection\")\r\n-            status_web = gr.Textbox(label=\"Status\")\r\n-            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"YouTube Collection\"):\r\n-            name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n-            query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n-            urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n-            use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            collect_btn_yt = gr.Button(\"Start Collection\")\r\n-            status_yt = gr.Textbox(label=\"Status\")\r\n-            mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n-            collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Reddit Collection\"):\r\n-            name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n-            timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n-            collect_btn_reddit = gr.Button(\"Start Collection\")\r\n-            status_reddit = gr.Textbox(label=\"Status\")\r\n-            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Subreddit Collection\"):\r\n-            name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n-            timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n-            use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n-            collect_btn_sub = gr.Button(\"Start Collection\")\r\n-            status_sub = gr.Textbox(label=\"Status\")\r\n-            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"File Ingestion\"):\r\n-            name_input_file = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            file_upload = gr.File(label=\"Upload TXT or PDF file\", file_types=['.txt', '.pdf'], type=\"filepath\")\r\n-            use_ollama_file = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            ingest_btn = gr.Button(\"Start Ingestion\")\r\n-            status_file = gr.Textbox(label=\"Status\")\r\n-            ingest_btn.click(lambda n, fp, u, ts, cs: start_file_ingestion(n, fp, u, ts, cs), [name_input_file, file_upload, use_ollama_file, collection_tasks_state, completed_collections_state], [status_file, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Tasks\"):\r\n-            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n-            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n-            with gr.Accordion(\"Task Detail\", open=False):\r\n-                task_id_input = gr.Number(label=\"Task ID\")\r\n-                view_detail_btn = gr.Button(\"View Detail\")\r\n-                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n-                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n-                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n-            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n-        \r\n-        with gr.Tab(\"View Database\"):\r\n-            load_db_btn = gr.Button(\"Load Database Contents\")\r\n-            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n-            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n-            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n-            sql_query_input = gr.Textbox(label=\"Custom SQL Query (e.g., SELECT * FROM urls LIMIT 5)\")\r\n-            execute_query_btn = gr.Button(\"Execute Query\")\r\n-            query_output = gr.Markdown(label=\"Query Results\")\r\n-            query_error = gr.Textbox(label=\"Error\")\r\n-            execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n-            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n-            tags_output = gr.Markdown(label=\"Available Tags\")\r\n-            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n-        \r\n-        with gr.Tab(\"View Vector Store\"):\r\n-            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n-            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n-            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n-            similarity_query_input = gr.Textbox(label=\"Similarity Search Query\")\r\n-            similarity_search_btn = gr.Button(\"Perform Similarity Search\")\r\n-            similarity_results = gr.Markdown(label=\"Similarity Search Results\")\r\n-            similarity_search_btn.click(perform_similarity_search, similarity_query_input, similarity_results)\r\n-\r\n demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756951424288,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n # main.py\r\n import os\r\n import gradio as gr\r\n-from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n+from db_utils import init_db, get_collections\r\n from chat_utils import chat_bot\r\n from web_utils import start_web_collection\r\n from youtube_utils import start_youtube_collection\r\n from reddit_utils import start_reddit_collection\r\n@@ -34,39 +34,8 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n-def load_data_sources():\r\n-    collections = load_completed_collections()\r\n-    df = pd.DataFrame(collections)\r\n-    return df\r\n-\r\n-def select_data_source(selected_index, collections):\r\n-    if selected_index is None:\r\n-        return \"\", pd.DataFrame()\r\n-    name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n-    chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n-    return name, chunks_df\r\n-\r\n-def rename_data_source(selected_index, new_name, collections):\r\n-    if selected_index is None:\r\n-        return \"No source selected\"\r\n-    old_name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n-    rename_collection(conn, old_name, new_name)\r\n-    collections[selected_index]['name'] = new_name\r\n-    return \"Renamed successfully. Refresh to see changes.\"\r\n-\r\n-def confirm_delete_data_source(selected_index, collections):\r\n-    if selected_index is None:\r\n-        return \"No source selected\"\r\n-    name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n-    delete_collection(conn, name, tag)\r\n-    del collections[selected_index]\r\n-    return \"Deleted successfully. Refresh to see changes.\"\r\n-\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n@@ -83,9 +52,9 @@\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n             refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs.value), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n+            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Web Collection\"):\r\n@@ -149,25 +118,8 @@\n             refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n-            sources_df = gr.Dataframe(label=\"Available Data Sources\", interactive=True)\r\n-            load_sources_btn = gr.Button(\"Load Data Sources\")\r\n-            selected_source = gr.Textbox(label=\"Selected Data Source\", interactive=False)\r\n-            source_contents_df = gr.Dataframe(label=\"Data Source Contents\")\r\n-            new_name_input = gr.Textbox(label=\"New Name for Selected Source\")\r\n-            rename_btn = gr.Button(\"Rename Selected Source\")\r\n-            rename_status = gr.Textbox(label=\"Rename Status\")\r\n-            delete_btn = gr.Button(\"Delete Selected Source\")\r\n-            delete_confirm = gr.Checkbox(label=\"Confirm Deletion\")\r\n-            delete_status = gr.Textbox(label=\"Delete Status\")\r\n-            load_sources_btn.click(load_data_sources, outputs=sources_df)\r\n-            sources_df.change(select_data_source, [sources_df, completed_collections_state], [selected_source, source_contents_df])\r\n-            rename_btn.click(lambda idx, new_name, cs: rename_data_source(idx, new_name, cs.value), [sources_df, new_name_input, completed_collections_state], rename_status)\r\n-            delete_btn.click(lambda idx, confirm, cs: confirm_delete_data_source(idx, confirm, cs.value) if confirm else \"Please confirm deletion.\", [sources_df, delete_confirm, completed_collections_state], delete_status)\r\n-        \r\n-        with gr.Tab(\"Admin\"):\r\n-            # Moved advanced features here\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n             chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n             load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n@@ -175,8 +127,13 @@\n             execute_query_btn = gr.Button(\"Execute Query\")\r\n             query_output = gr.Markdown(label=\"Query Results\")\r\n             query_error = gr.Textbox(label=\"Error\")\r\n             execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n+            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n+            tags_output = gr.Markdown(label=\"Available Tags\")\r\n+            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n+        \r\n+        with gr.Tab(\"View Vector Store\"):\r\n             show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n             vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n             show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n             similarity_query_input = gr.Textbox(label=\"Similarity Search Query\")\r\n"
                },
                {
                    "date": 1756951469757,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n # main.py\r\n import os\r\n import gradio as gr\r\n-from db_utils import init_db, get_collections\r\n+from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n from chat_utils import chat_bot\r\n from web_utils import start_web_collection\r\n from youtube_utils import start_youtube_collection\r\n from reddit_utils import start_reddit_collection\r\n@@ -34,8 +34,39 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n+def load_data_sources():\r\n+    collections = load_completed_collections()\r\n+    df = pd.DataFrame(collections)\r\n+    return df\r\n+\r\n+def select_data_source(selected_index, collections):\r\n+    if selected_index is None:\r\n+        return \"\", pd.DataFrame()\r\n+    name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n+    return name, chunks_df\r\n+\r\n+def rename_data_source(selected_index, new_name, collections):\r\n+    if selected_index is None:\r\n+        return \"No source selected\"\r\n+    old_name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    rename_collection(conn, old_name, new_name)\r\n+    collections[selected_index]['name'] = new_name\r\n+    return \"Renamed successfully. Refresh to see changes.\"\r\n+\r\n+def confirm_delete_data_source(selected_index, collections):\r\n+    if selected_index is None:\r\n+        return \"No source selected\"\r\n+    name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    delete_collection(conn, name, tag)\r\n+    del collections[selected_index]\r\n+    return \"Deleted successfully. Refresh to see changes.\"\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n@@ -52,9 +83,9 @@\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n             refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n+            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs.value), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Web Collection\"):\r\n@@ -118,8 +149,25 @@\n             refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n             view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n         \r\n         with gr.Tab(\"View Database\"):\r\n+            sources_df = gr.Dataframe(label=\"Available Data Sources\", interactive=True)\r\n+            load_sources_btn = gr.Button(\"Load Data Sources\")\r\n+            selected_source = gr.Textbox(label=\"Selected Data Source\", interactive=False)\r\n+            source_contents_df = gr.Dataframe(label=\"Data Source Contents\")\r\n+            new_name_input = gr.Textbox(label=\"New Name for Selected Source\")\r\n+            rename_btn = gr.Button(\"Rename Selected Source\")\r\n+            rename_status = gr.Textbox(label=\"Rename Status\")\r\n+            delete_btn = gr.Button(\"Delete Selected Source\")\r\n+            delete_confirm = gr.Checkbox(label=\"Confirm Deletion\")\r\n+            delete_status = gr.Textbox(label=\"Delete Status\")\r\n+            load_sources_btn.click(load_data_sources, outputs=sources_df)\r\n+            sources_df.change(select_data_source, [sources_df, completed_collections_state], [selected_source, source_contents_df])\r\n+            rename_btn.click(lambda idx, new_name, cs: rename_data_source(idx, new_name, cs.value), [sources_df, new_name_input, completed_collections_state], rename_status)\r\n+            delete_btn.click(lambda idx, confirm, cs: confirm_delete_data_source(idx, confirm, cs.value) if confirm else \"Please confirm deletion.\", [sources_df, delete_confirm, completed_collections_state], delete_status)\r\n+        \r\n+        with gr.Tab(\"Admin\"):\r\n+            # Moved advanced features here\r\n             load_db_btn = gr.Button(\"Load Database Contents\")\r\n             urls_df = gr.Dataframe(label=\"URLs Table\")\r\n             chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n             load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n@@ -127,13 +175,8 @@\n             execute_query_btn = gr.Button(\"Execute Query\")\r\n             query_output = gr.Markdown(label=\"Query Results\")\r\n             query_error = gr.Textbox(label=\"Error\")\r\n             execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n-            view_tags_btn = gr.Button(\"View Available Data Sources (Tags)\")\r\n-            tags_output = gr.Markdown(label=\"Available Tags\")\r\n-            view_tags_btn.click(view_available_tags, outputs=tags_output)\r\n-        \r\n-        with gr.Tab(\"View Vector Store\"):\r\n             show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n             vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n             show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n             similarity_query_input = gr.Textbox(label=\"Similarity Search Query\")\r\n"
                },
                {
                    "date": 1756951762546,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n # main.py\r\n import os\r\n import gradio as gr\r\n-from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n+from db_utils import init_db, get_collections\r\n from chat_utils import chat_bot\r\n from web_utils import start_web_collection\r\n from youtube_utils import start_youtube_collection\r\n from reddit_utils import start_reddit_collection\r\n@@ -83,9 +83,9 @@\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n             refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs.value), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n+            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Web Collection\"):\r\n"
                },
                {
                    "date": 1756952107882,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n # main.py\r\n import os\r\n import gradio as gr\r\n-from db_utils import init_db, get_collections\r\n+from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n from chat_utils import chat_bot\r\n from web_utils import start_web_collection\r\n from youtube_utils import start_youtube_collection\r\n from reddit_utils import start_reddit_collection\r\n@@ -24,10 +24,9 @@\n \r\n def submit_chat(m, h, s, completed_collections):\r\n     tag = next((c['tag'] for c in completed_collections if c['name'] == s), None) if s != \"No RAG\" else None\r\n     print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n-    for chat_out, msg_out in gen:\r\n+    for chat_out, msg_out in chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag):\r\n         yield chat_out, msg_out\r\n \r\n def toggle_youtube_inputs(mode):\r\n     if mode == \"Search Query\":\r\n@@ -83,9 +82,9 @@\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n             refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Web Collection\"):\r\n"
                },
                {
                    "date": 1756955061145,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,9 +24,10 @@\n \r\n def submit_chat(m, h, s, completed_collections):\r\n     tag = next((c['tag'] for c in completed_collections if c['name'] == s), None) if s != \"No RAG\" else None\r\n     print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n-    for chat_out, msg_out in chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag):\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n+    for chat_out, msg_out in gen:\r\n         yield chat_out, msg_out\r\n \r\n def toggle_youtube_inputs(mode):\r\n     if mode == \"Search Query\":\r\n@@ -82,9 +83,9 @@\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n             refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n+            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Web Collection\"):\r\n"
                },
                {
                    "date": 1756955315610,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -34,37 +34,33 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n-def load_data_sources():\r\n+def load_data_sources_dropdown():\r\n     collections = load_completed_collections()\r\n-    df = pd.DataFrame(collections)\r\n-    return df\r\n+    return gr.update(choices=[c['name'] for c in collections])\r\n \r\n-def select_data_source(selected_index, collections):\r\n-    if selected_index is None:\r\n+def show_data_source_details(selected_name):\r\n+    if not selected_name:\r\n         return \"\", pd.DataFrame()\r\n-    name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n-    chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n-    return name, chunks_df\r\n+    tag = next((c['tag'] for c in load_completed_collections() if c['name'] == selected_name), None)\r\n+    if tag:\r\n+        chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n+        return selected_name, chunks_df\r\n+    return \"\", pd.DataFrame()\r\n \r\n-def rename_data_source(selected_index, new_name, collections):\r\n-    if selected_index is None:\r\n+def rename_data_source(selected_name, new_name):\r\n+    if not selected_name:\r\n         return \"No source selected\"\r\n-    old_name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n-    rename_collection(conn, old_name, new_name)\r\n-    collections[selected_index]['name'] = new_name\r\n+    tag = next((c['tag'] for c in load_completed_collections() if c['name'] == selected_name), None)\r\n+    rename_collection(conn, selected_name, new_name)\r\n     return \"Renamed successfully. Refresh to see changes.\"\r\n \r\n-def confirm_delete_data_source(selected_index, collections):\r\n-    if selected_index is None:\r\n+def delete_data_source(selected_name):\r\n+    if not selected_name:\r\n         return \"No source selected\"\r\n-    name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n-    delete_collection(conn, name, tag)\r\n-    del collections[selected_index]\r\n+    tag = next((c['tag'] for c in load_completed_collections() if c['name'] == selected_name), None)\r\n+    delete_collection(conn, selected_name, tag)\r\n     return \"Deleted successfully. Refresh to see changes.\"\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n"
                },
                {
                    "date": 1756955866311,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,187 @@\n+# main.py\r\n+import os\r\n+import gradio as gr\r\n+from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n+from chat_utils import chat_bot\r\n+from web_utils import start_web_collection\r\n+from youtube_utils import start_youtube_collection\r\n+from reddit_utils import start_reddit_collection\r\n+from subreddit_utils import start_subreddit_collection\r\n+from file_utils import start_file_ingestion\r\n+from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n+from config import MODEL_NAME\r\n+import pandas as pd\r\n+\r\n+conn = init_db()\r\n+\r\n+def load_completed_collections():\r\n+    return get_collections(conn)\r\n+\r\n+def update_dropdown():\r\n+    completed_collections = load_completed_collections()\r\n+    print(\"Loaded collections:\", completed_collections)  # Debug\r\n+    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\"), completed_collections\r\n+\r\n+def submit_chat(m, h, s, completed_collections):\r\n+    tag = next((c['tag'] for c in completed_collections if c['name'] == s), None) if s != \"No RAG\" else None\r\n+    print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n+    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n+    for chat_out, msg_out in gen:\r\n+        yield chat_out, msg_out\r\n+\r\n+def toggle_youtube_inputs(mode):\r\n+    if mode == \"Search Query\":\r\n+        return gr.update(visible=True), gr.update(visible=False)\r\n+    else:\r\n+        return gr.update(visible=False), gr.update(visible=True)\r\n+\r\n+def load_data_sources():\r\n+    collections = load_completed_collections()\r\n+    df = pd.DataFrame(collections)\r\n+    return df\r\n+\r\n+def select_data_source(selected_index, collections):\r\n+    if selected_index is None:\r\n+        return \"\", pd.DataFrame()\r\n+    name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n+    return name, chunks_df\r\n+\r\n+def rename_data_source(selected_index, new_name, collections):\r\n+    if selected_index is None:\r\n+        return \"No source selected\"\r\n+    old_name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    rename_collection(conn, old_name, new_name)\r\n+    collections[selected_index]['name'] = new_name\r\n+    return \"Renamed successfully. Refresh to see changes.\"\r\n+\r\n+def confirm_delete_data_source(selected_index, collections):\r\n+    if selected_index is None:\r\n+        return \"No source selected\"\r\n+    name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    delete_collection(conn, name, tag)\r\n+    del collections[selected_index]\r\n+    return \"Deleted successfully. Refresh to see changes.\"\r\n+\r\n+with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n+    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n+    \r\n+    collection_tasks_state = gr.State([])\r\n+    completed_collections_state = gr.State([])\r\n+    \r\n+    with gr.Tabs():\r\n+        with gr.Tab(\"Chat\"):\r\n+            gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n+            source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n+            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n+            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n+            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n+            with gr.Row():\r\n+                submit_btn = gr.Button(\"Submit\")\r\n+                clear = gr.Button(\"Clear\")\r\n+            demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n+            refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n+            clear.click(lambda: None, None, chatbot, queue=False)\r\n+            clear.click(lambda: \"\", None, msg, queue=False)\r\n+        \r\n+        with gr.Tab(\"Web Collection\"):\r\n+            name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            query_input_web = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_web = gr.Button(\"Start Collection\")\r\n+            status_web = gr.Textbox(label=\"Status\")\r\n+            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"YouTube Collection\"):\r\n+            name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n+            query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n+            urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n+            use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            collect_btn_yt = gr.Button(\"Start Collection\")\r\n+            status_yt = gr.Textbox(label=\"Status\")\r\n+            mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n+            collect_btn_yt.click(lambdan, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Reddit Collection\"):\r\n+            name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n+            timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_reddit = gr.Button(\"Start Collection\")\r\n+            status_reddit = gr.Textbox(label=\"Status\")\r\n+            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Subreddit Collection\"):\r\n+            name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n+            timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n+            collect_btn_sub = gr.Button(\"Start Collection\")\r\n+            status_sub = gr.Textbox(label=\"Status\")\r\n+            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"File Ingestion\"):\r\n+            name_input_file = gr.Textbox(label=\"Data Source Name (optional)\")\r\n+            file_upload = gr.File(label=\"Upload TXT or PDF file\", file_types=['.txt', '.pdf'], type=\"filepath\")\r\n+            use_ollama_file = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n+            ingest_btn = gr.Button(\"Start Ingestion\")\r\n+            status_file = gr.Textbox(label=\"Status\")\r\n+            ingest_btn.click(lambda n, fp, u, ts, cs: start_file_ingestion(n, fp, u, ts, cs), [name_input_file, file_upload, use_ollama_file, collection_tasks_state, completed_collections_state], [status_file, collection_tasks_state, completed_collections_state])\r\n+        \r\n+        with gr.Tab(\"Tasks\"):\r\n+            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n+            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n+            with gr.Accordion(\"Task Detail\", open=False):\r\n+                task_id_input = gr.Number(label=\"Task ID\")\r\n+                view_detail_btn = gr.Button(\"View Detail\")\r\n+                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n+                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n+                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n+            refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n+            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n+        \r\n+        with gr.Tab(\"View Database\"):\r\n+            sources_df = gr.Dataframe(label=\"Available Data Sources\", interactive=True)\r\n+            load_sources_btn = gr.Button(\"Load Data Sources\")\r\n+            selected_source = gr.Textbox(label=\"Selected Data Source\", interactive=False)\r\n+            source_contents_df = gr.Dataframe(label=\"Data Source Contents\")\r\n+            new_name_input = gr.Textbox(label=\"New Name for Selected Source\")\r\n+            rename_btn = gr.Button(\"Rename Selected Source\")\r\n+            rename_status = gr.Textbox(label=\"Rename Status\")\r\n+            delete_btn = gr.Button(\"Delete Selected Source\")\r\n+            delete_confirm = gr.Checkbox(label=\"Confirm Deletion\")\r\n+            delete_status = gr.Textbox(label=\"Delete Status\")\r\n+            load_sources_btn.click(load_data_sources, outputs=sources_df)\r\n+            sources_df.change(select_data_source, [sources_df, completed_collections_state], [selected_source, source_contents_df])\r\n+            rename_btn.click(lambda idx, new_name, cs: rename_data_source(idx, new_name, cs.value), [sources_df, new_name_input, completed_collections_state], rename_status)\r\n+            delete_btn.click(lambda idx, confirm, cs: confirm_delete_data_source(idx, confirm, cs.value) if confirm else \"Please confirm deletion.\", [sources_df, delete_confirm, completed_collections_state], delete_status)\r\n+        \r\n+        with gr.Tab(\"Admin\"):\r\n+            # Moved advanced features here\r\n+            load_db_btn = gr.Button(\"Load Database Contents\")\r\n+            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n+            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n+            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n+            sql_query_input = gr.Textbox(label=\"Custom SQL Query (e.g., SELECT * FROM urls LIMIT 5)\")\r\n+            execute_query_btn = gr.Button(\"Execute Query\")\r\n+            query_output = gr.Markdown(label=\"Query Results\")\r\n+            query_error = gr.Textbox(label=\"Error\")\r\n+            execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n+            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n+            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n+            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n+            similarity_query_input = gr.Textbox(label=\"Similarity Search Query\")\r\n+            similarity_search_btn = gr.Button(\"Perform Similarity Search\")\r\n+            similarity_results = gr.Markdown(label=\"Similarity Search Results\")\r\n+            similarity_search_btn.click(perform_similarity_search, similarity_query_input, similarity_results)\r\n+\r\n+demo.queue(default_concurrency_limit=5).launch()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756956022503,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n # main.py\r\n import os\r\n import gradio as gr\r\n-from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n+from db_utils import init_db, get_collections\r\n from chat_utils import chat_bot\r\n from web_utils import start_web_collection\r\n from youtube_utils import start_youtube_collection\r\n from reddit_utils import start_reddit_collection\r\n@@ -34,39 +34,8 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n-def load_data_sources():\r\n-    collections = load_completed_collections()\r\n-    df = pd.DataFrame(collections)\r\n-    return df\r\n-\r\n-def select_data_source(selected_index, collections):\r\n-    if selected_index is None:\r\n-        return \"\", pd.DataFrame()\r\n-    name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n-    chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n-    return name, chunks_df\r\n-\r\n-def rename_data_source(selected_index, new_name, collections):\r\n-    if selected_index is None:\r\n-        return \"No source selected\"\r\n-    old_name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n-    rename_collection(conn, old_name, new_name)\r\n-    collections[selected_index]['name'] = new_name\r\n-    return \"Renamed successfully. Refresh to see changes.\"\r\n-\r\n-def confirm_delete_data_source(selected_index, collections):\r\n-    if selected_index is None:\r\n-        return \"No source selected\"\r\n-    name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n-    delete_collection(conn, name, tag)\r\n-    del collections[selected_index]\r\n-    return \"Deleted successfully. Refresh to see changes.\"\r\n-\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n@@ -83,9 +52,9 @@\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n             refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n+            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs.value), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Web Collection\"):\r\n@@ -105,191 +74,8 @@\n             use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_yt = gr.Button(\"Start Collection\")\r\n             status_yt = gr.Textbox(label=\"Status\")\r\n             mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n-            collect_btn_yt.click(lambdan, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Reddit Collection\"):\r\n-            name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n-            timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n-            collect_btn_reddit = gr.Button(\"Start Collection\")\r\n-            status_reddit = gr.Textbox(label=\"Status\")\r\n-            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Subreddit Collection\"):\r\n-            name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n-            timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n-            use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n-            collect_btn_sub = gr.Button(\"Start Collection\")\r\n-            status_sub = gr.Textbox(label=\"Status\")\r\n-            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"File Ingestion\"):\r\n-            name_input_file = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            file_upload = gr.File(label=\"Upload TXT or PDF file\", file_types=['.txt', '.pdf'], type=\"filepath\")\r\n-            use_ollama_file = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            ingest_btn = gr.Button(\"Start Ingestion\")\r\n-            status_file = gr.Textbox(label=\"Status\")\r\n-            ingest_btn.click(lambda n, fp, u, ts, cs: start_file_ingestion(n, fp, u, ts, cs), [name_input_file, file_upload, use_ollama_file, collection_tasks_state, completed_collections_state], [status_file, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"Tasks\"):\r\n-            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n-            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n-            with gr.Accordion(\"Task Detail\", open=False):\r\n-                task_id_input = gr.Number(label=\"Task ID\")\r\n-                view_detail_btn = gr.Button(\"View Detail\")\r\n-                detail_content = gr.Markdown(label=\"Scraped Content\")\r\n-                detail_summary = gr.Markdown(label=\"LLM Summarization\")\r\n-                detail_answer = gr.Markdown(label=\"Answer to Search Query\")\r\n-            refresh_btn.click(refresh_tasks, collection_tasks_state, tasks_df)\r\n-            view_detail_btn.click(lambda tid, ts: show_task_detail(tid, ts, conn), [task_id_input, collection_tasks_state], [detail_content, detail_summary, detail_answer])\r\n-        \r\n-        with gr.Tab(\"View Database\"):\r\n-            sources_df = gr.Dataframe(label=\"Available Data Sources\", interactive=True)\r\n-            load_sources_btn = gr.Button(\"Load Data Sources\")\r\n-            selected_source = gr.Textbox(label=\"Selected Data Source\", interactive=False)\r\n-            source_contents_df = gr.Dataframe(label=\"Data Source Contents\")\r\n-            new_name_input = gr.Textbox(label=\"New Name for Selected Source\")\r\n-            rename_btn = gr.Button(\"Rename Selected Source\")\r\n-            rename_status = gr.Textbox(label=\"Rename Status\")\r\n-            delete_btn = gr.Button(\"Delete Selected Source\")\r\n-            delete_confirm = gr.Checkbox(label=\"Confirm Deletion\")\r\n-            delete_status = gr.Textbox(label=\"Delete Status\")\r\n-            load_sources_btn.click(load_data_sources, outputs=sources_df)\r\n-            sources_df.change(select_data_source, [sources_df, completed_collections_state], [selected_source, source_contents_df])\r\n-            rename_btn.click(lambda idx, new_name, cs: rename_data_source(idx, new_name, cs.value), [sources_df, new_name_input, completed_collections_state], rename_status)\r\n-            delete_btn.click(lambda idx, confirm, cs: confirm_delete_data_source(idx, confirm, cs.value) if confirm else \"Please confirm deletion.\", [sources_df, delete_confirm, completed_collections_state], delete_status)\r\n-        \r\n-        with gr.Tab(\"Admin\"):\r\n-            # Moved advanced features here\r\n-            load_db_btn = gr.Button(\"Load Database Contents\")\r\n-            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n-            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n-            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n-            sql_query_input = gr.Textbox(label=\"Custom SQL Query (e.g., SELECT * FROM urls LIMIT 5)\")\r\n-            execute_query_btn = gr.Button(\"Execute Query\")\r\n-            query_output = gr.Markdown(label=\"Query Results\")\r\n-            query_error = gr.Textbox(label=\"Error\")\r\n-            execute_query_btn.click(lambda q: execute_sql_query(conn, q), sql_query_input, [query_output, query_error])\r\n-            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n-            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n-            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n-            similarity_query_input = gr.Textbox(label=\"Similarity Search Query\")\r\n-            similarity_search_btn = gr.Button(\"Perform Similarity Search\")\r\n-            similarity_results = gr.Markdown(label=\"Similarity Search Results\")\r\n-            similarity_search_btn.click(perform_similarity_search, similarity_query_input, similarity_results)\r\n-\r\n-demo.queue(default_concurrency_limit=5).launch()\n-# main.py\r\n-import os\r\n-import gradio as gr\r\n-from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n-from chat_utils import chat_bot\r\n-from web_utils import start_web_collection\r\n-from youtube_utils import start_youtube_collection\r\n-from reddit_utils import start_reddit_collection\r\n-from subreddit_utils import start_subreddit_collection\r\n-from file_utils import start_file_ingestion\r\n-from view_utils import view_db, execute_sql_query, view_vectorstore, perform_similarity_search, refresh_tasks, show_task_detail, view_available_tags\r\n-from config import MODEL_NAME\r\n-import pandas as pd\r\n-\r\n-conn = init_db()\r\n-\r\n-def load_completed_collections():\r\n-    return get_collections(conn)\r\n-\r\n-def update_dropdown():\r\n-    completed_collections = load_completed_collections()\r\n-    print(\"Loaded collections:\", completed_collections)  # Debug\r\n-    return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\"), completed_collections\r\n-\r\n-def submit_chat(m, h, s, completed_collections):\r\n-    tag = next((c['tag'] for c in completed_collections if c['name'] == s), None) if s != \"No RAG\" else None\r\n-    print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n-    gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n-    for chat_out, msg_out in gen:\r\n-        yield chat_out, msg_out\r\n-\r\n-def toggle_youtube_inputs(mode):\r\n-    if mode == \"Search Query\":\r\n-        return gr.update(visible=True), gr.update(visible=False)\r\n-    else:\r\n-        return gr.update(visible=False), gr.update(visible=True)\r\n-\r\n-def load_data_sources_dropdown():\r\n-    collections = load_completed_collections()\r\n-    return gr.update(choices=[c['name'] for c in collections])\r\n-\r\n-def show_data_source_details(selected_name):\r\n-    if not selected_name:\r\n-        return \"\", pd.DataFrame()\r\n-    tag = next((c['tag'] for c in load_completed_collections() if c['name'] == selected_name), None)\r\n-    if tag:\r\n-        chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n-        return selected_name, chunks_df\r\n-    return \"\", pd.DataFrame()\r\n-\r\n-def rename_data_source(selected_name, new_name):\r\n-    if not selected_name:\r\n-        return \"No source selected\"\r\n-    tag = next((c['tag'] for c in load_completed_collections() if c['name'] == selected_name), None)\r\n-    rename_collection(conn, selected_name, new_name)\r\n-    return \"Renamed successfully. Refresh to see changes.\"\r\n-\r\n-def delete_data_source(selected_name):\r\n-    if not selected_name:\r\n-        return \"No source selected\"\r\n-    tag = next((c['tag'] for c in load_completed_collections() if c['name'] == selected_name), None)\r\n-    delete_collection(conn, selected_name, tag)\r\n-    return \"Deleted successfully. Refresh to see changes.\"\r\n-\r\n-with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n-    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n-    \r\n-    collection_tasks_state = gr.State([])\r\n-    completed_collections_state = gr.State([])\r\n-    \r\n-    with gr.Tabs():\r\n-        with gr.Tab(\"Chat\"):\r\n-            gr.Markdown(\"\"\"**Instructions:** Select a RAG source below to augment your query with pre-collected data.\"\"\")\r\n-            source_dropdown = gr.Dropdown(label=\"Select RAG Source (optional)\", choices=[], value=None, interactive=True)\r\n-            refresh_sources_btn = gr.Button(\"Refresh Sources\")\r\n-            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n-            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n-            with gr.Row():\r\n-                submit_btn = gr.Button(\"Submit\")\r\n-                clear = gr.Button(\"Clear\")\r\n-            demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n-            clear.click(lambda: None, None, chatbot, queue=False)\r\n-            clear.click(lambda: \"\", None, msg, queue=False)\r\n-        \r\n-        with gr.Tab(\"Web Collection\"):\r\n-            name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            query_input_web = gr.Textbox(label=\"Search Query\")\r\n-            timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n-            use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            collect_btn_web = gr.Button(\"Start Collection\")\r\n-            status_web = gr.Textbox(label=\"Status\")\r\n-            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n-        \r\n-        with gr.Tab(\"YouTube Collection\"):\r\n-            name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n-            mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n-            query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n-            urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n-            use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n-            collect_btn_yt = gr.Button(\"Start Collection\")\r\n-            status_yt = gr.Textbox(label=\"Status\")\r\n-            mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n             collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Reddit Collection\"):\r\n             name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n"
                },
                {
                    "date": 1756956702740,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n # main.py\r\n import os\r\n import gradio as gr\r\n-from db_utils import init_db, get_collections\r\n+from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n from chat_utils import chat_bot\r\n from web_utils import start_web_collection\r\n from youtube_utils import start_youtube_collection\r\n from reddit_utils import start_reddit_collection\r\n@@ -34,8 +34,39 @@\n         return gr.update(visible=True), gr.update(visible=False)\r\n     else:\r\n         return gr.update(visible=False), gr.update(visible=True)\r\n \r\n+def load_data_sources():\r\n+    collections = load_completed_collections()\r\n+    df = pd.DataFrame(collections)\r\n+    return df\r\n+\r\n+def select_data_source(selected_index, collections):\r\n+    if selected_index is None:\r\n+        return \"\", pd.DataFrame()\r\n+    name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n+    return name, chunks_df\r\n+\r\n+def rename_data_source(selected_index, new_name, collections):\r\n+    if selected_index is None:\r\n+        return \"No source selected\"\r\n+    old_name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    rename_collection(conn, old_name, new_name)\r\n+    collections[selected_index]['name'] = new_name\r\n+    return \"Renamed successfully. Refresh to see changes.\"\r\n+\r\n+def confirm_delete_data_source(selected_index, collections):\r\n+    if selected_index is None:\r\n+        return \"No source selected\"\r\n+    name = collections[selected_index]['name']\r\n+    tag = collections[selected_index]['tag']\r\n+    delete_collection(conn, name, tag)\r\n+    del collections[selected_index]\r\n+    return \"Deleted successfully. Refresh to see changes.\"\r\n+\r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n     \r\n     collection_tasks_state = gr.State([])\r\n@@ -52,9 +83,9 @@\n                 submit_btn = gr.Button(\"Submit\")\r\n                 clear = gr.Button(\"Clear\")\r\n             demo.load(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n             refresh_sources_btn.click(update_dropdown, outputs=[source_dropdown, completed_collections_state])\r\n-            submit_btn.click(lambda m, h, s, cs: submit_chat(m, h, s, cs.value), [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n+            submit_btn.click(submit_chat, [msg, chatbot, source_dropdown, completed_collections_state], [chatbot, msg])\r\n             clear.click(lambda: None, None, chatbot, queue=False)\r\n             clear.click(lambda: \"\", None, msg, queue=False)\r\n         \r\n         with gr.Tab(\"Web Collection\"):\r\n"
                },
                {
                    "date": 1756957598419,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -39,32 +39,36 @@\n     collections = load_completed_collections()\r\n     df = pd.DataFrame(collections)\r\n     return df\r\n \r\n-def select_data_source(selected_index, collections):\r\n-    if selected_index is None:\r\n+def select_data_source(selected_row, collections):\r\n+    if selected_row is None:\r\n         return \"\", pd.DataFrame()\r\n-    name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n+    name = selected_row['name']\r\n+    tag = selected_row['tag']\r\n     chunks_df = pd.read_sql(f\"SELECT * FROM chunks WHERE tag = '{tag}'\", conn)\r\n     return name, chunks_df\r\n \r\n-def rename_data_source(selected_index, new_name, collections):\r\n-    if selected_index is None:\r\n+def rename_data_source(selected_row, new_name, collections):\r\n+    if selected_row is None:\r\n         return \"No source selected\"\r\n-    old_name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n+    old_name = selected_row['name']\r\n+    tag = selected_row['tag']\r\n     rename_collection(conn, old_name, new_name)\r\n-    collections[selected_index]['name'] = new_name\r\n+    # Update state\r\n+    for c in collections:\r\n+        if c['name'] == old_name:\r\n+            c['name'] = new_name\r\n     return \"Renamed successfully. Refresh to see changes.\"\r\n \r\n-def confirm_delete_data_source(selected_index, collections):\r\n-    if selected_index is None:\r\n+def confirm_delete_data_source(selected_row, collections):\r\n+    if selected_row is None:\r\n         return \"No source selected\"\r\n-    name = collections[selected_index]['name']\r\n-    tag = collections[selected_index]['tag']\r\n+    name = selected_row['name']\r\n+    tag = selected_row['tag']\r\n     delete_collection(conn, name, tag)\r\n-    del collections[selected_index]\r\n+    # Update state\r\n+    collections = [c for c in collections if c['name'] != name]\r\n     return \"Deleted successfully. Refresh to see changes.\"\r\n \r\n with gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n     gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n"
                },
                {
                    "date": 1756961129355,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,6 @@\n # main.py\r\n+# main.py\r\n import os\r\n import gradio as gr\r\n from db_utils import init_db, get_collections, rename_collection, delete_collection\r\n from chat_utils import chat_bot\r\n@@ -95,44 +96,48 @@\n         with gr.Tab(\"Web Collection\"):\r\n             name_input_web = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             query_input_web = gr.Textbox(label=\"Search Query\")\r\n             timelimit_input_web = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            max_urls_input_web = gr.Number(label=\"Max URLs\", value=10)\r\n             use_ollama_web = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_web = gr.Button(\"Start Collection\")\r\n             status_web = gr.Textbox(label=\"Status\")\r\n-            collect_btn_web.click(lambda n, q, tl, u, ts, cs: start_web_collection(n, q, tl, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_web.click(lambda n, q, tl, mu, u, ts, cs: start_web_collection(n, q, tl, mu, u, ts, cs), [name_input_web, query_input_web, timelimit_input_web, max_urls_input_web, use_ollama_web, collection_tasks_state, completed_collections_state], [status_web, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"YouTube Collection\"):\r\n             name_input_yt = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             mode_yt = gr.Radio([\"Search Query\", \"List of URLs\"], label=\"Collection Mode\", value=\"Search Query\")\r\n             query_input_yt = gr.Textbox(label=\"Search Query\", visible=True)\r\n             urls_input_yt = gr.TextArea(label=\"List of URLs (one per line)\", visible=False)\r\n+            max_videos_input_yt = gr.Number(label=\"Max Videos\", value=10)\r\n             use_ollama_yt = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             collect_btn_yt = gr.Button(\"Start Collection\")\r\n             status_yt = gr.Textbox(label=\"Status\")\r\n             mode_yt.change(toggle_youtube_inputs, mode_yt, [query_input_yt, urls_input_yt])\r\n-            collect_btn_yt.click(lambda n, m, q, urls, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_yt.click(lambda n, m, q, urls, mv, u, ts, cs: start_youtube_collection(n, m, q if m == \"Search Query\" else None, urls.splitlines() if m == \"List of URLs\" else None, mv, u, ts, cs), [name_input_yt, mode_yt, query_input_yt, urls_input_yt, max_videos_input_yt, use_ollama_yt, collection_tasks_state, completed_collections_state], [status_yt, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Reddit Collection\"):\r\n             name_input_reddit = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             query_input_reddit = gr.Textbox(label=\"Search Query\")\r\n             timelimit_input_reddit = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n+            max_urls_input_reddit = gr.Number(label=\"Max URLs\", value=10)\r\n             use_ollama_reddit = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             max_comments_reddit = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n             collect_btn_reddit = gr.Button(\"Start Collection\")\r\n             status_reddit = gr.Textbox(label=\"Status\")\r\n-            collect_btn_reddit.click(lambda n, q, tl, u, mc, ts, cs: start_reddit_collection(n, q, tl, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_reddit.click(lambda n, q, tl, mu, u, mc, ts, cs: start_reddit_collection(n, q, tl, mu, u, mc, ts, cs), [name_input_reddit, query_input_reddit, timelimit_input_reddit, max_urls_input_reddit, use_ollama_reddit, max_comments_reddit, collection_tasks_state, completed_collections_state], [status_reddit, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"Subreddit Collection\"):\r\n             name_input_sub = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n             timelimit_input_sub = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n             query_input_sub = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n+            max_urls_input_sub = gr.Number(label=\"Max URLs\", value=10)\r\n             use_ollama_sub = gr.Checkbox(label=\"Use Ollama Augmentation\", value=False)\r\n             max_comments_sub = gr.Number(label=\"Max Comments per Thread\", value=50)\r\n             collect_btn_sub = gr.Button(\"Start Collection\")\r\n             status_sub = gr.Textbox(label=\"Status\")\r\n-            collect_btn_sub.click(lambda n, s, tl, q, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n+            collect_btn_sub.click(lambda n, s, tl, q, mu, u, mc, ts, cs: start_subreddit_collection(n, s, tl, q, mu, u, mc, ts, cs), [name_input_sub, subreddit_input, timelimit_input_sub, query_input_sub, max_urls_input_sub, use_ollama_sub, max_comments_sub, collection_tasks_state, completed_collections_state], [status_sub, collection_tasks_state, completed_collections_state])\r\n         \r\n         with gr.Tab(\"File Ingestion\"):\r\n             name_input_file = gr.Textbox(label=\"Data Source Name (optional)\")\r\n             file_upload = gr.File(label=\"Upload TXT or PDF file\", file_types=['.txt', '.pdf'], type=\"filepath\")\r\n"
                },
                {
                    "date": 1756966892502,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,14 +19,14 @@\n     return get_collections(conn)\r\n \r\n def update_dropdown():\r\n     completed_collections = load_completed_collections()\r\n-    print(\"Loaded collections:\", completed_collections)  # Debug\r\n+    print(\"Debug: Loaded collections:\", completed_collections)  # Debug\r\n     return gr.update(choices=[\"No RAG\"] + [c['name'] for c in completed_collections], value=\"No RAG\"), completed_collections\r\n \r\n def submit_chat(m, h, s, completed_collections):\r\n     tag = next((c['tag'] for c in completed_collections if c['name'] == s), None) if s != \"No RAG\" else None\r\n-    print(f\"Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n+    print(f\"Debug: Submitting chat with source: {s}, tag: {tag}\")  # Debug\r\n     gen = chat_bot(m, h, conn=conn, selected_source=s, selected_tag=tag)\r\n     for chat_out, msg_out in gen:\r\n         yield chat_out, msg_out\r\n \r\n"
                }
            ],
            "date": 1756857001278,
            "name": "Commit-0",
            "content": "import gradio as gr\r\nfrom db_utils import init_db\r\nfrom chat_utils import chat_bot\r\nfrom crawl_utils import start_crawl\r\nfrom view_utils import view_db, view_vectorstore, refresh_tasks\r\nfrom config import MODEL_NAME\r\n\r\nconn = init_db()\r\n\r\nwith gr.Blocks(title=\"Enhanced RAG Chatbot with Qwen 2.5:7B\", theme=gr.themes.Soft()) as demo:\r\n    gr.Markdown(f\"# Enhanced RAG Chatbot\\nCurrent Model: {MODEL_NAME}\")\r\n    \r\n    tasks_state = gr.State([])\r\n    \r\n    with gr.Tabs():\r\n        with gr.Tab(\"Chat\"):\r\n            chatbot = gr.Chatbot(height=500, type=\"messages\")\r\n            msg = gr.Textbox(placeholder=\"Enter your prompt here...\", show_label=False)\r\n            with gr.Row():\r\n                submit_btn = gr.Button(\"Submit\")\r\n                clear = gr.Button(\"Clear\")\r\n            submit_btn.click(lambda m, h: chat_bot(m, h, conn=conn), [msg, chatbot], [msg, chatbot])\r\n            clear.click(lambda: (\"\", None), None, [msg, chatbot], queue=False)\r\n        \r\n        with gr.Tab(\"Crawl Subreddit\"):\r\n            subreddit_input = gr.Textbox(label=\"Subreddit Name (e.g., wallstreetbets)\")\r\n            timelimit_input = gr.Dropdown([\"Day\", \"Week\", \"Month\", \"Year\"], label=\"Time Limit\")\r\n            query_input = gr.Textbox(label=\"Search Query (e.g., best stocks to buy)\")\r\n            crawl_btn = gr.Button(\"Crawl\")\r\n            status = gr.Textbox(label=\"Status\")\r\n            refresh_btn = gr.Button(\"Refresh Tasks\")\r\n            tasks_df = gr.Dataframe(label=\"Tasks\")\r\n            crawl_btn.click(lambda s, t, q, ts: start_crawl(s, t, q, ts, conn=conn), [subreddit_input, timelimit_input, query_input, tasks_state], [status, tasks_state])\r\n            refresh_btn.click(refresh_tasks, tasks_state, tasks_df)\r\n        \r\n        with gr.Tab(\"View Database\"):\r\n            load_db_btn = gr.Button(\"Load Database Contents\")\r\n            urls_df = gr.Dataframe(label=\"URLs Table\")\r\n            chunks_df = gr.Dataframe(label=\"Chunks Table\")\r\n            load_db_btn.click(lambda: view_db(conn), outputs=[urls_df, chunks_df])\r\n        \r\n        with gr.Tab(\"View Vector Store\"):\r\n            show_vs_btn = gr.Button(\"Show Vector Store Contents\")\r\n            vs_output = gr.Markdown(label=\"Vector Store Entries\")\r\n            show_vs_btn.click(view_vectorstore, outputs=vs_output)\r\n\r\ndemo.queue(default_concurrency_limit=5).launch()"
        }
    ]
}