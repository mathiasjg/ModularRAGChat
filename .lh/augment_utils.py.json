{
    "sourceFile": "augment_utils.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1756965358147,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1756965545191,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,34 @@\n+# augment_utils.py\r\n+import spacy\r\n+import requests\r\n+import re\r\n+\r\n+nlp = spacy.load(\"en_core_web_sm\")\r\n+\r\n+def augment_chunk(chunk):\r\n+    \"\"\"\r\n+    Perform NLP on the chunk and enhance with Ollama.\r\n+    Returns the augmented text. Since augmentation is requested, Ollama is always used.\r\n+    \"\"\"\r\n+    # NLP Processing: lemmatization, remove stop words and punctuation\r\n+    doc = nlp(chunk)\r\n+    processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.text.strip()]\r\n+    processed_text = ' '.join(processed_tokens)\r\n+\r\n+    ollama_url = \"http://localhost:11434/api/generate\"\r\n+    payload = {\r\n+        \"model\": \"qwen2.5:7b\",\r\n+        \"prompt\": f\"Enhance and correct this content chunk for clarity and accuracy: {processed_text}. Include only the corrected text, do not include a summarization of the changes or any additional text.\",\r\n+        \"stream\": False\r\n+    }\r\n+    try:\r\n+        response = requests.post(ollama_url, json=payload, timeout=30)\r\n+        if response.status_code == 200:\r\n+            enhanced_text = response.json()['response'].strip()\r\n+            return enhanced_text\r\n+        else:\r\n+            print(f\"Error enhancing chunk with Ollama: {response.text}\")\r\n+            return processed_text  # Fallback\r\n+    except requests.exceptions.RequestException as e:\r\n+        print(f\"Ollama request failed: {e}. Falling back to NLP-processed text.\")\r\n+        return processed_text\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756966791242,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,13 +9,16 @@\n     \"\"\"\r\n     Perform NLP on the chunk and enhance with Ollama.\r\n     Returns the augmented text. Since augmentation is requested, Ollama is always used.\r\n     \"\"\"\r\n+    print(\"Debug: Starting NLP processing on chunk...\")\r\n     # NLP Processing: lemmatization, remove stop words and punctuation\r\n     doc = nlp(chunk)\r\n     processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.text.strip()]\r\n     processed_text = ' '.join(processed_tokens)\r\n+    print(f\"Debug: NLP processing completed. Processed text length: {len(processed_text)}\")\r\n \r\n+    print(\"Debug: Starting Ollama enhancement...\")\r\n     ollama_url = \"http://localhost:11434/api/generate\"\r\n     payload = {\r\n         \"model\": \"qwen2.5:7b\",\r\n         \"prompt\": f\"Enhance and correct this content chunk for clarity and accuracy: {processed_text}. Include only the corrected text, do not include a summarization of the changes or any additional text.\",\r\n@@ -24,8 +27,9 @@\n     try:\r\n         response = requests.post(ollama_url, json=payload, timeout=30)\r\n         if response.status_code == 200:\r\n             enhanced_text = response.json()['response'].strip()\r\n+            print(f\"Debug: Ollama enhancement successful. Enhanced text length: {len(enhanced_text)}\")\r\n             return enhanced_text\r\n         else:\r\n             print(f\"Error enhancing chunk with Ollama: {response.text}\")\r\n             return processed_text  # Fallback\r\n"
                },
                {
                    "date": 1757005642495,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,9 +10,8 @@\n     Perform NLP on the chunk and enhance with Ollama.\r\n     Returns the augmented text. Since augmentation is requested, Ollama is always used.\r\n     \"\"\"\r\n     print(\"Debug: Starting NLP processing on chunk...\")\r\n-    # NLP Processing: lemmatization, remove stop words and punctuation\r\n     doc = nlp(chunk)\r\n     processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.text.strip()]\r\n     processed_text = ' '.join(processed_tokens)\r\n     print(f\"Debug: NLP processing completed. Processed text length: {len(processed_text)}\")\r\n"
                },
                {
                    "date": 1757007617664,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,32 +6,26 @@\n nlp = spacy.load(\"en_core_web_sm\")\r\n \r\n def augment_chunk(chunk):\r\n     \"\"\"\r\n-    Perform NLP on the chunk and enhance with Ollama.\r\n-    Returns the augmented text. Since augmentation is requested, Ollama is always used.\r\n+    Enhance the chunk with Ollama for spelling and grammar correction only, without changing words, meaning, or structure.\r\n+    Returns the corrected text.\r\n     \"\"\"\r\n-    print(\"Debug: Starting NLP processing on chunk...\")\r\n-    doc = nlp(chunk)\r\n-    processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.text.strip()]\r\n-    processed_text = ' '.join(processed_tokens)\r\n-    print(f\"Debug: NLP processing completed. Processed text length: {len(processed_text)}\")\r\n-\r\n-    print(\"Debug: Starting Ollama enhancement...\")\r\n+    print(\"Debug: Starting Ollama correction...\")\r\n     ollama_url = \"http://localhost:11434/api/generate\"\r\n     payload = {\r\n         \"model\": \"qwen2.5:7b\",\r\n-        \"prompt\": f\"Enhance and correct this content chunk for clarity and accuracy: {processed_text}. Include only the corrected text, do not include a summarization of the changes or any additional text.\",\r\n+        \"prompt\": f\"Correct spelling and grammar in this content chunk without changing any words, meaning, or structure: {chunk}. Include only the corrected text, do not add or remove anything else.\",\r\n         \"stream\": False\r\n     }\r\n     try:\r\n         response = requests.post(ollama_url, json=payload, timeout=30)\r\n         if response.status_code == 200:\r\n             enhanced_text = response.json()['response'].strip()\r\n-            print(f\"Debug: Ollama enhancement successful. Enhanced text length: {len(enhanced_text)}\")\r\n+            print(f\"Debug: Ollama correction successful. Corrected text length: {len(enhanced_text)}\")\r\n             return enhanced_text\r\n         else:\r\n\\ No newline at end of file\n-            print(f\"Error enhancing chunk with Ollama: {response.text}\")\r\n-            return processed_text  # Fallback\r\n+            print(f\"Error correcting chunk with Ollama: {response.text}\")\r\n+            return chunk  # Fallback to original\r\n     except requests.exceptions.RequestException as e:\r\n-        print(f\"Ollama request failed: {e}. Falling back to NLP-processed text.\")\r\n-        return processed_text\n+        print(f\"Ollama request failed: {e}. Falling back to original text.\")\r\n+        return chunk\n\\ No newline at end of file\n"
                }
            ],
            "date": 1756965358147,
            "name": "Commit-0",
            "content": ""
        }
    ]
}