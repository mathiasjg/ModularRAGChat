{
    "sourceFile": "youtube_utils.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 48,
            "patches": [
                {
                    "date": 1756920084523,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1756920262851,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,15 +7,14 @@\n \r\n with tempfile.TemporaryDirectory() as tmpdir:\r\n     ydl_opts = {\r\n         'writesubtitles': True,\r\n-        'writeautomaticsubs': True,\r\n+        'writeautomaticsub': True,\r\n         'subtitleslangs': ['en'],\r\n         'subtitlesformat': 'vtt',\r\n         'skip_download': True,\r\n         'quiet': True,\r\n-        'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-        'impersonate': 'chrome'\r\n+        'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s')\r\n     }\r\n     with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n         info = ydl.extract_info(url, download=False)\r\n         video_id = info['id']\r\n"
                },
                {
                    "date": 1756920333835,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,14 +7,15 @@\n \r\n with tempfile.TemporaryDirectory() as tmpdir:\r\n     ydl_opts = {\r\n         'writesubtitles': True,\r\n-        'writeautomaticsub': True,\r\n+        'writeautomaticsubs': True,\r\n         'subtitleslangs': ['en'],\r\n         'subtitlesformat': 'vtt',\r\n         'skip_download': True,\r\n         'quiet': True,\r\n-        'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s')\r\n+        'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n+        'impersonate': 'chrome'\r\n     }\r\n     with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n         info = ydl.extract_info(url, download=False)\r\n         video_id = info['id']\r\n"
                },
                {
                    "date": 1756920464298,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,21 +1,22 @@\n import yt_dlp\r\n import tempfile\r\n import os\r\n import re\r\n+from yt_dlp.networking import ImpersonateTarget\r\n \r\n url = 'https://www.youtube.com/watch?v=VxOQjqNgQ5E'\r\n \r\n with tempfile.TemporaryDirectory() as tmpdir:\r\n     ydl_opts = {\r\n         'writesubtitles': True,\r\n-        'writeautomaticsubs': True,\r\n+        'writeautomaticsub': True,\r\n         'subtitleslangs': ['en'],\r\n         'subtitlesformat': 'vtt',\r\n         'skip_download': True,\r\n         'quiet': True,\r\n         'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-        'impersonate': 'chrome'\r\n+        'impersonate': ImpersonateTarget('chrome')\r\n     }\r\n     with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n         info = ydl.extract_info(url, download=False)\r\n         video_id = info['id']\r\n"
                },
                {
                    "date": 1756920571443,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,9 @@\n import yt_dlp\r\n import tempfile\r\n import os\r\n import re\r\n-from yt_dlp.networking import ImpersonateTarget\r\n+from yt_dlp.networking.impersonate import ImpersonateTarget\r\n \r\n url = 'https://www.youtube.com/watch?v=VxOQjqNgQ5E'\r\n \r\n with tempfile.TemporaryDirectory() as tmpdir:\r\n"
                },
                {
                    "date": 1756921400484,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,32 +1,50 @@\n+# youtube_utils.py\r\n import yt_dlp\r\n import tempfile\r\n import os\r\n import re\r\n from yt_dlp.networking.impersonate import ImpersonateTarget\r\n+import time\r\n \r\n url = 'https://www.youtube.com/watch?v=VxOQjqNgQ5E'\r\n \r\n-with tempfile.TemporaryDirectory() as tmpdir:\r\n-    ydl_opts = {\r\n-        'writesubtitles': True,\r\n-        'writeautomaticsub': True,\r\n-        'subtitleslangs': ['en'],\r\n-        'subtitlesformat': 'vtt',\r\n-        'skip_download': True,\r\n-        'quiet': True,\r\n-        'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-        'impersonate': ImpersonateTarget('chrome')\r\n-    }\r\n-    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n-        info = ydl.extract_info(url, download=False)\r\n-        video_id = info['id']\r\n-        ydl.download([url])\r\n-        vtt_file = os.path.join(tmpdir, f'transcript.{video_id}.en.vtt')\r\n-        if os.path.exists(vtt_file):\r\n-            with open(vtt_file, \"r\", encoding=\"utf-8\") as f:\r\n-                vtt_content = f.read()\r\n-            transcript_text = re.sub(r'^\\d+\\n\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\\n', '', vtt_content)\r\n-            transcript_text = re.sub(r'\\n\\n', '\\n', transcript_text).strip()\r\n-            print(transcript_text)\r\n\\ No newline at end of file\n+retries = 3\r\n+for attempt in range(retries):\r\n+    try:\r\n+        with tempfile.TemporaryDirectory() as tmpdir:\r\n+            ydl_opts = {\r\n+                'writesubtitles': True,\r\n+                'writeautomaticsub': True,\r\n+                'subtitleslangs': ['en'],\r\n+                'subtitlesformat': 'vtt',\r\n+                'skip_download': True,\r\n+                'quiet': True,\r\n+                'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n+                'impersonate': ImpersonateTarget('chrome'),\r\n+                'sleep_subtitles': 30\r\n+            }\r\n+            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n+                info = ydl.extract_info(url, download=False)\r\n+                video_id = info['id']\r\n+                ydl.download([url])\r\n+                vtt_file = os.path.join(tmpdir, f'transcript.{video_id}.en.vtt')\r\n+                if os.path.exists(vtt_file):\r\n+                    with open(vtt_file, \"r\", encoding=\"utf-8\") as f:\r\n+                        vtt_content = f.read()\r\n+                    transcript_text = re.sub(r'^\\d+\\n\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\\n', '', vtt_content)\r\n+                    transcript_text = re.sub(r'\\n\\n', '\\n', transcript_text).strip()\r\n+                    print(transcript_text)\r\n+                    break\r\n+                else:\r\n+                    print(\"No transcript available.\")\r\n+                    break\r\n+        break\r\n+    except yt_dlp.utils.DownloadError as e:\r\n+        if '429' in str(e):\r\n+            print(f\"Rate limit hit, retrying after 60s... (attempt {attempt+1}/{retries})\")\r\n+            time.sleep(60)\r\n         else:\r\n-            print(\"No transcript available.\")\n+            print(f\"Error: {e}\")\r\n+            break\r\n+else:\r\n+    print(\"Failed after retries.\")\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756921947245,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,50 +1,215 @@\n # youtube_utils.py\r\n-import yt_dlp\r\n-import tempfile\r\n import os\r\n import re\r\n-from yt_dlp.networking.impersonate import ImpersonateTarget\r\n import time\r\n+import tempfile\r\n+from urllib.parse import urlparse, parse_qs\r\n \r\n+# Method 1: yt-dlp\r\n+try:\r\n+    import yt_dlp\r\n+    from yt_dlp.networking.impersonate import ImpersonateTarget\r\n+except ImportError:\r\n+    print(\"yt-dlp not installed. Skipping Method 1.\")\r\n+\r\n+# Method 2: youtube-transcript-api\r\n+try:\r\n+    from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled\r\n+except ImportError:\r\n+    print(\"youtube-transcript-api not installed. Skipping Method 2.\")\r\n+\r\n+# Method 3: pytube\r\n+try:\r\n+    from pytube import YouTube\r\n+except ImportError:\r\n+    print(\"pytube not installed. Skipping Method 3.\")\r\n+\r\n+# Method 4: Selenium\r\n+try:\r\n+    from selenium import webdriver\r\n+    from selenium.webdriver.common.by import By\r\n+    from selenium.webdriver.support.ui import WebDriverWait\r\n+    from selenium.webdriver.support import expected_conditions as EC\r\n+    from bs4 import BeautifulSoup\r\n+except ImportError:\r\n+    print(\"selenium or bs4 not installed. Skipping Method 4.\")\r\n+\r\n url = 'https://www.youtube.com/watch?v=VxOQjqNgQ5E'\r\n \r\n-retries = 3\r\n-for attempt in range(retries):\r\n+def get_video_id(url):\r\n+    \"\"\"Extract video ID from URL\"\"\"\r\n+    parsed_url = urlparse(url)\r\n+    if parsed_url.hostname == 'youtu.be':\r\n+        return parsed_url.path[1:]\r\n+    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\r\n+        if parsed_url.path == '/watch':\r\n\\ No newline at end of file\n+            return parse_qs(parsed_url.query)['v'][0]\r\n+        if parsed_url.path.startswith('/embed/'):\r\n+            return parsed_url.path.split('/')[2]\r\n+        if parsed_url.path.startswith('/v/'):\r\n+            return parsed_url.path.split('/')[2]\r\n+    raise ValueError(\"Invalid YouTube URL\")\r\n+\r\n+video_id = get_video_id(url)\r\n+print(f\"Debug: Extracted video_id: {video_id}\")\r\n+\r\n+def method1_yt_dlp(url, retries=3, sleep_time=60):\r\n+    \"\"\"Method 1: Using yt-dlp with impersonation and retries\"\"\"\r\n+    print(\"Trying Method 1: yt-dlp\")\r\n+    for attempt in range(retries):\r\n+        try:\r\n+            with tempfile.TemporaryDirectory() as tmpdir:\r\n+                ydl_opts = {\r\n+                    'writesubtitles': True,\r\n+                    'writeautomaticsub': True,\r\n+                    'subtitleslangs': ['en'],\r\n+                    'subtitlesformat': 'vtt',\r\n+                    'skip_download': True,\r\n+                    'quiet': False,  # Set to True for less output, False for debug\r\n+                    'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n+                    'impersonate': ImpersonateTarget('chrome'),  # Try 'safari' or 'edge' if issues\r\n+                    'sleep_subtitles': 30,\r\n+                }\r\n+                print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n+                with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n+                    info = ydl.extract_info(url, download=False)\r\n+                    print(f\"Debug: Extracted info keys: {list(info.keys())}\")\r\n+                    if 'subtitles' in info or 'automatic_captions' in info:\r\n+                        print(\"Debug: Subtitles or auto captions available.\")\r\n+                    else:\r\n+                        print(\"Debug: No subtitles found in info.\")\r\n+                    ydl.download([url])\r\n+                    vtt_file = os.path.join(tmpdir, f'transcript.{info[\"id\"]}.en.vtt')\r\n+                    if os.path.exists(vtt_file):\r\n+                        with open(vtt_file, \"r\", encoding=\"utf-8\") as f:\r\n+                            vtt_content = f.read()\r\n+                        transcript_text = re.sub(r'^\\d+\\n\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\\n', '', vtt_content)\r\n+                        transcript_text = re.sub(r'\\n\\n', '\\n', transcript_text).strip()\r\n+                        print(\"Debug: Transcript extracted successfully with yt-dlp.\")\r\n+                        return transcript_text\r\n+                    else:\r\n+                        print(\"Debug: No VTT file generated.\")\r\n+            return None\r\n+        except yt_dlp.utils.DownloadError as e:\r\n+            print(f\"Error in yt-dlp: {e}\")\r\n+            if '429' in str(e):\r\n+                print(f\"Rate limit hit, retrying after {sleep_time}s... (attempt {attempt+1}/{retries})\")\r\n+                time.sleep(sleep_time)\r\n+            else:\r\n+                break\r\n+    print(\"Failed Method 1 after retries.\")\r\n+    return None\r\n+\r\n+def method2_youtube_transcript_api(video_id):\r\n+    \"\"\"Method 2: Using youtube-transcript-api\"\"\"\r\n+    print(\"Trying Method 2: youtube-transcript-api\")\r\n     try:\r\n-        with tempfile.TemporaryDirectory() as tmpdir:\r\n-            ydl_opts = {\r\n-                'writesubtitles': True,\r\n-                'writeautomaticsub': True,\r\n-                'subtitleslangs': ['en'],\r\n-                'subtitlesformat': 'vtt',\r\n-                'skip_download': True,\r\n-                'quiet': True,\r\n-                'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                'impersonate': ImpersonateTarget('chrome'),\r\n-                'sleep_subtitles': 30\r\n-            }\r\n-            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n-                info = ydl.extract_info(url, download=False)\r\n-                video_id = info['id']\r\n-                ydl.download([url])\r\n-                vtt_file = os.path.join(tmpdir, f'transcript.{video_id}.en.vtt')\r\n-                if os.path.exists(vtt_file):\r\n-                    with open(vtt_file, \"r\", encoding=\"utf-8\") as f:\r\n-                        vtt_content = f.read()\r\n-                    transcript_text = re.sub(r'^\\d+\\n\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\\n', '', vtt_content)\r\n-                    transcript_text = re.sub(r'\\n\\n', '\\n', transcript_text).strip()\r\n-                    print(transcript_text)\r\n-                    break\r\n-                else:\r\n-                    print(\"No transcript available.\")\r\n-                    break\r\n-        break\r\n-    except yt_dlp.utils.DownloadError as e:\r\n-        if '429' in str(e):\r\n-            print(f\"Rate limit hit, retrying after 60s... (attempt {attempt+1}/{retries})\")\r\n-            time.sleep(60)\r\n+        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\r\n+        print(f\"Debug: Available transcripts: {transcript_list}\")\r\n+        transcript = transcript_list.find_generated_transcript(['en']) or transcript_list.find_transcript(['en'])\r\n+        transcript_data = transcript.fetch()\r\n+        print(f\"Debug: Fetched {len(transcript_data)} transcript segments.\")\r\n+        transcript_text = '\\n'.join([item['text'] for item in transcript_data])\r\n+        print(\"Debug: Transcript extracted successfully with youtube-transcript-api.\")\r\n+        return transcript_text\r\n+    except (NoTranscriptFound, TranscriptsDisabled) as e:\r\n+        print(f\"Error: No transcript available - {e}\")\r\n+    except Exception as e:\r\n+        print(f\"Error in youtube-transcript-api: {e}\")\r\n+    return None\r\n+\r\n+def method3_pytube(url):\r\n+    \"\"\"Method 3: Using pytube\"\"\"\r\n+    print(\"Trying Method 3: pytube\")\r\n+    try:\r\n+        yt = YouTube(url)\r\n+        print(f\"Debug: Video title: {yt.title}\")\r\n+        captions = yt.captions\r\n+        print(f\"Debug: Available captions: {captions}\")\r\n+        if 'en' in captions:\r\n+            caption = captions['en']\r\n+        elif 'a.en' in captions:  # Auto-generated\r\n+            caption = captions['a.en']\r\n         else:\r\n-            print(f\"Error: {e}\")\r\n-            break\r\n+            print(\"Debug: No English captions found.\")\r\n+            return None\r\n+        srt = caption.generate_srt_captions()\r\n+        print(\"Debug: SRT captions generated.\")\r\n+        # Convert SRT to plain text\r\n+        lines = srt.split('\\n')\r\n+        transcript_text = ''\r\n+        for i in range(2, len(lines), 4):  # Skip index and time\r\n+            if i < len(lines):\r\n+                transcript_text += lines[i] + '\\n'\r\n+        print(\"Debug: Transcript extracted successfully with pytube.\")\r\n+        return transcript_text.strip()\r\n+    except Exception as e:\r\n+        print(f\"Error in pytube: {e}\")\r\n+    return None\r\n+\r\n+def method4_selenium(url, driver_path=None):\r\n+    \"\"\"Method 4: Using Selenium (requires Chrome/Firefox driver)\"\"\"\r\n+    print(\"Trying Method 4: Selenium\")\r\n+    try:\r\n+        # Assuming Firefox, change to Chrome if needed\r\n+        options = webdriver.FirefoxOptions()\r\n+        options.add_argument(\"--headless\")  # Headless mode\r\n+        driver = webdriver.Firefox(options=options)\r\n+        wait = WebDriverWait(driver, 10)\r\n+        driver.get(url)\r\n+        print(\"Debug: Loaded YouTube page.\")\r\n+\r\n+        # Click accept cookies if present (may vary)\r\n+        try:\r\n+            driver.find_element(By.CSS_SELECTOR, \"ytd-button-renderer.style-scope:nth-child(2) > a:nth-child(1)\").click()\r\n+            print(\"Debug: Accepted cookies.\")\r\n+        except:\r\n+            print(\"Debug: No cookies button found.\")\r\n+\r\n+        # Click 3 dots menu\r\n+        driver.find_element(By.CSS_SELECTOR, \"ytd-menu-renderer.ytd-video-primary-info-renderer > yt-icon-button:nth-child(2) > button:nth-child(1)\").click()\r\n+        print(\"Debug: Clicked menu.\")\r\n+\r\n+        # Click transcript\r\n+        wait.until(EC.element_to_be_clickable((By.TAG_NAME, \"ytd-menu-service-item-renderer\"))).click()\r\n+        print(\"Debug: Clicked show transcript.\")\r\n+\r\n+        # Wait for transcript panel\r\n+        wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"ytd-engagement-panel-section-list-renderer.style-scope\")))\r\n+        print(\"Debug: Transcript panel loaded.\")\r\n+\r\n+        # Get transcript elements\r\n+        transcript_elements = driver.find_elements(By.CSS_SELECTOR, \"div.cue.style-scope.ytd-transcript-body-renderer\")\r\n+        if not transcript_elements:\r\n+            print(\"Debug: No transcript elements found.\")\r\n+            driver.quit()\r\n+            return None\r\n+        transcript_text = '\\n'.join([elem.text.strip() for elem in transcript_elements])\r\n+        print(f\"Debug: Extracted {len(transcript_elements)} transcript lines.\")\r\n+        driver.quit()\r\n+        print(\"Debug: Transcript extracted successfully with Selenium.\")\r\n+        return transcript_text\r\n+    except Exception as e:\r\n+        print(f\"Error in Selenium: {e}\")\r\n+        if 'driver' in locals():\r\n+            driver.quit()\r\n+    return None\r\n+\r\n+# Try methods in sequence\r\n+transcript = method1_yt_dlp(url)\r\n+if transcript:\r\n+    print(\"Success with yt-dlp:\\n\", transcript)\r\n else:\r\n-    print(\"Failed after retries.\")\n+    transcript = method2_youtube_transcript_api(video_id)\r\n+    if transcript:\r\n+        print(\"Success with youtube-transcript-api:\\n\", transcript)\r\n+    else:\r\n+        transcript = method3_pytube(url)\r\n+        if transcript:\r\n+            print(\"Success with pytube:\\n\", transcript)\r\n+        else:\r\n+            transcript = method4_selenium(url)\r\n+            if transcript:\r\n+                print(\"Success with Selenium:\\n\", transcript)\r\n+            else:\r\n+                print(\"All methods failed.\")\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756922587710,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,26 +3,30 @@\n import re\r\n import time\r\n import tempfile\r\n from urllib.parse import urlparse, parse_qs\r\n+import shutil\r\n \r\n # Method 1: yt-dlp\r\n try:\r\n     import yt_dlp\r\n     from yt_dlp.networking.impersonate import ImpersonateTarget\r\n except ImportError:\r\n+    yt_dlp = None\r\n     print(\"yt-dlp not installed. Skipping Method 1.\")\r\n \r\n # Method 2: youtube-transcript-api\r\n try:\r\n     from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled\r\n except ImportError:\r\n+    YouTubeTranscriptApi = None\r\n     print(\"youtube-transcript-api not installed. Skipping Method 2.\")\r\n \r\n # Method 3: pytube\r\n try:\r\n     from pytube import YouTube\r\n except ImportError:\r\n+    YouTube = None\r\n     print(\"pytube not installed. Skipping Method 3.\")\r\n \r\n # Method 4: Selenium\r\n try:\r\n@@ -31,8 +35,9 @@\n     from selenium.webdriver.support.ui import WebDriverWait\r\n     from selenium.webdriver.support import expected_conditions as EC\r\n     from bs4 import BeautifulSoup\r\n except ImportError:\r\n+    webdriver = None\r\n     print(\"selenium or bs4 not installed. Skipping Method 4.\")\r\n \r\n url = 'https://www.youtube.com/watch?v=VxOQjqNgQ5E'\r\n \r\n@@ -52,10 +57,12 @@\n \r\n video_id = get_video_id(url)\r\n print(f\"Debug: Extracted video_id: {video_id}\")\r\n \r\n-def method1_yt_dlp(url, retries=3, sleep_time=60):\r\n+def method1_yt_dlp(url, retries=5, sleep_time=120):\r\n     \"\"\"Method 1: Using yt-dlp with impersonation and retries\"\"\"\r\n+    if yt_dlp is None:\r\n+        return None\r\n     print(\"Trying Method 1: yt-dlp\")\r\n     for attempt in range(retries):\r\n         try:\r\n             with tempfile.TemporaryDirectory() as tmpdir:\r\n@@ -66,10 +73,11 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('chrome'),  # Try 'safari' or 'edge' if issues\r\n-                    'sleep_subtitles': 30,\r\n+                    'impersonate': ImpersonateTarget('chrome:126'),  # Specify version\r\n+                    'sleep_subtitles': 60,  # Increased sleep\r\n+                    'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n                 with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n                     info = ydl.extract_info(url, download=False)\r\n@@ -80,8 +88,12 @@\n                         print(\"Debug: No subtitles found in info.\")\r\n                     ydl.download([url])\r\n                     vtt_file = os.path.join(tmpdir, f'transcript.{info[\"id\"]}.en.vtt')\r\n                     if os.path.exists(vtt_file):\r\n+                        # Save locally\r\n+                        local_vtt = os.path.join(os.getcwd(), f'transcript_{info[\"id\"]}.vtt')\r\n+                        shutil.copy(vtt_file, local_vtt)\r\n+                        print(f\"Debug: Saved VTT locally to {local_vtt}\")\r\n                         with open(vtt_file, \"r\", encoding=\"utf-8\") as f:\r\n                             vtt_content = f.read()\r\n                         transcript_text = re.sub(r'^\\d+\\n\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\\n', '', vtt_content)\r\n                         transcript_text = re.sub(r'\\n\\n', '\\n', transcript_text).strip()\r\n@@ -101,16 +113,15 @@\n     return None\r\n \r\n def method2_youtube_transcript_api(video_id):\r\n     \"\"\"Method 2: Using youtube-transcript-api\"\"\"\r\n+    if YouTubeTranscriptApi is None:\r\n+        return None\r\n     print(\"Trying Method 2: youtube-transcript-api\")\r\n     try:\r\n-        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\r\n-        print(f\"Debug: Available transcripts: {transcript_list}\")\r\n-        transcript = transcript_list.find_generated_transcript(['en']) or transcript_list.find_transcript(['en'])\r\n-        transcript_data = transcript.fetch()\r\n-        print(f\"Debug: Fetched {len(transcript_data)} transcript segments.\")\r\n-        transcript_text = '\\n'.join([item['text'] for item in transcript_data])\r\n+        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\r\n+        print(f\"Debug: Fetched {len(transcript)} transcript segments.\")\r\n+        transcript_text = '\\n'.join([item['text'] for item in transcript])\r\n         print(\"Debug: Transcript extracted successfully with youtube-transcript-api.\")\r\n         return transcript_text\r\n     except (NoTranscriptFound, TranscriptsDisabled) as e:\r\n         print(f\"Error: No transcript available - {e}\")\r\n@@ -119,68 +130,80 @@\n     return None\r\n \r\n def method3_pytube(url):\r\n     \"\"\"Method 3: Using pytube\"\"\"\r\n+    if YouTube is None:\r\n+        return None\r\n     print(\"Trying Method 3: pytube\")\r\n     try:\r\n         yt = YouTube(url)\r\n         print(f\"Debug: Video title: {yt.title}\")\r\n         captions = yt.captions\r\n         print(f\"Debug: Available captions: {captions}\")\r\n-        if 'en' in captions:\r\n-            caption = captions['en']\r\n-        elif 'a.en' in captions:  # Auto-generated\r\n-            caption = captions['a.en']\r\n-        else:\r\n+        caption_code = 'en' if 'en' in captions else 'a.en' if 'a.en' in captions else None\r\n+        if caption_code is None:\r\n             print(\"Debug: No English captions found.\")\r\n             return None\r\n+        caption = captions[caption_code]\r\n         srt = caption.generate_srt_captions()\r\n         print(\"Debug: SRT captions generated.\")\r\n         # Convert SRT to plain text\r\n         lines = srt.split('\\n')\r\n         transcript_text = ''\r\n-        for i in range(2, len(lines), 4):  # Skip index and time\r\n-            if i < len(lines):\r\n-                transcript_text += lines[i] + '\\n'\r\n+        i = 0\r\n+        while i < len(lines):\r\n+            if lines[i].isdigit():  # Index\r\n+                i += 1\r\n+                if i < len(lines) and '-->' in lines[i]:  # Time\r\n+                    i += 1\r\n+                    while i < len(lines) and lines[i].strip() != '':\r\n+                        transcript_text += lines[i] + ' '\r\n+                        i += 1\r\n+                    transcript_text += '\\n'\r\n+            i += 1\r\n         print(\"Debug: Transcript extracted successfully with pytube.\")\r\n         return transcript_text.strip()\r\n     except Exception as e:\r\n         print(f\"Error in pytube: {e}\")\r\n     return None\r\n \r\n-def method4_selenium(url, driver_path=None):\r\n+def method4_selenium(url):\r\n     \"\"\"Method 4: Using Selenium (requires Chrome/Firefox driver)\"\"\"\r\n+    if webdriver is None:\r\n+        return None\r\n     print(\"Trying Method 4: Selenium\")\r\n     try:\r\n-        # Assuming Firefox, change to Chrome if needed\r\n-        options = webdriver.FirefoxOptions()\r\n-        options.add_argument(\"--headless\")  # Headless mode\r\n-        driver = webdriver.Firefox(options=options)\r\n-        wait = WebDriverWait(driver, 10)\r\n+        options = webdriver.ChromeOptions()  # Change to FirefoxOptions if using Firefox\r\n+        options.add_argument(\"--headless=new\")  # Headless mode\r\n+        options.add_argument(\"--disable-gpu\")\r\n+        driver = webdriver.Chrome(options=options)\r\n+        wait = WebDriverWait(driver, 20)\r\n         driver.get(url)\r\n         print(\"Debug: Loaded YouTube page.\")\r\n \r\n-        # Click accept cookies if present (may vary)\r\n+        # Accept cookies if present\r\n         try:\r\n-            driver.find_element(By.CSS_SELECTOR, \"ytd-button-renderer.style-scope:nth-child(2) > a:nth-child(1)\").click()\r\n+            wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept all')]\"))).click()\r\n             print(\"Debug: Accepted cookies.\")\r\n         except:\r\n             print(\"Debug: No cookies button found.\")\r\n \r\n-        # Click 3 dots menu\r\n-        driver.find_element(By.CSS_SELECTOR, \"ytd-menu-renderer.ytd-video-primary-info-renderer > yt-icon-button:nth-child(2) > button:nth-child(1)\").click()\r\n-        print(\"Debug: Clicked menu.\")\r\n+        # Click more actions button\r\n+        more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n+        more_actions.click()\r\n+        print(\"Debug: Clicked More actions.\")\r\n \r\n-        # Click transcript\r\n-        wait.until(EC.element_to_be_clickable((By.TAG_NAME, \"ytd-menu-service-item-renderer\"))).click()\r\n-        print(\"Debug: Clicked show transcript.\")\r\n+        # Click transcript in menu\r\n+        transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//ytd-menu-service-item-renderer[contains(., \"Transcript\")]')))\r\n+        transcript_item.click()\r\n+        print(\"Debug: Clicked Transcript.\")\r\n \r\n         # Wait for transcript panel\r\n-        wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"ytd-engagement-panel-section-list-renderer.style-scope\")))\r\n+        wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"ytd-engagement-panel-section-list-renderer\")))\r\n         print(\"Debug: Transcript panel loaded.\")\r\n \r\n         # Get transcript elements\r\n-        transcript_elements = driver.find_elements(By.CSS_SELECTOR, \"div.cue.style-scope.ytd-transcript-body-renderer\")\r\n+        transcript_elements = driver.find_elements(By.CSS_SELECTOR, \"ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n         if not transcript_elements:\r\n             print(\"Debug: No transcript elements found.\")\r\n             driver.quit()\r\n             return None\r\n"
                },
                {
                    "date": 1756922729733,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('chrome:126'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('chrome:116'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756922756764,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('chrome:116'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('edge:101'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756922765487,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('edge:101'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('chrome:99'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756922771135,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('chrome:99'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('chrome'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756922805845,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,9 @@\n         except yt_dlp.utils.DownloadError as e:\r\n             print(f\"Error in yt-dlp: {e}\")\r\n             if '429' in str(e):\r\n                 print(f\"Rate limit hit, retrying after {sleep_time}s... (attempt {attempt+1}/{retries})\")\r\n-                time.sleep(sleep_time)\r\n+                time.sleep(2)\r\n             else:\r\n                 break\r\n     print(\"Failed Method 1 after retries.\")\r\n     return None\r\n"
                },
                {
                    "date": 1756922979226,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('chrome'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('firefox'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756923018735,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('firefox'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('chrome:140'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756923094630,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('chrome:140'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('chrome'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756923108748,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('chrome'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('web_safari'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756923141383,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('web_safari'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('chromium'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756923173111,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,11 +73,12 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('chromium'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget('chrome:126'),  # Specify version\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n-                    'cookiefile': 'www.youtube.com_cookies.txt'  # Use the cookies file from main folder\r\n+                    'cookiesfrombrowser': 'chrome',  # Extract cookies from Chrome browser\r\n+                    'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n                 with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n                     info = ydl.extract_info(url, download=False)\r\n@@ -105,9 +106,9 @@\n         except yt_dlp.utils.DownloadError as e:\r\n             print(f\"Error in yt-dlp: {e}\")\r\n             if '429' in str(e):\r\n                 print(f\"Rate limit hit, retrying after {sleep_time}s... (attempt {attempt+1}/{retries})\")\r\n-                time.sleep(2)\r\n+                time.sleep(sleep_time)\r\n             else:\r\n                 break\r\n     print(\"Failed Method 1 after retries.\")\r\n     return None\r\n@@ -117,11 +118,17 @@\n     if YouTubeTranscriptApi is None:\r\n         return None\r\n     print(\"Trying Method 2: youtube-transcript-api\")\r\n     try:\r\n-        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\r\n-        print(f\"Debug: Fetched {len(transcript)} transcript segments.\")\r\n-        transcript_text = '\\n'.join([item['text'] for item in transcript])\r\n+        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\r\n+        print(f\"Debug: Available transcripts: {transcript_list}\")\r\n+        try:\r\n+            transcript = transcript_list.find_generated_transcript(['en'])\r\n+        except NoTranscriptFound:\r\n+            transcript = transcript_list.find_transcript(['en'])\r\n+        transcript_data = transcript.fetch()\r\n+        print(f\"Debug: Fetched {len(transcript_data)} transcript segments.\")\r\n+        transcript_text = '\\n'.join([item['text'] for item in transcript_data])\r\n         print(\"Debug: Transcript extracted successfully with youtube-transcript-api.\")\r\n         return transcript_text\r\n     except (NoTranscriptFound, TranscriptsDisabled) as e:\r\n         print(f\"Error: No transcript available - {e}\")\r\n@@ -137,30 +144,20 @@\n     try:\r\n         yt = YouTube(url)\r\n         print(f\"Debug: Video title: {yt.title}\")\r\n         captions = yt.captions\r\n-        print(f\"Debug: Available captions: {captions}\")\r\n+        print(f\"Debug: Available captions: {list(captions.keys())}\")\r\n         caption_code = 'en' if 'en' in captions else 'a.en' if 'a.en' in captions else None\r\n         if caption_code is None:\r\n             print(\"Debug: No English captions found.\")\r\n             return None\r\n         caption = captions[caption_code]\r\n-        srt = caption.generate_srt_captions()\r\n-        print(\"Debug: SRT captions generated.\")\r\n-        # Convert SRT to plain text\r\n-        lines = srt.split('\\n')\r\n-        transcript_text = ''\r\n-        i = 0\r\n-        while i < len(lines):\r\n-            if lines[i].isdigit():  # Index\r\n-                i += 1\r\n-                if i < len(lines) and '-->' in lines[i]:  # Time\r\n-                    i += 1\r\n-                    while i < len(lines) and lines[i].strip() != '':\r\n-                        transcript_text += lines[i] + ' '\r\n-                        i += 1\r\n-                    transcript_text += '\\n'\r\n-            i += 1\r\n+        xml_captions = caption.xml_captions\r\n+        print(\"Debug: XML captions fetched.\")\r\n+        # Parse XML to plain text\r\n+        from xml.etree.ElementTree import fromstring\r\n+        tree = fromstring(xml_captions)\r\n+        transcript_text = '\\n'.join([p.text for p in tree.findall('.//p') if p.text])\r\n         print(\"Debug: Transcript extracted successfully with pytube.\")\r\n         return transcript_text.strip()\r\n     except Exception as e:\r\n         print(f\"Error in pytube: {e}\")\r\n@@ -175,9 +172,9 @@\n         options = webdriver.ChromeOptions()  # Change to FirefoxOptions if using Firefox\r\n         options.add_argument(\"--headless=new\")  # Headless mode\r\n         options.add_argument(\"--disable-gpu\")\r\n         driver = webdriver.Chrome(options=options)\r\n-        wait = WebDriverWait(driver, 20)\r\n+        wait = WebDriverWait(driver, 30)  # Increased timeout\r\n         driver.get(url)\r\n         print(\"Debug: Loaded YouTube page.\")\r\n \r\n         # Accept cookies if present\r\n@@ -186,26 +183,44 @@\n             print(\"Debug: Accepted cookies.\")\r\n         except:\r\n             print(\"Debug: No cookies button found.\")\r\n \r\n-        # Click more actions button\r\n-        more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n-        more_actions.click()\r\n-        print(\"Debug: Clicked More actions.\")\r\n+        # Expand description if needed\r\n+        try:\r\n+            description_more = wait.until(EC.element_to_be_clickable((By.ID, \"description-inline-expander\")))\r\n+            description_more.click()\r\n+            print(\"Debug: Expanded description.\")\r\n+        except:\r\n+            print(\"Debug: No need to expand description.\")\r\n \r\n-        # Click transcript in menu\r\n-        transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//ytd-menu-service-item-renderer[contains(., \"Transcript\")]')))\r\n-        transcript_item.click()\r\n-        print(\"Debug: Clicked Transcript.\")\r\n+        # Click show transcript button in description\r\n+        try:\r\n+            transcript_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//tp-yt-paper-button[contains(text(), 'Show transcript')]\")))\r\n+            transcript_button.click()\r\n+            print(\"Debug: Clicked Show transcript in description.\")\r\n+        except:\r\n+            print(\"Debug: No Show transcript button in description. Trying more actions.\")\r\n \r\n+            # Fallback to more actions\r\n+            more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n+            more_actions.click()\r\n+            print(\"Debug: Clicked More actions.\")\r\n+\r\n+            transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//tp-yt-paper-item[contains(text(), \"Show transcript\")]')))\r\n+            transcript_item.click()\r\n+            print(\"Debug: Clicked Transcript from menu.\")\r\n+\r\n         # Wait for transcript panel\r\n-        wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"ytd-engagement-panel-section-list-renderer\")))\r\n+        wait.until(EC.visibility_of_element_located((By.ID, \"panels\")))\r\n         print(\"Debug: Transcript panel loaded.\")\r\n \r\n         # Get transcript elements\r\n-        transcript_elements = driver.find_elements(By.CSS_SELECTOR, \"ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n+        transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n         if not transcript_elements:\r\n-            print(\"Debug: No transcript elements found.\")\r\n+            print(\"Debug: No transcript elements found. Trying alternative selector.\")\r\n+            transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".cue.style-scope.ytd-transcript-body-renderer\")\r\n+        if not transcript_elements:\r\n+            print(\"Debug: Still no transcript elements found.\")\r\n             driver.quit()\r\n             return None\r\n         transcript_text = '\\n'.join([elem.text.strip() for elem in transcript_elements])\r\n         print(f\"Debug: Extracted {len(transcript_elements)} transcript lines.\")\r\n"
                },
                {
                    "date": 1756923301639,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,11 +73,11 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget('chrome:126'),  # Specify version\r\n+                    'impersonate': ImpersonateTarget(client='chrome', version='126'),  # Fixed constructor\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n-                    'cookiesfrombrowser': 'chrome',  # Extract cookies from Chrome browser\r\n+                    'cookiesfrombrowser': ('chrome',),  # Extract cookies from Chrome browser, fixed to tuple\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n                 with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n@@ -118,15 +118,10 @@\n     if YouTubeTranscriptApi is None:\r\n         return None\r\n     print(\"Trying Method 2: youtube-transcript-api\")\r\n     try:\r\n-        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\r\n-        print(f\"Debug: Available transcripts: {transcript_list}\")\r\n-        try:\r\n-            transcript = transcript_list.find_generated_transcript(['en'])\r\n-        except NoTranscriptFound:\r\n-            transcript = transcript_list.find_transcript(['en'])\r\n-        transcript_data = transcript.fetch()\r\n+        # Fallback to get_transcript if list_transcripts not available\r\n+        transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\r\n         print(f\"Debug: Fetched {len(transcript_data)} transcript segments.\")\r\n         transcript_text = '\\n'.join([item['text'] for item in transcript_data])\r\n         print(\"Debug: Transcript extracted successfully with youtube-transcript-api.\")\r\n         return transcript_text\r\n@@ -175,45 +170,38 @@\n         driver = webdriver.Chrome(options=options)\r\n         wait = WebDriverWait(driver, 30)  # Increased timeout\r\n         driver.get(url)\r\n         print(\"Debug: Loaded YouTube page.\")\r\n-\r\n         # Accept cookies if present\r\n         try:\r\n             wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept all')]\"))).click()\r\n             print(\"Debug: Accepted cookies.\")\r\n         except:\r\n             print(\"Debug: No cookies button found.\")\r\n-\r\n         # Expand description if needed\r\n         try:\r\n             description_more = wait.until(EC.element_to_be_clickable((By.ID, \"description-inline-expander\")))\r\n             description_more.click()\r\n             print(\"Debug: Expanded description.\")\r\n         except:\r\n             print(\"Debug: No need to expand description.\")\r\n-\r\n         # Click show transcript button in description\r\n         try:\r\n             transcript_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//tp-yt-paper-button[contains(text(), 'Show transcript')]\")))\r\n             transcript_button.click()\r\n             print(\"Debug: Clicked Show transcript in description.\")\r\n         except:\r\n             print(\"Debug: No Show transcript button in description. Trying more actions.\")\r\n-\r\n             # Fallback to more actions\r\n             more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n             more_actions.click()\r\n             print(\"Debug: Clicked More actions.\")\r\n-\r\n             transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//tp-yt-paper-item[contains(text(), \"Show transcript\")]')))\r\n             transcript_item.click()\r\n             print(\"Debug: Clicked Transcript from menu.\")\r\n-\r\n         # Wait for transcript panel\r\n         wait.until(EC.visibility_of_element_located((By.ID, \"panels\")))\r\n         print(\"Debug: Transcript panel loaded.\")\r\n-\r\n         # Get transcript elements\r\n         transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n         if not transcript_elements:\r\n             print(\"Debug: No transcript elements found. Trying alternative selector.\")\r\n"
                },
                {
                    "date": 1756923532583,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,19 +27,8 @@\n except ImportError:\r\n     YouTube = None\r\n     print(\"pytube not installed. Skipping Method 3.\")\r\n \r\n-# Method 4: Selenium\r\n-try:\r\n-    from selenium import webdriver\r\n-    from selenium.webdriver.common.by import By\r\n-    from selenium.webdriver.support.ui import WebDriverWait\r\n-    from selenium.webdriver.support import expected_conditions as EC\r\n-    from bs4 import BeautifulSoup\r\n-except ImportError:\r\n-    webdriver = None\r\n-    print(\"selenium or bs4 not installed. Skipping Method 4.\")\r\n-\r\n url = 'https://www.youtube.com/watch?v=VxOQjqNgQ5E'\r\n \r\n def get_video_id(url):\r\n     \"\"\"Extract video ID from URL\"\"\"\r\n@@ -75,10 +64,9 @@\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n                     'impersonate': ImpersonateTarget(client='chrome', version='126'),  # Fixed constructor\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n-                    'cookiesfrombrowser': ('chrome',),  # Extract cookies from Chrome browser, fixed to tuple\r\n-                    'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n+                    'cookiefile': 'www.youtube.com_cookies.txt'  # Rely on manual cookies file\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n                 with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n                     info = ydl.extract_info(url, download=False)\r\n@@ -118,9 +106,9 @@\n     if YouTubeTranscriptApi is None:\r\n         return None\r\n     print(\"Trying Method 2: youtube-transcript-api\")\r\n     try:\r\n-        # Fallback to get_transcript if list_transcripts not available\r\n+        # Use get_transcript directly\r\n         transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\r\n         print(f\"Debug: Fetched {len(transcript_data)} transcript segments.\")\r\n         transcript_text = '\\n'.join([item['text'] for item in transcript_data])\r\n         print(\"Debug: Transcript extracted successfully with youtube-transcript-api.\")\r\n@@ -136,9 +124,9 @@\n     if YouTube is None:\r\n         return None\r\n     print(\"Trying Method 3: pytube\")\r\n     try:\r\n-        yt = YouTube(url)\r\n+        yt = YouTube(url, use_oauth=True, allow_oauth_cache=True)  # Enable OAuth for potential auth\r\n         print(f\"Debug: Video title: {yt.title}\")\r\n         captions = yt.captions\r\n         print(f\"Debug: Available captions: {list(captions.keys())}\")\r\n         caption_code = 'en' if 'en' in captions else 'a.en' if 'a.en' in captions else None\r\n@@ -157,71 +145,8 @@\n     except Exception as e:\r\n         print(f\"Error in pytube: {e}\")\r\n     return None\r\n \r\n-def method4_selenium(url):\r\n-    \"\"\"Method 4: Using Selenium (requires Chrome/Firefox driver)\"\"\"\r\n-    if webdriver is None:\r\n-        return None\r\n-    print(\"Trying Method 4: Selenium\")\r\n-    try:\r\n-        options = webdriver.ChromeOptions()  # Change to FirefoxOptions if using Firefox\r\n-        options.add_argument(\"--headless=new\")  # Headless mode\r\n-        options.add_argument(\"--disable-gpu\")\r\n-        driver = webdriver.Chrome(options=options)\r\n-        wait = WebDriverWait(driver, 30)  # Increased timeout\r\n-        driver.get(url)\r\n-        print(\"Debug: Loaded YouTube page.\")\r\n-        # Accept cookies if present\r\n-        try:\r\n-            wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Accept all')]\"))).click()\r\n-            print(\"Debug: Accepted cookies.\")\r\n-        except:\r\n-            print(\"Debug: No cookies button found.\")\r\n-        # Expand description if needed\r\n-        try:\r\n-            description_more = wait.until(EC.element_to_be_clickable((By.ID, \"description-inline-expander\")))\r\n-            description_more.click()\r\n-            print(\"Debug: Expanded description.\")\r\n-        except:\r\n-            print(\"Debug: No need to expand description.\")\r\n-        # Click show transcript button in description\r\n-        try:\r\n-            transcript_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//tp-yt-paper-button[contains(text(), 'Show transcript')]\")))\r\n-            transcript_button.click()\r\n-            print(\"Debug: Clicked Show transcript in description.\")\r\n-        except:\r\n-            print(\"Debug: No Show transcript button in description. Trying more actions.\")\r\n-            # Fallback to more actions\r\n-            more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n-            more_actions.click()\r\n-            print(\"Debug: Clicked More actions.\")\r\n-            transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//tp-yt-paper-item[contains(text(), \"Show transcript\")]')))\r\n-            transcript_item.click()\r\n-            print(\"Debug: Clicked Transcript from menu.\")\r\n-        # Wait for transcript panel\r\n-        wait.until(EC.visibility_of_element_located((By.ID, \"panels\")))\r\n-        print(\"Debug: Transcript panel loaded.\")\r\n-        # Get transcript elements\r\n-        transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n-        if not transcript_elements:\r\n-            print(\"Debug: No transcript elements found. Trying alternative selector.\")\r\n-            transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".cue.style-scope.ytd-transcript-body-renderer\")\r\n-        if not transcript_elements:\r\n-            print(\"Debug: Still no transcript elements found.\")\r\n-            driver.quit()\r\n-            return None\r\n-        transcript_text = '\\n'.join([elem.text.strip() for elem in transcript_elements])\r\n-        print(f\"Debug: Extracted {len(transcript_elements)} transcript lines.\")\r\n-        driver.quit()\r\n-        print(\"Debug: Transcript extracted successfully with Selenium.\")\r\n-        return transcript_text\r\n-    except Exception as e:\r\n-        print(f\"Error in Selenium: {e}\")\r\n-        if 'driver' in locals():\r\n-            driver.quit()\r\n-    return None\r\n-\r\n # Try methods in sequence\r\n transcript = method1_yt_dlp(url)\r\n if transcript:\r\n     print(\"Success with yt-dlp:\\n\", transcript)\r\n@@ -233,9 +158,5 @@\n         transcript = method3_pytube(url)\r\n         if transcript:\r\n             print(\"Success with pytube:\\n\", transcript)\r\n         else:\r\n-            transcript = method4_selenium(url)\r\n-            if transcript:\r\n-                print(\"Success with Selenium:\\n\", transcript)\r\n-            else:\r\n-                print(\"All methods failed.\")\n\\ No newline at end of file\n+            print(\"All methods failed.\")\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756923758134,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,9 +64,9 @@\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n                     'impersonate': ImpersonateTarget(client='chrome', version='126'),  # Fixed constructor\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n-                    'cookiefile': 'www.youtube.com_cookies.txt'  # Rely on manual cookies file\r\n+                    'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n                 with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n                     info = ydl.extract_info(url, download=False)\r\n@@ -106,9 +106,8 @@\n     if YouTubeTranscriptApi is None:\r\n         return None\r\n     print(\"Trying Method 2: youtube-transcript-api\")\r\n     try:\r\n-        # Use get_transcript directly\r\n         transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\r\n         print(f\"Debug: Fetched {len(transcript_data)} transcript segments.\")\r\n         transcript_text = '\\n'.join([item['text'] for item in transcript_data])\r\n         print(\"Debug: Transcript extracted successfully with youtube-transcript-api.\")\r\n@@ -124,9 +123,9 @@\n     if YouTube is None:\r\n         return None\r\n     print(\"Trying Method 3: pytube\")\r\n     try:\r\n-        yt = YouTube(url, use_oauth=True, allow_oauth_cache=True)  # Enable OAuth for potential auth\r\n+        yt = YouTube(url, use_oauth=True, allow_oauth_cache=True)  # Enable OAuth to avoid API issues\r\n         print(f\"Debug: Video title: {yt.title}\")\r\n         captions = yt.captions\r\n         print(f\"Debug: Available captions: {list(captions.keys())}\")\r\n         caption_code = 'en' if 'en' in captions else 'a.en' if 'a.en' in captions else None\r\n"
                },
                {
                    "date": 1756923882254,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget(client='chrome', version='126'),  # Fixed constructor\r\n+                    'impersonate': ImpersonateTarget(client='chrome', version='124', os='macos', os_version='14'),\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n@@ -123,9 +123,9 @@\n     if YouTube is None:\r\n         return None\r\n     print(\"Trying Method 3: pytube\")\r\n     try:\r\n-        yt = YouTube(url, use_oauth=True, allow_oauth_cache=True)  # Enable OAuth to avoid API issues\r\n+        yt = YouTube(url, use_oauth=True, allow_oauth_cache=True)  # Enable OAuth to avoid potential API issues\r\n         print(f\"Debug: Video title: {yt.title}\")\r\n         captions = yt.captions\r\n         print(f\"Debug: Available captions: {list(captions.keys())}\")\r\n         caption_code = 'en' if 'en' in captions else 'a.en' if 'a.en' in captions else None\r\n"
                },
                {
                    "date": 1756923921786,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,9 +46,9 @@\n \r\n video_id = get_video_id(url)\r\n print(f\"Debug: Extracted video_id: {video_id}\")\r\n \r\n-def method1_yt_dlp(url, retries=5, sleep_time=120):\r\n+def method1_yt_dlp(url, retries=0, sleep_time=120):\r\n     \"\"\"Method 1: Using yt-dlp with impersonation and retries\"\"\"\r\n     if yt_dlp is None:\r\n         return None\r\n     print(\"Trying Method 1: yt-dlp\")\r\n"
                },
                {
                    "date": 1756924098711,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,9 +46,9 @@\n \r\n video_id = get_video_id(url)\r\n print(f\"Debug: Extracted video_id: {video_id}\")\r\n \r\n-def method1_yt_dlp(url, retries=0, sleep_time=120):\r\n+def method1_yt_dlp(url, retries=5, sleep_time=120):\r\n     \"\"\"Method 1: Using yt-dlp with impersonation and retries\"\"\"\r\n     if yt_dlp is None:\r\n         return None\r\n     print(\"Trying Method 1: yt-dlp\")\r\n@@ -106,9 +106,11 @@\n     if YouTubeTranscriptApi is None:\r\n         return None\r\n     print(\"Trying Method 2: youtube-transcript-api\")\r\n     try:\r\n-        transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\r\n+        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\r\n+        transcript = transcript_list.find_generated_transcript(['en']) if transcript_list.find_generated_transcript(['en']) else transcript_list.find_transcript(['en'])\r\n+        transcript_data = transcript.fetch()\r\n         print(f\"Debug: Fetched {len(transcript_data)} transcript segments.\")\r\n         transcript_text = '\\n'.join([item['text'] for item in transcript_data])\r\n         print(\"Debug: Transcript extracted successfully with youtube-transcript-api.\")\r\n         return transcript_text\r\n"
                },
                {
                    "date": 1756924123709,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,9 +46,9 @@\n \r\n video_id = get_video_id(url)\r\n print(f\"Debug: Extracted video_id: {video_id}\")\r\n \r\n-def method1_yt_dlp(url, retries=5, sleep_time=120):\r\n+def method1_yt_dlp(url, retries=0, sleep_time=120):\r\n     \"\"\"Method 1: Using yt-dlp with impersonation and retries\"\"\"\r\n     if yt_dlp is None:\r\n         return None\r\n     print(\"Trying Method 1: yt-dlp\")\r\n"
                },
                {
                    "date": 1756924136371,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,9 +46,9 @@\n \r\n video_id = get_video_id(url)\r\n print(f\"Debug: Extracted video_id: {video_id}\")\r\n \r\n-def method1_yt_dlp(url, retries=0, sleep_time=120):\r\n+def method1_yt_dlp(url, retries=1, sleep_time=120):\r\n     \"\"\"Method 1: Using yt-dlp with impersonation and retries\"\"\"\r\n     if yt_dlp is None:\r\n         return None\r\n     print(\"Trying Method 1: yt-dlp\")\r\n"
                },
                {
                    "date": 1756924141941,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,9 +46,9 @@\n \r\n video_id = get_video_id(url)\r\n print(f\"Debug: Extracted video_id: {video_id}\")\r\n \r\n-def method1_yt_dlp(url, retries=1, sleep_time=120):\r\n+def method1_yt_dlp(url, retries=1, sleep_time=1):\r\n     \"\"\"Method 1: Using yt-dlp with impersonation and retries\"\"\"\r\n     if yt_dlp is None:\r\n         return None\r\n     print(\"Trying Method 1: yt-dlp\")\r\n"
                },
                {
                    "date": 1756924258563,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,9 +46,9 @@\n \r\n video_id = get_video_id(url)\r\n print(f\"Debug: Extracted video_id: {video_id}\")\r\n \r\n-def method1_yt_dlp(url, retries=1, sleep_time=1):\r\n+def method1_yt_dlp(url, retries=5, sleep_time=120):\r\n     \"\"\"Method 1: Using yt-dlp with impersonation and retries\"\"\"\r\n     if yt_dlp is None:\r\n         return None\r\n     print(\"Trying Method 1: yt-dlp\")\r\n@@ -62,9 +62,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget(client='chrome', version='124', os='macos', os_version='14'),\r\n+                    'impersonate': ImpersonateTarget(client='chrome', version='124', os='windows', os_version='10'),\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n@@ -106,11 +106,9 @@\n     if YouTubeTranscriptApi is None:\r\n         return None\r\n     print(\"Trying Method 2: youtube-transcript-api\")\r\n     try:\r\n-        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\r\n-        transcript = transcript_list.find_generated_transcript(['en']) if transcript_list.find_generated_transcript(['en']) else transcript_list.find_transcript(['en'])\r\n-        transcript_data = transcript.fetch()\r\n+        transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\r\n         print(f\"Debug: Fetched {len(transcript_data)} transcript segments.\")\r\n         transcript_text = '\\n'.join([item['text'] for item in transcript_data])\r\n         print(\"Debug: Transcript extracted successfully with youtube-transcript-api.\")\r\n         return transcript_text\r\n"
                },
                {
                    "date": 1756924294001,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget(client='chrome', version='124', os='windows', os_version='10'),\r\n+                    'impersonate': ImpersonateTarget(client='chrome', version='99', os='windows', os_version='10'),\r\n                     'sleep_subtitles': 60,  # Increased sleep\r\n                     'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n"
                },
                {
                    "date": 1756925106832,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,11 +62,18 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget(client='chrome', version='99', os='windows', os_version='10'),\r\n-                    'sleep_subtitles': 60,  # Increased sleep\r\n-                    'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n+                    'impersonate': ImpersonateTarget(client='chrome', version='124', os='windows', os_version='10'),\r\n+                    'sleep_subtitles': 60,  # Increased sleep for subtitles\r\n+                    'cookiefile': 'www.youtube.com_cookies.txt',  # Fallback to manual cookies file\r\n+                    'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',\r\n+                    'extractor_args': {'youtube': {'skip': ['hls', 'dash']}},\r\n+                    'ignore_no_formats': True,\r\n+                    'verbose': True,\r\n+                    'sleep_interval': 5,  # Sleep between requests\r\n+                    'sleep_requests': 5,  # Sleep between consecutive requests\r\n+                    'max_downloads': 1,  # Limit simultaneous\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n                 with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n                     info = ydl.extract_info(url, download=False)\r\n"
                },
                {
                    "date": 1756925264012,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,18 +62,11 @@\n                     'subtitlesformat': 'vtt',\r\n                     'skip_download': True,\r\n                     'quiet': False,  # Set to True for less output, False for debug\r\n                     'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget(client='chrome', version='124', os='windows', os_version='10'),\r\n-                    'sleep_subtitles': 60,  # Increased sleep for subtitles\r\n-                    'cookiefile': 'www.youtube.com_cookies.txt',  # Fallback to manual cookies file\r\n-                    'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36',\r\n-                    'extractor_args': {'youtube': {'skip': ['hls', 'dash']}},\r\n-                    'ignore_no_formats': True,\r\n-                    'verbose': True,\r\n-                    'sleep_interval': 5,  # Sleep between requests\r\n-                    'sleep_requests': 5,  # Sleep between consecutive requests\r\n-                    'max_downloads': 1,  # Limit simultaneous\r\n+                    'impersonate': ImpersonateTarget(client='chrome', version='116', os='windows', os_version='10'),\r\n+                    'sleep_subtitles': 60,  # Increased sleep\r\n+                    'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n                 }\r\n                 print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n                 with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n                     info = ydl.extract_info(url, download=False)\r\n"
                },
                {
                    "date": 1756935511898,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,161 +1,123 @@\n # youtube_utils.py\r\n-import os\r\n-import re\r\n import time\r\n-import tempfile\r\n-from urllib.parse import urlparse, parse_qs\r\n-import shutil\r\n+import spacy\r\n+import requests\r\n+import threading\r\n+from selenium import webdriver\r\n+from selenium.webdriver.common.by import By\r\n+from selenium.webdriver.support.ui import WebDriverWait\r\n+from selenium.webdriver.support import expected_conditions as EC\r\n+from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\r\n+from webdriver_manager.chrome import ChromeDriverManager\r\n+from selenium.webdriver.chrome.service import Service as ChromeService\r\n+from selenium.webdriver.chrome.options import Options\r\n+from langchain.text_splitter import RecursiveCharacterTextSplitter\r\n+from langchain_core.documents import Document\r\n+from config import MAX_URLS, FAISS_PATH, RAW_DIR\r\n+from web_utils import search_web\r\n+from db_utils import add_chunk_if_new, store_content, get_stored_content\r\n+from vectorstore_utils import vectorstore\r\n+from utils import lock\r\n+from urllib.parse import quote\r\n+import html\r\n \r\n-# Method 1: yt-dlp\r\n-try:\r\n-    import yt_dlp\r\n-    from yt_dlp.networking.impersonate import ImpersonateTarget\r\n-except ImportError:\r\n-    yt_dlp = None\r\n-    print(\"yt-dlp not installed. Skipping Method 1.\")\r\n+nlp = spacy.load(\"en_core_web_sm\")\r\n \r\n-# Method 2: youtube-transcript-api\r\n-try:\r\n-    from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, TranscriptsDisabled\r\n-except ImportError:\r\n-    YouTubeTranscriptApi = None\r\n-    print(\"youtube-transcript-api not installed. Skipping Method 2.\")\r\n+def fetch_youtube_transcript(url, use_ollama=False):\r\n+    yield (\"status\", f\"Fetching YouTube transcript for {url} with Ollama: {use_ollama}\")\r\n+    options = Options()\r\n+    options.add_argument('--disable-notifications')\r\n+    options.add_experimental_option('excludeSwitches', ['enable-logging'])\r\n+    options.add_argument('--log-level=3')\r\n+    service = ChromeService(ChromeDriverManager().install())\r\n+    driver = webdriver.Chrome(service=service, options=options)\r\n+    wait = WebDriverWait(driver, 30)\r\n \r\n-# Method 3: pytube\r\n-try:\r\n-    from pytube import YouTube\r\n-except ImportError:\r\n-    YouTube = None\r\n-    print(\"pytube not installed. Skipping Method 3.\")\r\n+    try:\r\n+        yield (\"status\", \"Step 1: Navigating to URL...\")\r\n+        driver.get(url)\r\n+        time.sleep(5)\r\n+        yield (\"status\", \"Step 1 completed: Page loaded.\")\r\n \r\n-url = 'https://www.youtube.com/watch?v=VxOQjqNgQ5E'\r\n+        # ... (rest of the function remains the same, with yield (\"status\", ...) for each step)\r\n \r\n-def get_video_id(url):\r\n-    \"\"\"Extract video ID from URL\"\"\"\r\n-    parsed_url = urlparse(url)\r\n-    if parsed_url.hostname == 'youtu.be':\r\n-        return parsed_url.path[1:]\r\n-    if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):\r\n-        if parsed_url.path == '/watch':\r\n-            return parse_qs(parsed_url.query)['v'][0]\r\n-        if parsed_url.path.startswith('/embed/'):\r\n-            return parsed_url.path.split('/')[2]\r\n-        if parsed_url.path.startswith('/v/'):\r\n-            return parsed_url.path.split('/')[2]\r\n-    raise ValueError(\"Invalid YouTube URL\")\r\n+        yield (\"transcript\", processed_text)\r\n \r\n-video_id = get_video_id(url)\r\n-print(f\"Debug: Extracted video_id: {video_id}\")\r\n+    finally:\r\n+        yield (\"status\", \"Final Step: Closing browser...\")\r\n+        time.sleep(5)\r\n+        driver.quit()\r\n+        yield (\"status\", \"Browser closed.\")\r\n \r\n-def method1_yt_dlp(url, retries=5, sleep_time=120):\r\n-    \"\"\"Method 1: Using yt-dlp with impersonation and retries\"\"\"\r\n-    if yt_dlp is None:\r\n-        return None\r\n-    print(\"Trying Method 1: yt-dlp\")\r\n-    for attempt in range(retries):\r\n-        try:\r\n-            with tempfile.TemporaryDirectory() as tmpdir:\r\n-                ydl_opts = {\r\n-                    'writesubtitles': True,\r\n-                    'writeautomaticsub': True,\r\n-                    'subtitleslangs': ['en'],\r\n-                    'subtitlesformat': 'vtt',\r\n-                    'skip_download': True,\r\n-                    'quiet': False,  # Set to True for less output, False for debug\r\n-                    'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n-                    'impersonate': ImpersonateTarget(client='chrome', version='116', os='windows', os_version='10'),\r\n-                    'sleep_subtitles': 60,  # Increased sleep\r\n-                    'cookiefile': 'www.youtube.com_cookies.txt'  # Fallback to manual cookies file\r\n-                }\r\n-                print(f\"Debug: yt-dlp options: {ydl_opts}\")\r\n-                with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n-                    info = ydl.extract_info(url, download=False)\r\n-                    print(f\"Debug: Extracted info keys: {list(info.keys())}\")\r\n-                    if 'subtitles' in info or 'automatic_captions' in info:\r\n-                        print(\"Debug: Subtitles or auto captions available.\")\r\n-                    else:\r\n-                        print(\"Debug: No subtitles found in info.\")\r\n-                    ydl.download([url])\r\n-                    vtt_file = os.path.join(tmpdir, f'transcript.{info[\"id\"]}.en.vtt')\r\n-                    if os.path.exists(vtt_file):\r\n-                        # Save locally\r\n-                        local_vtt = os.path.join(os.getcwd(), f'transcript_{info[\"id\"]}.vtt')\r\n-                        shutil.copy(vtt_file, local_vtt)\r\n-                        print(f\"Debug: Saved VTT locally to {local_vtt}\")\r\n-                        with open(vtt_file, \"r\", encoding=\"utf-8\") as f:\r\n-                            vtt_content = f.read()\r\n-                        transcript_text = re.sub(r'^\\d+\\n\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\\n', '', vtt_content)\r\n-                        transcript_text = re.sub(r'\\n\\n', '\\n', transcript_text).strip()\r\n-                        print(\"Debug: Transcript extracted successfully with yt-dlp.\")\r\n-                        return transcript_text\r\n-                    else:\r\n-                        print(\"Debug: No VTT file generated.\")\r\n-            return None\r\n-        except yt_dlp.utils.DownloadError as e:\r\n-            print(f\"Error in yt-dlp: {e}\")\r\n-            if '429' in str(e):\r\n-                print(f\"Rate limit hit, retrying after {sleep_time}s... (attempt {attempt+1}/{retries})\")\r\n-                time.sleep(sleep_time)\r\n+def run_youtube_collection(task_id, query, use_ollama, tasks, completed_collections, conn=None):\r\n+    print(f\"Starting YouTube collection task {task_id} for query: {query}\")\r\n+    try:\r\n+        response = \"\"\r\n+        history = [{\"role\": \"assistant\", \"content\": \"\"}]  # Dummy\r\n+        message = query\r\n+        tag = \"youtube_\" + query.replace(\" \", \"_\")\r\n+\r\n+        youtube_urls = search_web(query, site=\"youtube.com\")\r\n+        all_urls = list(set(youtube_urls))[:3]  # Limit\r\n+\r\n+        transcripts = []\r\n+        new_docs_total = 0\r\n+        for url in all_urls:\r\n+            stored = get_stored_content(conn, url)\r\n+            if stored:\r\n+                response += f\"Using stored transcript for {url}\\n\"\r\n             else:\r\n-                break\r\n-    print(\"Failed Method 1 after retries.\")\r\n-    return None\r\n\\ No newline at end of file\n+                gen = fetch_youtube_transcript(url, use_ollama=use_ollama)\r\n+                transcript = None\r\n+                for item in gen:\r\n+                    item_type, value = item\r\n+                    if item_type == \"status\":\r\n+                        response += value + \"\\n\"\r\n+                    elif item_type == \"transcript\":\r\n+                        transcript = value\r\n+                if transcript:\r\n+                    store_content(conn, url, transcript)\r\n+                    prefix = \"ollama_\" if use_ollama else \"\"\r\n+                    safe_filename = prefix + quote(url.replace(\"https://\", \"\").replace(\"http://\", \"\").replace(\"/\", \"_\")[:100]) + \".txt\"\r\n+                    filepath = os.path.join(RAW_DIR, safe_filename)\r\n+                    with open(filepath, \"w\", encoding=\"utf-8\") as f:\r\n+                        f.write(transcript)\r\n \r\n-def method2_youtube_transcript_api(video_id):\r\n-    \"\"\"Method 2: Using youtube-transcript-api\"\"\"\r\n-    if YouTubeTranscriptApi is None:\r\n-        return None\r\n-    print(\"Trying Method 2: youtube-transcript-api\")\r\n-    try:\r\n-        transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\r\n-        print(f\"Debug: Fetched {len(transcript_data)} transcript segments.\")\r\n-        transcript_text = '\\n'.join([item['text'] for item in transcript_data])\r\n-        print(\"Debug: Transcript extracted successfully with youtube-transcript-api.\")\r\n-        return transcript_text\r\n-    except (NoTranscriptFound, TranscriptsDisabled) as e:\r\n-        print(f\"Error: No transcript available - {e}\")\r\n-    except Exception as e:\r\n-        print(f\"Error in youtube-transcript-api: {e}\")\r\n-    return None\r\n+                    # HTML view\r\n+                    html_safe_filename = safe_filename.replace(\".txt\", \".html\")\r\n+                    html_filepath = os.path.join(RAW_DIR, html_safe_filename)\r\n+                    escaped_text = html.escape(transcript)\r\n+                    html_content = f\"\"\"<html><head><style>body {{ font-family: sans-serif; padding: 20px; line-height: 1.6; max-width: 800px; margin: auto; }} pre {{ white-space: pre-wrap; word-wrap: break-word; }}</style></head><body><h1>Processed Transcript for {url}</h1><pre>{escaped_text}</pre></body></html>\"\"\"\r\n+                    with open(html_filepath, \"w\", encoding=\"utf-8\") as f:\r\n+                        f.write(html_content)\r\n \r\n-def method3_pytube(url):\r\n-    \"\"\"Method 3: Using pytube\"\"\"\r\n-    if YouTube is None:\r\n-        return None\r\n-    print(\"Trying Method 3: pytube\")\r\n-    try:\r\n-        yt = YouTube(url, use_oauth=True, allow_oauth_cache=True)  # Enable OAuth to avoid potential API issues\r\n-        print(f\"Debug: Video title: {yt.title}\")\r\n-        captions = yt.captions\r\n-        print(f\"Debug: Available captions: {list(captions.keys())}\")\r\n-        caption_code = 'en' if 'en' in captions else 'a.en' if 'a.en' in captions else None\r\n-        if caption_code is None:\r\n-            print(\"Debug: No English captions found.\")\r\n-            return None\r\n-        caption = captions[caption_code]\r\n-        xml_captions = caption.xml_captions\r\n-        print(\"Debug: XML captions fetched.\")\r\n-        # Parse XML to plain text\r\n-        from xml.etree.ElementTree import fromstring\r\n-        tree = fromstring(xml_captions)\r\n-        transcript_text = '\\n'.join([p.text for p in tree.findall('.//p') if p.text])\r\n-        print(\"Debug: Transcript extracted successfully with pytube.\")\r\n-        return transcript_text.strip()\r\n+            if transcript:\r\n+                text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\r\n+                chunks = text_splitter.split_text(transcript)\r\n+                new_docs = []\r\n+                for chunk in chunks:\r\n+                    if add_chunk_if_new(conn, chunk, url, tag=tag):\r\n+                        metadata = {\"source\": url, \"tag\": tag}\r\n+                        new_docs.append(Document(page_content=chunk, metadata=metadata))\r\n+                if new_docs:\r\n+                    with lock:\r\n+                        vectorstore.add_documents(new_docs)\r\n+                        vectorstore.save_local(FAISS_PATH)\r\n+                    new_docs_total += len(new_docs)\r\n+\r\n+        tasks[task_id]['status'] = 'completed'\r\n+        tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added.\"\r\n+        tasks[task_id]['tag'] = tag\r\n+        completed_collections.append({'name': f\"YouTube - {query}\", 'tag': tag})\r\n+        print(f\"YouTube collection task {task_id} completed.\")\r\n     except Exception as e:\r\n-        print(f\"Error in pytube: {e}\")\r\n-    return None\r\n+        tasks[task_id]['status'] = 'error'\r\n+        tasks[task_id]['message'] = str(e)\r\n+        print(f\"YouTube collection task {task_id} error: {e}\")\r\n \r\n-# Try methods in sequence\r\n-transcript = method1_yt_dlp(url)\r\n-if transcript:\r\n-    print(\"Success with yt-dlp:\\n\", transcript)\r\n-else:\r\n-    transcript = method2_youtube_transcript_api(video_id)\r\n-    if transcript:\r\n-        print(\"Success with youtube-transcript-api:\\n\", transcript)\r\n-    else:\r\n-        transcript = method3_pytube(url)\r\n-        if transcript:\r\n-            print(\"Success with pytube:\\n\", transcript)\r\n-        else:\r\n-            print(\"All methods failed.\")\n+def start_youtube_collection(query, use_ollama, tasks, completed_collections, conn=None):\r\n+    task_id = len(tasks)\r\n+    task = {'id': task_id, 'type': 'youtube', 'query': query, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n+    tasks.append(task)\r\n+    threading.Thread(target=run_youtube_collection, args=(task_id, query, use_ollama, tasks, completed_collections, conn)).start()\r\n+    return \"YouTube collection started in background.\", tasks, completed_collections\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756936222090,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,8 +2,9 @@\n import time\r\n import spacy\r\n import requests\r\n import threading\r\n+import sqlite3\r\n from selenium import webdriver\r\n from selenium.webdriver.common.by import By\r\n from selenium.webdriver.support.ui import WebDriverWait\r\n from selenium.webdriver.support import expected_conditions as EC\r\n@@ -35,24 +36,180 @@\n \r\n     try:\r\n         yield (\"status\", \"Step 1: Navigating to URL...\")\r\n         driver.get(url)\r\n-        time.sleep(5)\r\n+        time.sleep(5)  # Reduced sleep, allow page to load\r\n         yield (\"status\", \"Step 1 completed: Page loaded.\")\r\n \r\n-        # ... (rest of the function remains the same, with yield (\"status\", ...) for each step)\r\n+        # Handle consent popup\r\n+        try:\r\n+            yield (\"status\", \"Step 2: Checking for consent popup...\")\r\n+            wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe[src*='consent.youtube.com']\")))\r\n+            accept_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Accept all') or contains(., 'I agree') or contains(@aria-label, 'Accept')]\")))\r\n+            try:\r\n+                accept_button.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", accept_button)\r\n+            driver.switch_to.default_content()\r\n+            yield (\"status\", \"Step 2 completed: Consent popup handled.\")\r\n+            time.sleep(3)  # Allow page to refresh after consent\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 2: No consent popup found or already handled.\")\r\n \r\n+        # Expand description\r\n+        try:\r\n+            yield (\"status\", \"Step 3: Expanding description...\")\r\n+            expander_xpath = \"//ytd-text-inline-expander[@id='description-inline-expander']//tp-yt-paper-button[@id='expand']\"\r\n+            description_expander = wait.until(EC.element_to_be_clickable((By.XPATH, expander_xpath)))\r\n+            try:\r\n+                description_expander.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", description_expander)\r\n+            time.sleep(3)\r\n+            yield (\"status\", \"Step 3 completed: Description expanded.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 3: Description may already be expanded or not found.\")\r\n+\r\n+        # Click 'Show transcript'\r\n+        try:\r\n+            yield (\"status\", \"Step 4: Clicking 'Show transcript' button...\")\r\n+            transcript_button_xpath = \"//ytd-video-description-transcript-section-renderer//ytd-button-renderer/yt-button-shape/button\"\r\n+            transcript_button = wait.until(EC.element_to_be_clickable((By.XPATH, transcript_button_xpath)))\r\n+            try:\r\n+                transcript_button.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", transcript_button)\r\n+            time.sleep(3)\r\n+            yield (\"status\", \"Step 4 completed: 'Show transcript' clicked.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 4: No 'Show transcript' button found in description. Trying fallback method...\")\r\n+            # Fallback to more actions menu\r\n+            try:\r\n+                more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n+                try:\r\n+                    more_actions.click()\r\n+                except ElementClickInterceptedException:\r\n+                    driver.execute_script(\"arguments[0].click();\", more_actions)\r\n+                time.sleep(1)\r\n+                transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//tp-yt-paper-item[contains(text(), \"Show transcript\")]')))\r\n+                try:\r\n+                    transcript_item.click()\r\n+                except ElementClickInterceptedException:\r\n+                    driver.execute_script(\"arguments[0].click();\", transcript_item)\r\n+                time.sleep(3)\r\n+                yield (\"status\", \"Step 4 completed: 'Show transcript' clicked via fallback.\")\r\n+            except TimeoutException:\r\n+                yield (\"status\", f\"Error: Could not find 'Show transcript' for {url}\")\r\n+                return\r\n+\r\n+        # Wait for transcript panel\r\n+        try:\r\n+            yield (\"status\", \"Step 5: Waiting for transcript panel to load...\")\r\n+            transcript_title_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//yt-formatted-string[@id='title-text']\"\r\n+            wait.until(EC.visibility_of_element_located((By.XPATH, transcript_title_xpath)))\r\n+            time.sleep(2)\r\n+            yield (\"status\", \"Step 5 completed: Transcript panel loaded.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", f\"Error: Transcript panel did not load for {url}\")\r\n+            return\r\n+\r\n+        # Extract transcript\r\n+        try:\r\n+            yield (\"status\", \"Step 6: Extracting transcript text...\")\r\n+            transcript_elements_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//ytd-transcript-segment-renderer//yt-formatted-string\"\r\n+            transcript_elements = driver.find_elements(By.XPATH, transcript_elements_xpath)\r\n+            if not transcript_elements:\r\n+                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n+            if not transcript_elements:\r\n+                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".cue.style-scope.ytd-transcript-body-renderer\")\r\n+            if not transcript_elements:\r\n+                yield (\"status\", f\"Error: No transcript elements found for {url}\")\r\n+                return\r\n+            transcript_text = '\\n'.join([elem.text.strip() for elem in transcript_elements if elem.text.strip()])\r\n+            yield (\"status\", f\"Step 6 completed: Extracted {len(transcript_text.splitlines())} lines of transcript.\")\r\n+        except NoSuchElementException:\r\n+            yield (\"status\", f\"Error: Transcript elements not found for {url}\")\r\n+            return\r\n+\r\n+        # NLP Processing\r\n+        yield (\"status\", \"Step 7: Processing transcript with NLP...\")\r\n+        doc = nlp(transcript_text)\r\n+        processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.text.strip()]\r\n+        processed_text = ' '.join(processed_tokens)\r\n+        yield (\"status\", \"Step 7 completed: NLP processing done.\")\r\n+\r\n+        # Chunking\r\n+        yield (\"status\", \"Step 8: Chunking transcript...\")\r\n+        sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\r\n+        chunk_size = 200  # Words per chunk\r\n+        chunks = []\r\n+        current_chunk = []\r\n+        current_word_count = 0\r\n+        for sent in sentences:\r\n+            word_count = len(sent.split())\r\n+            if current_word_count + word_count > chunk_size:\r\n+                chunks.append(' '.join(current_chunk))\r\n+                current_chunk = [sent]\r\n+                current_word_count = word_count\r\n+            else:\r\n+                current_chunk.append(sent)\r\n+                current_word_count += word_count\r\n+        if current_chunk:\r\n+            chunks.append(' '.join(current_chunk))\r\n+        yield (\"status\", f\"Step 8 completed: Created {len(chunks)} chunks.\")\r\n+\r\n+        # Optional Ollama enhancement\r\n+        if use_ollama:\r\n+            yield (\"status\", \"Step 9: Enhancing chunks with Ollama...\")\r\n+            ollama_url = \"http://localhost:11434/api/generate\"\r\n+            enhanced_chunks = []\r\n+            for i, chunk in enumerate(chunks):\r\n+                yield (\"status\", f\"Enhancing chunk {i+1}/{len(chunks)}...\")\r\n+                payload = {\r\n+                    \"model\": \"qwen2.5:7b\",\r\n+                    \"prompt\": f\"Enhance and correct this transcript chunk for clarity and accuracy: {chunk}. Include only the corrected text, do not include a summarization of the changes.\",\r\n+                    \"stream\": False\r\n+                }\r\n+                try:\r\n+                    response = requests.post(ollama_url, json=payload, timeout=30)\r\n+                    if response.status_code == 200:\r\n+                        enhanced_text = response.json()['response']\r\n+                        enhanced_chunks.append(enhanced_text)\r\n+                        yield (\"status\", f\"Chunk {i+1} enhanced.\")\r\n+                    else:\r\n+                        yield (\"status\", f\"Error enhancing chunk {i+1} with Ollama: {response.text}\")\r\n+                        enhanced_chunks.append(chunk)  # Fallback\r\n+                except requests.exceptions.RequestException as e:\r\n+                    yield (\"status\", f\"Ollama request failed for chunk {i+1}: {e}. Falling back to original chunk.\")\r\n+                    enhanced_chunks.append(chunk)\r\n+            processed_text = '\\n\\n'.join(enhanced_chunks)\r\n+            yield (\"status\", \"Step 9 completed: Ollama enhancement done.\")\r\n+\r\n         yield (\"transcript\", processed_text)\r\n \r\n     finally:\r\n         yield (\"status\", \"Final Step: Closing browser...\")\r\n         time.sleep(5)\r\n         driver.quit()\r\n         yield (\"status\", \"Browser closed.\")\r\n \r\n-def run_youtube_collection(task_id, query, use_ollama, tasks, completed_collections, conn=None):\r\n+def run_youtube_collection(task_id, query, use_ollama, tasks, completed_collections):\r\n     print(f\"Starting YouTube collection task {task_id} for query: {query}\")\r\n+    conn = sqlite3.connect('crawled.db')\r\n+    c = conn.cursor()\r\n+    c.execute('''CREATE TABLE IF NOT EXISTS urls\r\n+                 (url TEXT PRIMARY KEY, timestamp DATETIME, cleaned_text TEXT)''')\r\n+    c.execute('''CREATE TABLE IF NOT EXISTS chunks\r\n+                 (hash TEXT PRIMARY KEY, content TEXT, source TEXT, tag TEXT)''')\r\n     try:\r\n+        c.execute(\"ALTER TABLE chunks ADD COLUMN tag TEXT\")\r\n+        print(\"Added 'tag' column to chunks table.\")\r\n+    except sqlite3.OperationalError as e:\r\n+        if \"duplicate column name\" not in str(e):\r\n+            raise e\r\n+        print(\"'tag' column already exists in chunks table.\")\r\n+    conn.commit()\r\n+    try:\r\n         response = \"\"\r\n         history = [{\"role\": \"assistant\", \"content\": \"\"}]  # Dummy\r\n         message = query\r\n         tag = \"youtube_\" + query.replace(\" \", \"_\")\r\n@@ -65,8 +222,9 @@\n         for url in all_urls:\r\n             stored = get_stored_content(conn, url)\r\n             if stored:\r\n                 response += f\"Using stored transcript for {url}\\n\"\r\n+                transcript = stored\r\n             else:\r\n                 gen = fetch_youtube_transcript(url, use_ollama=use_ollama)\r\n                 transcript = None\r\n                 for item in gen:\r\n@@ -113,11 +271,13 @@\n     except Exception as e:\r\n         tasks[task_id]['status'] = 'error'\r\n         tasks[task_id]['message'] = str(e)\r\n         print(f\"YouTube collection task {task_id} error: {e}\")\r\n+    finally:\r\n+        conn.close()\r\n \r\n-def start_youtube_collection(query, use_ollama, tasks, completed_collections, conn=None):\r\n+def start_youtube_collection(query, use_ollama, tasks, completed_collections):\r\n     task_id = len(tasks)\r\n     task = {'id': task_id, 'type': 'youtube', 'query': query, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n     tasks.append(task)\r\n-    threading.Thread(target=run_youtube_collection, args=(task_id, query, use_ollama, tasks, completed_collections, conn)).start()\r\n+    threading.Thread(target=run_youtube_collection, args=(task_id, query, use_ollama, tasks, completed_collections)).start()\r\n     return \"YouTube collection started in background.\", tasks, completed_collections\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756936516076,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -182,8 +182,10 @@\n                     yield (\"status\", f\"Ollama request failed for chunk {i+1}: {e}. Falling back to original chunk.\")\r\n                     enhanced_chunks.append(chunk)\r\n             processed_text = '\\n\\n'.join(enhanced_chunks)\r\n             yield (\"status\", \"Step 9 completed: Ollama enhancement done.\")\r\n+        else:\r\n+            processed_text = ' '.join(processed_tokens)\r\n \r\n         yield (\"transcript\", processed_text)\r\n \r\n     finally:\r\n@@ -263,9 +265,9 @@\n                         vectorstore.save_local(FAISS_PATH)\r\n                     new_docs_total += len(new_docs)\r\n \r\n         tasks[task_id]['status'] = 'completed'\r\n-        tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added.\"\r\n+        tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n         tasks[task_id]['tag'] = tag\r\n         completed_collections.append({'name': f\"YouTube - {query}\", 'tag': tag})\r\n         print(f\"YouTube collection task {task_id} completed.\")\r\n     except Exception as e:\r\n"
                },
                {
                    "date": 1756937099507,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,8 +20,9 @@\n from vectorstore_utils import vectorstore\r\n from utils import lock\r\n from urllib.parse import quote\r\n import html\r\n+import os\r\n \r\n nlp = spacy.load(\"en_core_web_sm\")\r\n \r\n def fetch_youtube_transcript(url, use_ollama=False):\r\n"
                },
                {
                    "date": 1756937379036,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -194,10 +194,10 @@\n         time.sleep(5)\r\n         driver.quit()\r\n         yield (\"status\", \"Browser closed.\")\r\n \r\n-def run_youtube_collection(task_id, query, use_ollama, tasks, completed_collections):\r\n-    print(f\"Starting YouTube collection task {task_id} for query: {query}\")\r\n+def run_youtube_collection(task_id, query, url_list, use_ollama, tasks, completed_collections):\r\n+    print(f\"Starting YouTube collection task {task_id} for query: {query} or URLs: {url_list}\")\r\n     conn = sqlite3.connect('crawled.db')\r\n     c = conn.cursor()\r\n     c.execute('''CREATE TABLE IF NOT EXISTS urls\r\n                  (url TEXT PRIMARY KEY, timestamp DATETIME, cleaned_text TEXT)''')\r\n@@ -213,13 +213,16 @@\n     conn.commit()\r\n     try:\r\n         response = \"\"\r\n         history = [{\"role\": \"assistant\", \"content\": \"\"}]  # Dummy\r\n-        message = query\r\n-        tag = \"youtube_\" + query.replace(\" \", \"_\")\r\n+        message = query or \"custom_urls\"\r\n+        tag = \"youtube_\" + message.replace(\" \", \"_\")\r\n \r\n-        youtube_urls = search_web(query, site=\"youtube.com\")\r\n-        all_urls = list(set(youtube_urls))[:3]  # Limit\r\n+        if query:\r\n+            youtube_urls = search_web(query, site=\"youtube.com\")\r\n+            all_urls = list(set(youtube_urls))[:3]  # Limit\r\n+        else:\r\n+            all_urls = [url.strip() for url in url_list if url.strip()]\r\n \r\n         transcripts = []\r\n         new_docs_total = 0\r\n         for url in all_urls:\r\n@@ -268,19 +271,19 @@\n \r\n         tasks[task_id]['status'] = 'completed'\r\n         tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n         tasks[task_id]['tag'] = tag\r\n-        completed_collections.append({'name': f\"YouTube - {query}\", 'tag': tag})\r\n+        completed_collections.append({'name': f\"YouTube - {message}\", 'tag': tag})\r\n         print(f\"YouTube collection task {task_id} completed.\")\r\n     except Exception as e:\r\n         tasks[task_id]['status'] = 'error'\r\n         tasks[task_id]['message'] = str(e)\r\n         print(f\"YouTube collection task {task_id} error: {e}\")\r\n     finally:\r\n         conn.close()\r\n \r\n-def start_youtube_collection(query, use_ollama, tasks, completed_collections):\r\n+def start_youtube_collection(mode, query, url_list, use_ollama, tasks, completed_collections):\r\n     task_id = len(tasks)\r\n-    task = {'id': task_id, 'type': 'youtube', 'query': query, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n+    task = {'id': task_id, 'type': 'youtube', 'mode': mode, 'query': query, 'url_list': url_list, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n     tasks.append(task)\r\n-    threading.Thread(target=run_youtube_collection, args=(task_id, query, use_ollama, tasks, completed_collections)).start()\r\n+    threading.Thread(target=run_youtube_collection, args=(task_id, query, url_list, use_ollama, tasks, completed_collections)).start()\r\n     return \"YouTube collection started in background.\", tasks, completed_collections\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756937879030,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,4 @@\n-# youtube_utils.py\r\n import time\r\n import spacy\r\n import requests\r\n import threading\r\n@@ -32,17 +31,16 @@\n     options.add_experimental_option('excludeSwitches', ['enable-logging'])\r\n     options.add_argument('--log-level=3')\r\n     service = ChromeService(ChromeDriverManager().install())\r\n     driver = webdriver.Chrome(service=service, options=options)\r\n-    wait = WebDriverWait(driver, 30)\r\n+    wait = WebDriverWait(driver, 10)  # Reduced timeout for faster failure\r\n \r\n     try:\r\n         yield (\"status\", \"Step 1: Navigating to URL...\")\r\n         driver.get(url)\r\n-        time.sleep(5)  # Reduced sleep, allow page to load\r\n         yield (\"status\", \"Step 1 completed: Page loaded.\")\r\n \r\n-        # Handle consent popup\r\n+        # Handle consent popup with wait instead of sleep\r\n         try:\r\n             yield (\"status\", \"Step 2: Checking for consent popup...\")\r\n             wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe[src*='consent.youtube.com']\")))\r\n             accept_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Accept all') or contains(., 'I agree') or contains(@aria-label, 'Accept')]\")))\r\n@@ -51,9 +49,8 @@\n             except ElementClickInterceptedException:\r\n                 driver.execute_script(\"arguments[0].click();\", accept_button)\r\n             driver.switch_to.default_content()\r\n             yield (\"status\", \"Step 2 completed: Consent popup handled.\")\r\n-            time.sleep(3)  # Allow page to refresh after consent\r\n         except TimeoutException:\r\n             yield (\"status\", \"Step 2: No consent popup found or already handled.\")\r\n \r\n         # Expand description\r\n@@ -64,9 +61,8 @@\n             try:\r\n                 description_expander.click()\r\n             except ElementClickInterceptedException:\r\n                 driver.execute_script(\"arguments[0].click();\", description_expander)\r\n-            time.sleep(3)\r\n             yield (\"status\", \"Step 3 completed: Description expanded.\")\r\n         except TimeoutException:\r\n             yield (\"status\", \"Step 3: Description may already be expanded or not found.\")\r\n \r\n@@ -78,9 +74,8 @@\n             try:\r\n                 transcript_button.click()\r\n             except ElementClickInterceptedException:\r\n                 driver.execute_script(\"arguments[0].click();\", transcript_button)\r\n-            time.sleep(3)\r\n             yield (\"status\", \"Step 4 completed: 'Show transcript' clicked.\")\r\n         except TimeoutException:\r\n             yield (\"status\", \"Step 4: No 'Show transcript' button found in description. Trying fallback method...\")\r\n             # Fallback to more actions menu\r\n@@ -89,15 +84,13 @@\n                 try:\r\n                     more_actions.click()\r\n                 except ElementClickInterceptedException:\r\n                     driver.execute_script(\"arguments[0].click();\", more_actions)\r\n-                time.sleep(1)\r\n                 transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//tp-yt-paper-item[contains(text(), \"Show transcript\")]')))\r\n                 try:\r\n                     transcript_item.click()\r\n                 except ElementClickInterceptedException:\r\n                     driver.execute_script(\"arguments[0].click();\", transcript_item)\r\n-                time.sleep(3)\r\n                 yield (\"status\", \"Step 4 completed: 'Show transcript' clicked via fallback.\")\r\n             except TimeoutException:\r\n                 yield (\"status\", f\"Error: Could not find 'Show transcript' for {url}\")\r\n                 return\r\n@@ -106,9 +99,8 @@\n         try:\r\n             yield (\"status\", \"Step 5: Waiting for transcript panel to load...\")\r\n             transcript_title_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//yt-formatted-string[@id='title-text']\"\r\n             wait.until(EC.visibility_of_element_located((By.XPATH, transcript_title_xpath)))\r\n-            time.sleep(2)\r\n             yield (\"status\", \"Step 5 completed: Transcript panel loaded.\")\r\n         except TimeoutException:\r\n             yield (\"status\", f\"Error: Transcript panel did not load for {url}\")\r\n             return\r\n@@ -190,9 +182,8 @@\n         yield (\"transcript\", processed_text)\r\n \r\n     finally:\r\n         yield (\"status\", \"Final Step: Closing browser...\")\r\n-        time.sleep(5)\r\n         driver.quit()\r\n         yield (\"status\", \"Browser closed.\")\r\n \r\n def run_youtube_collection(task_id, query, url_list, use_ollama, tasks, completed_collections):\r\n"
                },
                {
                    "date": 1756938024899,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,4 +1,5 @@\n+# youtube_utils.py\r\n import time\r\n import spacy\r\n import requests\r\n import threading\r\n@@ -185,9 +186,9 @@\n         yield (\"status\", \"Final Step: Closing browser...\")\r\n         driver.quit()\r\n         yield (\"status\", \"Browser closed.\")\r\n \r\n-def run_youtube_collection(task_id, query, url_list, use_ollama, tasks, completed_collections):\r\n+def run_youtube_collection(task_id, custom_name, query, url_list, use_ollama, tasks, completed_collections):\r\n     print(f\"Starting YouTube collection task {task_id} for query: {query} or URLs: {url_list}\")\r\n     conn = sqlite3.connect('crawled.db')\r\n     c = conn.cursor()\r\n     c.execute('''CREATE TABLE IF NOT EXISTS urls\r\n@@ -206,8 +207,9 @@\n         response = \"\"\r\n         history = [{\"role\": \"assistant\", \"content\": \"\"}]  # Dummy\r\n         message = query or \"custom_urls\"\r\n         tag = \"youtube_\" + message.replace(\" \", \"_\")\r\n+        name = custom_name or f\"YouTube - {message}\"\r\n \r\n         if query:\r\n             youtube_urls = search_web(query, site=\"youtube.com\")\r\n             all_urls = list(set(youtube_urls))[:3]  # Limit\r\n@@ -262,19 +264,19 @@\n \r\n         tasks[task_id]['status'] = 'completed'\r\n         tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n         tasks[task_id]['tag'] = tag\r\n-        completed_collections.append({'name': f\"YouTube - {message}\", 'tag': tag})\r\n+        completed_collections.append({'name': name, 'tag': tag})\r\n         print(f\"YouTube collection task {task_id} completed.\")\r\n     except Exception as e:\r\n         tasks[task_id]['status'] = 'error'\r\n         tasks[task_id]['message'] = str(e)\r\n         print(f\"YouTube collection task {task_id} error: {e}\")\r\n     finally:\r\n         conn.close()\r\n \r\n-def start_youtube_collection(mode, query, url_list, use_ollama, tasks, completed_collections):\r\n+def start_youtube_collection(custom_name, mode, query, url_list, use_ollama, tasks, completed_collections):\r\n     task_id = len(tasks)\r\n-    task = {'id': task_id, 'type': 'youtube', 'mode': mode, 'query': query, 'url_list': url_list, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n+    task = {'id': task_id, 'type': 'youtube', 'custom_name': custom_name, 'mode': mode, 'query': query, 'url_list': url_list, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n     tasks.append(task)\r\n-    threading.Thread(target=run_youtube_collection, args=(task_id, query, url_list, use_ollama, tasks, completed_collections)).start()\r\n+    threading.Thread(target=run_youtube_collection, args=(task_id, custom_name, query, url_list, use_ollama, tasks, completed_collections)).start()\r\n     return \"YouTube collection started in background.\", tasks, completed_collections\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756938406887,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -217,9 +217,11 @@\n             all_urls = [url.strip() for url in url_list if url.strip()]\r\n \r\n         transcripts = []\r\n         new_docs_total = 0\r\n-        for url in all_urls:\r\n+        for i, url in enumerate(all_urls):\r\n+            print(f\"Processing URL {i+1}/{len(all_urls)}: {url}\")\r\n+            tasks[task_id]['message'] = f\"Processing URL {i+1}/{len(all_urls)}: {url}\"\r\n             stored = get_stored_content(conn, url)\r\n             if stored:\r\n                 response += f\"Using stored transcript for {url}\\n\"\r\n                 transcript = stored\r\n"
                },
                {
                    "date": 1756941032309,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,9 +16,9 @@\n from langchain_core.documents import Document\r\n from config import MAX_URLS, FAISS_PATH, RAW_DIR\r\n from web_utils import search_web\r\n from db_utils import add_chunk_if_new, store_content, get_stored_content\r\n-from vectorstore_utils import vectorstore\r\n+from vectorstore_manager import get_vectorstore\r\n from utils import lock\r\n from urllib.parse import quote\r\n import html\r\n import os\r\n@@ -259,10 +259,10 @@\n                         metadata = {\"source\": url, \"tag\": tag}\r\n                         new_docs.append(Document(page_content=chunk, metadata=metadata))\r\n                 if new_docs:\r\n                     with lock:\r\n-                        vectorstore.add_documents(new_docs)\r\n-                        vectorstore.save_local(FAISS_PATH)\r\n+                        vs = get_vectorstore(tag)\r\n+                        vs.add_documents(new_docs)\r\n                     new_docs_total += len(new_docs)\r\n \r\n         tasks[task_id]['status'] = 'completed'\r\n         tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n"
                },
                {
                    "date": 1756941199400,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,9 +16,9 @@\n from langchain_core.documents import Document\r\n from config import MAX_URLS, FAISS_PATH, RAW_DIR\r\n from web_utils import search_web\r\n from db_utils import add_chunk_if_new, store_content, get_stored_content\r\n-from vectorstore_manager import get_vectorstore\r\n+from vectorstore_utils import get_vectorstore\r\n from utils import lock\r\n from urllib.parse import quote\r\n import html\r\n import os\r\n"
                },
                {
                    "date": 1756943236895,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,9 +16,9 @@\n from langchain_core.documents import Document\r\n from config import MAX_URLS, FAISS_PATH, RAW_DIR\r\n from web_utils import search_web\r\n from db_utils import add_chunk_if_new, store_content, get_stored_content\r\n-from vectorstore_utils import get_vectorstore\r\n+from vectorstore_manager import get_vectorstore\r\n from utils import lock\r\n from urllib.parse import quote\r\n import html\r\n import os\r\n@@ -66,219 +66,5 @@\n             yield (\"status\", \"Step 3 completed: Description expanded.\")\r\n         except TimeoutException:\r\n             yield (\"status\", \"Step 3: Description may already be expanded or not found.\")\r\n \r\n-        # Click 'Show transcript'\r\n-        try:\r\n-            yield (\"status\", \"Step 4: Clicking 'Show transcript' button...\")\r\n-            transcript_button_xpath = \"//ytd-video-description-transcript-section-renderer//ytd-button-renderer/yt-button-shape/button\"\r\n-            transcript_button = wait.until(EC.element_to_be_clickable((By.XPATH, transcript_button_xpath)))\r\n-            try:\r\n-                transcript_button.click()\r\n-            except ElementClickInterceptedException:\r\n-                driver.execute_script(\"arguments[0].click();\", transcript_button)\r\n-            yield (\"status\", \"Step 4 completed: 'Show transcript' clicked.\")\r\n-        except TimeoutException:\r\n-            yield (\"status\", \"Step 4: No 'Show transcript' button found in description. Trying fallback method...\")\r\n-            # Fallback to more actions menu\r\n-            try:\r\n-                more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n-                try:\r\n-                    more_actions.click()\r\n-                except ElementClickInterceptedException:\r\n-                    driver.execute_script(\"arguments[0].click();\", more_actions)\r\n-                transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//tp-yt-paper-item[contains(text(), \"Show transcript\")]')))\r\n-                try:\r\n-                    transcript_item.click()\r\n-                except ElementClickInterceptedException:\r\n-                    driver.execute_script(\"arguments[0].click();\", transcript_item)\r\n-                yield (\"status\", \"Step 4 completed: 'Show transcript' clicked via fallback.\")\r\n-            except TimeoutException:\r\n-                yield (\"status\", f\"Error: Could not find 'Show transcript' for {url}\")\r\n-                return\r\n-\r\n-        # Wait for transcript panel\r\n-        try:\r\n-            yield (\"status\", \"Step 5: Waiting for transcript panel to load...\")\r\n-            transcript_title_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//yt-formatted-string[@id='title-text']\"\r\n-            wait.until(EC.visibility_of_element_located((By.XPATH, transcript_title_xpath)))\r\n-            yield (\"status\", \"Step 5 completed: Transcript panel loaded.\")\r\n-        except TimeoutException:\r\n-            yield (\"status\", f\"Error: Transcript panel did not load for {url}\")\r\n-            return\r\n-\r\n-        # Extract transcript\r\n-        try:\r\n-            yield (\"status\", \"Step 6: Extracting transcript text...\")\r\n-            transcript_elements_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//ytd-transcript-segment-renderer//yt-formatted-string\"\r\n-            transcript_elements = driver.find_elements(By.XPATH, transcript_elements_xpath)\r\n-            if not transcript_elements:\r\n-                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n-            if not transcript_elements:\r\n-                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".cue.style-scope.ytd-transcript-body-renderer\")\r\n-            if not transcript_elements:\r\n-                yield (\"status\", f\"Error: No transcript elements found for {url}\")\r\n-                return\r\n-            transcript_text = '\\n'.join([elem.text.strip() for elem in transcript_elements if elem.text.strip()])\r\n-            yield (\"status\", f\"Step 6 completed: Extracted {len(transcript_text.splitlines())} lines of transcript.\")\r\n-        except NoSuchElementException:\r\n-            yield (\"status\", f\"Error: Transcript elements not found for {url}\")\r\n-            return\r\n-\r\n-        # NLP Processing\r\n-        yield (\"status\", \"Step 7: Processing transcript with NLP...\")\r\n-        doc = nlp(transcript_text)\r\n-        processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.text.strip()]\r\n-        processed_text = ' '.join(processed_tokens)\r\n-        yield (\"status\", \"Step 7 completed: NLP processing done.\")\r\n-\r\n-        # Chunking\r\n-        yield (\"status\", \"Step 8: Chunking transcript...\")\r\n-        sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\r\n-        chunk_size = 200  # Words per chunk\r\n-        chunks = []\r\n-        current_chunk = []\r\n-        current_word_count = 0\r\n-        for sent in sentences:\r\n-            word_count = len(sent.split())\r\n-            if current_word_count + word_count > chunk_size:\r\n-                chunks.append(' '.join(current_chunk))\r\n-                current_chunk = [sent]\r\n-                current_word_count = word_count\r\n-            else:\r\n-                current_chunk.append(sent)\r\n-                current_word_count += word_count\r\n-        if current_chunk:\r\n-            chunks.append(' '.join(current_chunk))\r\n-        yield (\"status\", f\"Step 8 completed: Created {len(chunks)} chunks.\")\r\n-\r\n-        # Optional Ollama enhancement\r\n-        if use_ollama:\r\n-            yield (\"status\", \"Step 9: Enhancing chunks with Ollama...\")\r\n-            ollama_url = \"http://localhost:11434/api/generate\"\r\n-            enhanced_chunks = []\r\n-            for i, chunk in enumerate(chunks):\r\n-                yield (\"status\", f\"Enhancing chunk {i+1}/{len(chunks)}...\")\r\n-                payload = {\r\n-                    \"model\": \"qwen2.5:7b\",\r\n-                    \"prompt\": f\"Enhance and correct this transcript chunk for clarity and accuracy: {chunk}. Include only the corrected text, do not include a summarization of the changes.\",\r\n-                    \"stream\": False\r\n-                }\r\n-                try:\r\n-                    response = requests.post(ollama_url, json=payload, timeout=30)\r\n-                    if response.status_code == 200:\r\n-                        enhanced_text = response.json()['response']\r\n-                        enhanced_chunks.append(enhanced_text)\r\n-                        yield (\"status\", f\"Chunk {i+1} enhanced.\")\r\n-                    else:\r\n-                        yield (\"status\", f\"Error enhancing chunk {i+1} with Ollama: {response.text}\")\r\n-                        enhanced_chunks.append(chunk)  # Fallback\r\n-                except requests.exceptions.RequestException as e:\r\n-                    yield (\"status\", f\"Ollama request failed for chunk {i+1}: {e}. Falling back to original chunk.\")\r\n-                    enhanced_chunks.append(chunk)\r\n-            processed_text = '\\n\\n'.join(enhanced_chunks)\r\n-            yield (\"status\", \"Step 9 completed: Ollama enhancement done.\")\r\n-        else:\r\n-            processed_text = ' '.join(processed_tokens)\r\n-\r\n-        yield (\"transcript\", processed_text)\r\n-\r\n-    finally:\r\n-        yield (\"status\", \"Final Step: Closing browser...\")\r\n-        driver.quit()\r\n-        yield (\"status\", \"Browser closed.\")\r\n-\r\n-def run_youtube_collection(task_id, custom_name, query, url_list, use_ollama, tasks, completed_collections):\r\n-    print(f\"Starting YouTube collection task {task_id} for query: {query} or URLs: {url_list}\")\r\n-    conn = sqlite3.connect('crawled.db')\r\n-    c = conn.cursor()\r\n-    c.execute('''CREATE TABLE IF NOT EXISTS urls\r\n-                 (url TEXT PRIMARY KEY, timestamp DATETIME, cleaned_text TEXT)''')\r\n-    c.execute('''CREATE TABLE IF NOT EXISTS chunks\r\n-                 (hash TEXT PRIMARY KEY, content TEXT, source TEXT, tag TEXT)''')\r\n-    try:\r\n-        c.execute(\"ALTER TABLE chunks ADD COLUMN tag TEXT\")\r\n-        print(\"Added 'tag' column to chunks table.\")\r\n-    except sqlite3.OperationalError as e:\r\n-        if \"duplicate column name\" not in str(e):\r\n-            raise e\r\n-        print(\"'tag' column already exists in chunks table.\")\r\n-    conn.commit()\r\n-    try:\r\n-        response = \"\"\r\n-        history = [{\"role\": \"assistant\", \"content\": \"\"}]  # Dummy\r\n-        message = query or \"custom_urls\"\r\n-        tag = \"youtube_\" + message.replace(\" \", \"_\")\r\n-        name = custom_name or f\"YouTube - {message}\"\r\n-\r\n-        if query:\r\n-            youtube_urls = search_web(query, site=\"youtube.com\")\r\n-            all_urls = list(set(youtube_urls))[:3]  # Limit\r\n-        else:\r\n-            all_urls = [url.strip() for url in url_list if url.strip()]\r\n-\r\n-        transcripts = []\r\n-        new_docs_total = 0\r\n-        for i, url in enumerate(all_urls):\r\n-            print(f\"Processing URL {i+1}/{len(all_urls)}: {url}\")\r\n-            tasks[task_id]['message'] = f\"Processing URL {i+1}/{len(all_urls)}: {url}\"\r\n-            stored = get_stored_content(conn, url)\r\n-            if stored:\r\n-                response += f\"Using stored transcript for {url}\\n\"\r\n-                transcript = stored\r\n-            else:\r\n-                gen = fetch_youtube_transcript(url, use_ollama=use_ollama)\r\n-                transcript = None\r\n-                for item in gen:\r\n-                    item_type, value = item\r\n-                    if item_type == \"status\":\r\n-                        response += value + \"\\n\"\r\n-                    elif item_type == \"transcript\":\r\n-                        transcript = value\r\n-                if transcript:\r\n-                    store_content(conn, url, transcript)\r\n-                    prefix = \"ollama_\" if use_ollama else \"\"\r\n-                    safe_filename = prefix + quote(url.replace(\"https://\", \"\").replace(\"http://\", \"\").replace(\"/\", \"_\")[:100]) + \".txt\"\r\n-                    filepath = os.path.join(RAW_DIR, safe_filename)\r\n-                    with open(filepath, \"w\", encoding=\"utf-8\") as f:\r\n-                        f.write(transcript)\r\n-\r\n-                    # HTML view\r\n-                    html_safe_filename = safe_filename.replace(\".txt\", \".html\")\r\n-                    html_filepath = os.path.join(RAW_DIR, html_safe_filename)\r\n-                    escaped_text = html.escape(transcript)\r\n-                    html_content = f\"\"\"<html><head><style>body {{ font-family: sans-serif; padding: 20px; line-height: 1.6; max-width: 800px; margin: auto; }} pre {{ white-space: pre-wrap; word-wrap: break-word; }}</style></head><body><h1>Processed Transcript for {url}</h1><pre>{escaped_text}</pre></body></html>\"\"\"\r\n-                    with open(html_filepath, \"w\", encoding=\"utf-8\") as f:\r\n-                        f.write(html_content)\r\n-\r\n-            if transcript:\r\n-                text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\r\n-                chunks = text_splitter.split_text(transcript)\r\n-                new_docs = []\r\n-                for chunk in chunks:\r\n-                    if add_chunk_if_new(conn, chunk, url, tag=tag):\r\n-                        metadata = {\"source\": url, \"tag\": tag}\r\n-                        new_docs.append(Document(page_content=chunk, metadata=metadata))\r\n-                if new_docs:\r\n-                    with lock:\r\n-                        vs = get_vectorstore(tag)\r\n-                        vs.add_documents(new_docs)\r\n-                    new_docs_total += len(new_docs)\r\n-\r\n-        tasks[task_id]['status'] = 'completed'\r\n-        tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n-        tasks[task_id]['tag'] = tag\r\n-        completed_collections.append({'name': name, 'tag': tag})\r\n-        print(f\"YouTube collection task {task_id} completed.\")\r\n-    except Exception as e:\r\n-        tasks[task_id]['status'] = 'error'\r\n-        tasks[task_id]['message'] = str(e)\r\n-        print(f\"YouTube collection task {task_id} error: {e}\")\r\n-    finally:\r\n-        conn.close()\r\n-\r\n-def start_youtube_collection(custom_name, mode, query, url_list, use_ollama, tasks, completed_collections):\r\n-    task_id = len(tasks)\r\n-    task = {'id': task_id, 'type': 'youtube', 'custom_name': custom_name, 'mode': mode, 'query': query, 'url_list': url_list, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n-    tasks.append(task)\r\n-    threading.Thread(target=run_youtube_collection, args=(task_id, custom_name, query, url_list, use_ollama, tasks, completed_collections)).start()\r\n-    return \"YouTube collection started in background.\", tasks, completed_collections\n\\ No newline at end of file\n+        # Click 'Show transcript\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756943613282,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,5 +66,206 @@\n             yield (\"status\", \"Step 3 completed: Description expanded.\")\r\n         except TimeoutException:\r\n             yield (\"status\", \"Step 3: Description may already be expanded or not found.\")\r\n \r\n-        # Click 'Show transcript\n\\ No newline at end of file\n+        # Click 'Show transcript'\r\n+        try:\r\n+            yield (\"status\", \"Step 4: Clicking 'Show transcript' button...\")\r\n+            transcript_button_xpath = \"//ytd-video-description-transcript-section-renderer//ytd-button-renderer/yt-button-shape/button\"\r\n+            transcript_button = wait.until(EC.element_to_be_clickable((By.XPATH, transcript_button_xpath)))\r\n+            try:\r\n+                transcript_button.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", transcript_button)\r\n+            yield (\"status\", \"Step 4 completed: 'Show transcript' clicked.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 4: No 'Show transcript' button found in description. Trying fallback method...\")\r\n+            # Fallback to more actions menu\r\n+            try:\r\n+                more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n+                try:\r\n+                    more_actions.click()\r\n+                except ElementClickInterceptedException:\r\n+                    driver.execute_script(\"arguments[0].click();\", more_actions)\r\n+                transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//tp-yt-paper-item[contains(text(), \"Show transcript\")]')))\r\n+                try:\r\n+                    transcript_item.click()\r\n+                except ElementClickInterceptedException:\r\n+                    driver.execute_script(\"arguments[0].click();\", transcript_item)\r\n+                yield (\"status\", \"Step 4 completed: 'Show transcript' clicked via fallback.\")\r\n+            except TimeoutException:\r\n+                yield (\"status\", f\"Error: Could not find 'Show transcript' for {url}\")\r\n+                return\r\n+\r\n+        # Wait for transcript panel\r\n+        try:\r\n+            yield (\"status\", \"Step 5: Waiting for transcript panel to load...\")\r\n+            transcript_title_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//yt-formatted-string[@id='title-text']\"\r\n+            wait.until(EC.visibility_of_element_located((By.XPATH, transcript_title_xpath)))\r\n+            yield (\"status\", \"Step 5 completed: Transcript panel loaded.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", f\"Error: Transcript panel did not load for {url}\")\r\n+            return\r\n+\r\n+        # Extract transcript\r\n+        try:\r\n+            yield (\"status\", \"Step 6: Extracting transcript text...\")\r\n+            transcript_elements_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//ytd-transcript-segment-renderer//yt-formatted-string\"\r\n+            transcript_elements = driver.find_elements(By.XPATH, transcript_elements_xpath)\r\n+            if not transcript_elements:\r\n+                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n+            if not transcript_elements:\r\n+                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".cue.style-scope.ytd-transcript-body-renderer\")\r\n+            if not transcript_elements:\r\n+                yield (\"status\", f\"Error: No transcript elements found for {url}\")\r\n+                return\r\n+            transcript_text = '\\n'.join([elem.text.strip() for elem in transcript_elements if elem.text.strip()])\r\n+            yield (\"status\", f\"Step 6 completed: Extracted {len(transcript_text.splitlines())} lines of transcript.\")\r\n+        except NoSuchElementException:\r\n+            yield (\"status\", f\"Error: Transcript elements not found for {url}\")\r\n+            return\r\n+\r\n+        # NLP Processing\r\n+        yield (\"status\", \"Step 7: Processing transcript with NLP...\")\r\n+        doc = nlp(transcript_text)\r\n+        processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.text.strip()]\r\n+        processed_text = ' '.join(processed_tokens)\r\n+        yield (\"status\", \"Step 7 completed: NLP processing done.\")\r\n+\r\n+        # Chunking\r\n+        yield (\"status\", \"Step 8: Chunking transcript...\")\r\n+        sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\r\n+        chunk_size = 200  # Words per chunk\r\n+        chunks = []\r\n+        current_chunk = []\r\n+        current_word_count = 0\r\n+        for sent in sentences:\r\n+            word_count = len(sent.split())\r\n+            if current_word_count + word_count > chunk_size:\r\n+                chunks.append(' '.join(current_chunk))\r\n+                current_chunk = [sent]\r\n+                current_word_count = word_count\r\n+            else:\r\n+                current_chunk.append(sent)\r\n+                current_word_count += word_count\r\n+        if current_chunk:\r\n+            chunks.append(' '.join(current_chunk))\r\n+        yield (\"status\", f\"Step 8 completed: Created {len(chunks)} chunks.\")\r\n+\r\n+        # Optional Ollama enhancement\r\n+        if use_ollama:\r\n+            yield (\"status\", \"Step 9: Enhancing chunks with Ollama...\")\r\n+            ollama_url = \"http://localhost:11434/api/generate\"\r\n+            enhanced_chunks = []\r\n+            for i, chunk in enumerate(chunks):\r\n+                yield (\"status\", f\"Enhancing chunk {i+1}/{len(chunks)}...\")\r\n+                payload = {\r\n+                    \"model\": \"qwen2.5:7b\",\r\n+                    \"prompt\": f\"Enhance and correct this transcript chunk for clarity and accuracy: {chunk}. Include only the corrected text, do not include a summarization of the changes.\",\r\n+                    \"stream\": False\r\n+                }\r\n+                try:\r\n+                    response = requests.post(ollama_url, json=payload, timeout=30)\r\n+                    if response.status_code == 200:\r\n+                        enhanced_text = response.json()['response']\r\n+                        enhanced_chunks.append(enhanced_text)\r\n+                        yield (\"status\", f\"Chunk {i+1} enhanced.\")\r\n+                    else:\r\n+                        yield (\"status\", f\"Error enhancing chunk {i+1} with Ollama: {response.text}\")\r\n+                        enhanced_chunks.append(chunk)  # Fallback\r\n+                except requests.exceptions.RequestException as e:\r\n+                    yield (\"status\", f\"Ollama request failed for chunk {i+1}: {e}. Falling back to original chunk.\")\r\n+                    enhanced_chunks.append(chunk)\r\n+            processed_text = '\\n\\n'.join(enhanced_chunks)\r\n+            yield (\"status\", \"Step 9 completed: Ollama enhancement done.\")\r\n+        else:\r\n+            processed_text = ' '.join(processed_tokens)\r\n+\r\n+        yield (\"transcript\", processed_text)\r\n+\r\n+    finally:\r\n+        yield (\"status\", \"Final Step: Closing browser...\")\r\n+        driver.quit()\r\n+        yield (\"status\", \"Browser closed.\")\r\n+\r\n+def run_youtube_collection(task_id, custom_name, query, url_list, use_ollama, tasks, completed_collections):\r\n+    print(f\"Starting YouTube collection task {task_id} for query: {query} or URLs: {url_list}\")\r\n+    conn = sqlite3.connect('crawled.db')\r\n+    c = conn.cursor()\r\n+    c.execute('''CREATE TABLE IF NOT EXISTS urls\r\n+                 (url TEXT PRIMARY KEY, timestamp DATETIME, cleaned_text TEXT)''')\r\n+    c.execute('''CREATE TABLE IF NOT EXISTS chunks\r\n+                 (hash TEXT PRIMARY KEY, content TEXT, source TEXT, tag TEXT)''')\r\n+    try:\r\n+        c.execute(\"ALTER TABLE chunks ADD COLUMN tag TEXT\")\r\n+        print(\"Added 'tag' column to chunks table.\")\r\n+    except sqlite3.OperationalError as e:\r\n+        if \"duplicate column name\" not in str(e):\r\n+            raise e\r\n+        print(\"'tag' column already exists in chunks table.\")\r\n+    conn.commit()\r\n+    try:\r\n+        response = \"\"\r\n+        history = [{\"role\": \"assistant\", \"content\": \"\"}]  # Dummy\r\n+        message = query or \"custom_urls\"\r\n+        tag = \"youtube_\" + message.replace(\" \", \"_\")\r\n+        name = custom_name or f\"YouTube - {message}\"\r\n+\r\n+        if query:\r\n+            youtube_urls = search_web(query, site=\"youtube.com\")\r\n+            all_urls = list(set(youtube_urls))[:3]  # Limit\r\n+        else:\r\n+            all_urls = [url.strip() for url in url_list if url.strip()]\r\n+\r\n+        transcripts = []\r\n+        new_docs_total = 0\r\n+        for i, url in enumerate(all_urls):\r\n+            print(f\"Processing URL {i+1}/{len(all_urls)}: {url}\")\r\n+            tasks[task_id]['message'] = f\"Processing URL {i+1}/{len(all_urls)}: {url}\"\r\n+            stored = get_stored_content(conn, url)\r\n+            if stored:\r\n+                response += f\"Using stored transcript for {url}\\n\"\r\n+                transcript = stored\r\n+            else:\r\n+                gen = fetch_youtube_transcript(url, use_ollama=use_ollama)\r\n+                transcript = None\r\n+                for item in gen:\r\n+                    item_type, value = item\r\n+                    if item_type == \"status\":\r\n+                        response += value + \"\\n\"\r\n+                    elif item_type == \"transcript\":\r\n+                        transcript = value\r\n+                if transcript:\r\n+                    store_content(conn, url, transcript)\r\n+\r\n+            if transcript:\r\n+                text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\r\n+                chunks = text_splitter.split_text(transcript)\r\n+                new_docs = []\r\n+                for chunk in chunks:\r\n+                    if add_chunk_if_new(conn, chunk, url, tag=tag):\r\n+                        metadata = {\"source\": url, \"tag\": tag}\r\n+                        new_docs.append(Document(page_content=chunk, metadata=metadata))\r\n+                if new_docs:\r\n+                    with lock:\r\n+                        vs = get_vectorstore(tag)\r\n+                        vs.add_documents(new_docs)\r\n+                    new_docs_total += len(new_docs)\r\n+\r\n+        tasks[task_id]['status'] = 'completed'\r\n+        tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n+        tasks[task_id]['tag'] = tag\r\n+        completed_collections.append({'name': name, 'tag': tag})\r\n+        print(f\"YouTube collection task {task_id} completed.\")\r\n+    except Exception as e:\r\n+        tasks[task_id]['status'] = 'error'\r\n+        tasks[task_id]['message'] = str(e)\r\n+        print(f\"YouTube collection task {task_id} error: {e}\")\r\n+    finally:\r\n+        conn.close()\r\n+\r\n+def start_youtube_collection(custom_name, mode, query, url_list, use_ollama, tasks, completed_collections):\r\n+    task_id = len(tasks)\r\n+    task = {'id': task_id, 'type': 'youtube', 'custom_name': custom_name, 'mode': mode, 'query': query, 'url_list': url_list, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n+    tasks.append(task)\r\n+    threading.Thread(target=run_youtube_collection, args=(task_id, custom_name, query, url_list, use_ollama, tasks, completed_collections)).start()\r\n+    return \"YouTube collection started in background.\", tasks, completed_collections\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756945768740,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -15,9 +15,9 @@\n from langchain.text_splitter import RecursiveCharacterTextSplitter\r\n from langchain_core.documents import Document\r\n from config import MAX_URLS, FAISS_PATH, RAW_DIR\r\n from web_utils import search_web\r\n-from db_utils import add_chunk_if_new, store_content, get_stored_content\r\n+from db_utils import add_chunk_if_new, store_content, get_stored_content, add_collection\r\n from vectorstore_manager import get_vectorstore\r\n from utils import lock\r\n from urllib.parse import quote\r\n import html\r\n@@ -250,8 +250,9 @@\n                         vs = get_vectorstore(tag)\r\n                         vs.add_documents(new_docs)\r\n                     new_docs_total += len(new_docs)\r\n \r\n+        add_collection(conn, name, tag)\r\n         tasks[task_id]['status'] = 'completed'\r\n         tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n         tasks[task_id]['tag'] = tag\r\n         completed_collections.append({'name': name, 'tag': tag})\r\n"
                },
                {
                    "date": 1756946398578,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -179,8 +179,24 @@\n             yield (\"status\", \"Step 9 completed: Ollama enhancement done.\")\r\n         else:\r\n             processed_text = ' '.join(processed_tokens)\r\n \r\n+        # Save processed text to raw_contents\r\n+        prefix = \"ollama_\" if use_ollama else \"\"\r\n+        safe_filename = prefix + quote(url.replace(\"https://\", \"\").replace(\"http://\", \"\").replace(\"/\", \"_\")[:100]) + \".txt\"\r\n+        filepath = os.path.join(RAW_DIR, safe_filename)\r\n+        with open(filepath, \"w\", encoding=\"utf-8\") as f:\r\n+            f.write(processed_text)\r\n+        yield (\"status\", f\"Saved processed transcript to {filepath}\")\r\n+\r\n+        # HTML view\r\n+        html_safe_filename = safe_filename.replace(\".txt\", \".html\")\r\n+        html_filepath = os.path.join(RAW_DIR, html_safe_filename)\r\n+        escaped_text = html.escape(processed_text)\r\n+        html_content = f\"\"\"<html><head><style>body {{ font-family: sans-serif; padding: 20px; line-height: 1.6; max-width: 800px; margin: auto; }} pre {{ white-space: pre-wrap; word-wrap: break-word; }}</style></head><body><h1>Processed Transcript for {url}</h1><pre>{escaped_text}</pre></body></html>\"\"\"\r\n+        with open(html_filepath, \"w\", encoding=\"utf-8\") as f:\r\n+            f.write(html_content)\r\n+\r\n         yield (\"transcript\", processed_text)\r\n \r\n     finally:\r\n         yield (\"status\", \"Final Step: Closing browser...\")\r\n@@ -250,9 +266,10 @@\n                         vs = get_vectorstore(tag)\r\n                         vs.add_documents(new_docs)\r\n                     new_docs_total += len(new_docs)\r\n \r\n-        add_collection(conn, name, tag)\r\n+        add_collection(conn, name, tag)  # Save to DB\r\n+\r\n         tasks[task_id]['status'] = 'completed'\r\n         tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n         tasks[task_id]['tag'] = tag\r\n         completed_collections.append({'name': name, 'tag': tag})\r\n"
                },
                {
                    "date": 1756958227336,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -264,8 +264,9 @@\n                 if new_docs:\r\n                     with lock:\r\n                         vs = get_vectorstore(tag)\r\n                         vs.add_documents(new_docs)\r\n+                        print(f\"Added {len(new_docs)} documents to vectorstore for tag {tag}.\")\r\n                     new_docs_total += len(new_docs)\r\n \r\n         add_collection(conn, name, tag)  # Save to DB\r\n \r\n"
                },
                {
                    "date": 1756963510661,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,303 @@\n+# youtube_utils.py\r\n+import time\r\n+import spacy\r\n+import requests\r\n+import threading\r\n+import sqlite3\r\n+from selenium import webdriver\r\n+from selenium.webdriver.common.by import By\r\n+from selenium.webdriver.support.ui import WebDriverWait\r\n+from selenium.webdriver.support import expected_conditions as EC\r\n+from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\r\n+from webdriver_manager.chrome import ChromeDriverManager\r\n+from selenium.webdriver.chrome.service import Service as ChromeService\r\n+from selenium.webdriver.chrome.options import Options\r\n+from langchain.text_splitter import RecursiveCharacterTextSplitter\r\n+from langchain_core.documents import Document\r\n+from config import MAX_URLS, FAISS_PATH, RAW_DIR\r\n+from web_utils import search_web\r\n+from db_utils import add_chunk_if_new, store_content, get_stored_content, add_collection\r\n+from vectorstore_manager import get_vectorstore\r\n+from utils import lock\r\n+from urllib.parse import quote\r\n+import html\r\n+import os\r\n+import re  # Added for sanitization\r\n+\r\n+nlp = spacy.load(\"en_core_web_sm\")\r\n+\r\n+def sanitize_tag(name):\r\n+    # Replace invalid path characters with '_'\r\n+    invalid_chars = r'[<>:\"/\\\\|?*]'\r\n+    sanitized = re.sub(invalid_chars, '_', name)\r\n+    # Strip leading/trailing whitespace\r\n+    sanitized = sanitized.strip()\r\n+    # Collapse multiple '_' into single\r\n+    sanitized = re.sub(r'_+', '_', sanitized)\r\n+    return sanitized\r\n+\r\n+def fetch_youtube_transcript(url, use_ollama=False):\r\n+    yield (\"status\", f\"Fetching YouTube transcript for {url} with Ollama: {use_ollama}\")\r\n+    options = Options()\r\n+    options.add_argument('--disable-notifications')\r\n+    options.add_experimental_option('excludeSwitches', ['enable-logging'])\r\n+    options.add_argument('--log-level=3')\r\n+    service = ChromeService(ChromeDriverManager().install())\r\n+    driver = webdriver.Chrome(service=service, options=options)\r\n+    wait = WebDriverWait(driver, 10)  # Reduced timeout for faster failure\r\n+\r\n+    try:\r\n+        yield (\"status\", \"Step 1: Navigating to URL...\")\r\n+        driver.get(url)\r\n+        yield (\"status\", \"Step 1 completed: Page loaded.\")\r\n+\r\n+        # Handle consent popup with wait instead of sleep\r\n+        try:\r\n+            yield (\"status\", \"Step 2: Checking for consent popup...\")\r\n+            wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe[src*='consent.youtube.com']\")))\r\n+            accept_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Accept all') or contains(., 'I agree') or contains(@aria-label, 'Accept')]\")))\r\n+            try:\r\n+                accept_button.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", accept_button)\r\n+            driver.switch_to.default_content()\r\n+            yield (\"status\", \"Step 2 completed: Consent popup handled.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 2: No consent popup found or already handled.\")\r\n+\r\n+        # Expand description\r\n+        try:\r\n+            yield (\"status\", \"Step 3: Expanding description...\")\r\n+            expander_xpath = \"//ytd-text-inline-expander[@id='description-inline-expander']//tp-yt-paper-button[@id='expand']\"\r\n+            description_expander = wait.until(EC.element_to_be_clickable((By.XPATH, expander_xpath)))\r\n+            try:\r\n+                description_expander.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", description_expander)\r\n+            yield (\"status\", \"Step 3 completed: Description expanded.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 3: Description may already be expanded or not found.\")\r\n+\r\n+        # Click 'Show transcript'\r\n+        try:\r\n+            yield (\"status\", \"Step 4: Clicking 'Show transcript' button...\")\r\n+            transcript_button_xpath = \"//ytd-video-description-transcript-section-renderer//ytd-button-renderer/yt-button-shape/button\"\r\n+            transcript_button = wait.until(EC.element_to_be_clickable((By.XPATH, transcript_button_xpath)))\r\n+            try:\r\n+                transcript_button.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", transcript_button)\r\n+            yield (\"status\", \"Step 4 completed: 'Show transcript' clicked.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 4: No 'Show transcript' button found in description. Trying fallback method...\")\r\n+            # Fallback to more actions menu\r\n+            try:\r\n+                more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n+                try:\r\n+                    more_actions.click()\r\n+                except ElementClickInterceptedException:\r\n+                    driver.execute_script(\"arguments[0].click();\", more_actions)\r\n+                transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//tp-yt-paper-item[contains(text(), \"Show transcript\")]')))\r\n+                try:\r\n+                    transcript_item.click()\r\n+                except ElementClickInterceptedException:\r\n+                    driver.execute_script(\"arguments[0].click();\", transcript_item)\r\n+                yield (\"status\", \"Step 4 completed: 'Show transcript' clicked via fallback.\")\r\n+            except TimeoutException:\r\n+                yield (\"status\", f\"Error: Could not find 'Show transcript' for {url}\")\r\n+                return\r\n+\r\n+        # Wait for transcript panel\r\n+        try:\r\n+            yield (\"status\", \"Step 5: Waiting for transcript panel to load...\")\r\n+            transcript_title_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//yt-formatted-string[@id='title-text']\"\r\n+            wait.until(EC.visibility_of_element_located((By.XPATH, transcript_title_xpath)))\r\n+            yield (\"status\", \"Step 5 completed: Transcript panel loaded.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", f\"Error: Transcript panel did not load for {url}\")\r\n+            return\r\n+\r\n+        # Extract transcript\r\n+        try:\r\n+            yield (\"status\", \"Step 6: Extracting transcript text...\")\r\n+            transcript_elements_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//ytd-transcript-segment-renderer//yt-formatted-string\"\r\n+            transcript_elements = driver.find_elements(By.XPATH, transcript_elements_xpath)\r\n+            if not transcript_elements:\r\n+                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n+            if not transcript_elements:\r\n+                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".cue.style-scope.ytd-transcript-body-renderer\")\r\n+            if not transcript_elements:\r\n+                yield (\"status\", f\"Error: No transcript elements found for {url}\")\r\n+                return\r\n+            transcript_text = '\\n'.join([elem.text.strip() for elem in transcript_elements if elem.text.strip()])\r\n+            yield (\"status\", f\"Step 6 completed: Extracted {len(transcript_text.splitlines())} lines of transcript.\")\r\n+        except NoSuchElementException:\r\n+            yield (\"status\", f\"Error: Transcript elements not found for {url}\")\r\n+            return\r\n+\r\n+        # NLP Processing\r\n+        yield (\"status\", \"Step 7: Processing transcript with NLP...\")\r\n+        doc = nlp(transcript_text)\r\n+        processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.text.strip()]\r\n+        processed_text = ' '.join(processed_tokens)\r\n+        yield (\"status\", \"Step 7 completed: NLP processing done.\")\r\n+\r\n+        # Chunking\r\n+        yield (\"status\", \"Step 8: Chunking transcript...\")\r\n+        sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\r\n+        chunk_size = 200  # Words per chunk\r\n+        chunks = []\r\n+        current_chunk = []\r\n+        current_word_count = 0\r\n+        for sent in sentences:\r\n+            word_count = len(sent.split())\r\n+            if current_word_count + word_count > chunk_size:\r\n+                chunks.append(' '.join(current_chunk))\r\n+                current_chunk = [sent]\r\n+                current_word_count = word_count\r\n+            else:\r\n+                current_chunk.append(sent)\r\n+                current_word_count += word_count\r\n+        if current_chunk:\r\n+            chunks.append(' '.join(current_chunk))\r\n+        yield (\"status\", f\"Step 8 completed: Created {len(chunks)} chunks.\")\r\n+\r\n+        # Optional Ollama enhancement\r\n+        if use_ollama:\r\n+            yield (\"status\", \"Step 9: Enhancing chunks with Ollama...\")\r\n+            ollama_url = \"http://localhost:11434/api/generate\"\r\n+            enhanced_chunks = []\r\n+            for i, chunk in enumerate(chunks):\r\n+                yield (\"status\", f\"Enhancing chunk {i+1}/{len(chunks)}...\")\r\n+                payload = {\r\n+                    \"model\": \"qwen2.5:7b\",\r\n+                    \"prompt\": f\"Enhance and correct this transcript chunk for clarity and accuracy: {chunk}. Include only the corrected text, do not include a summarization of the changes.\",\r\n+                    \"stream\": False\r\n+                }\r\n+                try:\r\n+                    response = requests.post(ollama_url, json=payload, timeout=30)\r\n+                    if response.status_code == 200:\r\n+                        enhanced_text = response.json()['response']\r\n+                        enhanced_chunks.append(enhanced_text)\r\n+                        yield (\"status\", f\"Chunk {i+1} enhanced.\")\r\n+                    else:\r\n+                        yield (\"status\", f\"Error enhancing chunk {i+1} with Ollama: {response.text}\")\r\n+                        enhanced_chunks.append(chunk)  # Fallback\r\n+                except requests.exceptions.RequestException as e:\r\n+                    yield (\"status\", f\"Ollama request failed for chunk {i+1}: {e}. Falling back to original chunk.\")\r\n+                    enhanced_chunks.append(chunk)\r\n+            processed_text = '\\n\\n'.join(enhanced_chunks)\r\n+            yield (\"status\", \"Step 9 completed: Ollama enhancement done.\")\r\n+        else:\r\n+            processed_text = ' '.join(processed_tokens)\r\n+\r\n+        # Save processed text to raw_contents\r\n+        prefix = \"ollama_\" if use_ollama else \"\"\r\n+        safe_filename = prefix + quote(url.replace(\"https://\", \"\").replace(\"http://\", \"\").replace(\"/\", \"_\")[:100]) + \".txt\"\r\n+        filepath = os.path.join(RAW_DIR, safe_filename)\r\n+        with open(filepath, \"w\", encoding=\"utf-8\") as f:\r\n+            f.write(processed_text)\r\n+        yield (\"status\", f\"Saved processed transcript to {filepath}\")\r\n+\r\n+        # HTML view\r\n+        html_safe_filename = safe_filename.replace(\".txt\", \".html\")\r\n+        html_filepath = os.path.join(RAW_DIR, html_safe_filename)\r\n+        escaped_text = html.escape(processed_text)\r\n+        html_content = f\"\"\"<html><head><style>body {{ font-family: sans-serif; padding: 20px; line-height: 1.6; max-width: 800px; margin: auto; }} pre {{ white-space: pre-wrap; word-wrap: break-word; }}</style></head><body><h1>Processed Transcript for {url}</h1><pre>{escaped_text}</pre></body></html>\"\"\"\r\n+        with open(html_filepath, \"w\", encoding=\"utf-8\") as f:\r\n+            f.write(html_content)\r\n+\r\n+        yield (\"transcript\", processed_text)\r\n+\r\n+    finally:\r\n+        yield (\"status\", \"Final Step: Closing browser...\")\r\n+        driver.quit()\r\n+        yield (\"status\", \"Browser closed.\")\r\n+\r\n+def run_youtube_collection(task_id, custom_name, query, url_list, max_videos, use_ollama, tasks, completed_collections):\r\n+    print(f\"Starting YouTube collection task {task_id} for query: {query} or URLs: {url_list}\")\r\n+    conn = sqlite3.connect('crawled.db')\r\n+    c = conn.cursor()\r\n+    c.execute('''CREATE TABLE IF NOT EXISTS urls\r\n+                 (url TEXT PRIMARY KEY, timestamp DATETIME, cleaned_text TEXT)''')\r\n+    c.execute('''CREATE TABLE IF NOT EXISTS chunks\r\n+                 (hash TEXT PRIMARY KEY, content TEXT, source TEXT, tag TEXT)''')\r\n+    try:\r\n+        c.execute(\"ALTER TABLE chunks ADD COLUMN tag TEXT\")\r\n+        print(\"Added 'tag' column to chunks table.\")\r\n+    except sqlite3.OperationalError as e:\r\n+        if \"duplicate column name\" not in str(e):\r\n+            raise e\r\n+        print(\"'tag' column already exists in chunks table.\")\r\n+    conn.commit()\r\n+    try:\r\n+        response = \"\"\r\n+        history = [{\"role\": \"assistant\", \"content\": \"\"}]  # Dummy\r\n+        message = query or \"custom_urls\"\r\n+        raw_tag = \"youtube_\" + message.replace(\" \", \"_\")\r\n+        tag = sanitize_tag(raw_tag)  # Sanitize to prevent invalid path characters\r\n+        print(f\"Debug: Sanitized tag from '{raw_tag}' to '{tag}'\")\r\n+        name = custom_name or f\"YouTube - {message}\"\r\n+\r\n+        if query:\r\n+            youtube_urls = search_web(query, site=\"youtube.com\")\r\n+            all_urls = list(set(youtube_urls))[:max_videos]  # Limit to max_videos\r\n+        else:\r\n+            all_urls = [url.strip() for url in url_list if url.strip()][:max_videos]  # Limit to max_videos\r\n+\r\n+        transcripts = []\r\n+        new_docs_total = 0\r\n+        for i, url in enumerate(all_urls):\r\n+            print(f\"Processing URL {i+1}/{len(all_urls)}: {url}\")\r\n+            tasks[task_id]['message'] = f\"Processing URL {i+1}/{len(all_urls)}: {url}\"\r\n+            stored = get_stored_content(conn, url)\r\n+            if stored:\r\n+                response += f\"Using stored transcript for {url}\\n\"\r\n+                transcript = stored\r\n+            else:\r\n+                gen = fetch_youtube_transcript(url, use_ollama=use_ollama)\r\n+                transcript = None\r\n+                for item in gen:\r\n+                    item_type, value = item\r\n+                    if item_type == \"status\":\r\n+                        response += value + \"\\n\"\r\n+                    elif item_type == \"transcript\":\r\n+                        transcript = value\r\n+                if transcript:\r\n+                    store_content(conn, url, transcript)\r\n+\r\n+            if transcript:\r\n+                text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\r\n+                chunks = text_splitter.split_text(transcript)\r\n+                new_docs = []\r\n+                for chunk in chunks:\r\n+                    if add_chunk_if_new(conn, chunk, url, tag=tag):\r\n+                        metadata = {\"source\": url, \"tag\": tag}\r\n+                        new_docs.append(Document(page_content=chunk, metadata=metadata))\r\n+                if new_docs:\r\n+                    with lock:\r\n+                        vs = get_vectorstore(tag)\r\n+                        vs.add_documents(new_docs)\r\n+                        print(f\"Added {len(new_docs)} documents to vectorstore for tag {tag}.\")\r\n+                    new_docs_total += len(new_docs)\r\n+\r\n+        add_collection(conn, name, tag)  # Save to DB\r\n+\r\n+        tasks[task_id]['status'] = 'completed'\r\n+        tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n+        tasks[task_id]['tag'] = tag\r\n+        completed_collections.append({'name': name, 'tag': tag})\r\n+        print(f\"YouTube collection task {task_id} completed.\")\r\n+    except Exception as e:\r\n+        tasks[task_id]['status'] = 'error'\r\n+        tasks[task_id]['message'] = str(e)\r\n+        print(f\"YouTube collection task {task_id} error: {e}\")\r\n+    finally:\r\n+        conn.close()\r\n+\r\n+def start_youtube_collection(custom_name, mode, query, url_list, max_videos=10, use_ollama=False, tasks=None, completed_collections=None):\r\n+    task_id = len(tasks)\r\n+    task = {'id': task_id, 'type': 'youtube', 'custom_name': custom_name, 'mode': mode, 'query': query, 'url_list': url_list, 'max_videos': max_videos, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n+    tasks.append(task)\r\n+    threading.Thread(target=run_youtube_collection, args=(task_id, custom_name, query, url_list, max_videos, use_ollama, tasks, completed_collections)).start()\r\n+    return \"YouTube collection started in background.\", tasks, completed_collections\n\\ No newline at end of file\n"
                },
                {
                    "date": 1756975255590,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,303 @@\n+# youtube_utils.py\r\n+import time\r\n+import spacy\r\n+import requests\r\n+import threading\r\n+import sqlite3\r\n+from selenium import webdriver\r\n+from selenium.webdriver.common.by import By\r\n+from selenium.webdriver.support.ui import WebDriverWait\r\n+from selenium.webdriver.support import expected_conditions as EC\r\n+from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\r\n+from webdriver_manager.chrome import ChromeDriverManager\r\n+from selenium.webdriver.chrome.service import Service as ChromeService\r\n+from selenium.webdriver.chrome.options import Options\r\n+from langchain.text_splitter import RecursiveCharacterTextSplitter\r\n+from langchain_core.documents import Document\r\n+from config import MAX_URLS, FAISS_PATH, RAW_DIR\r\n+from web_utils import search_web\r\n+from db_utils import add_chunk_if_new, store_content, get_stored_content, add_collection\r\n+from vectorstore_manager import get_vectorstore\r\n+from utils import lock\r\n+from urllib.parse import quote\r\n+import html\r\n+import os\r\n+import re  # Added for sanitization\r\n+\r\n+nlp = spacy.load(\"en_core_web_sm\")\r\n+\r\n+def sanitize_tag(name):\r\n+    # Replace invalid path characters with '_'\r\n+    invalid_chars = r'[<>:\"/\\\\|?*]'\r\n+    sanitized = re.sub(invalid_chars, '_', name)\r\n+    # Strip leading/trailing whitespace\r\n+    sanitized = sanitized.strip()\r\n+    # Collapse multiple '_' into single\r\n+    sanitized = re.sub(r'_+', '_', sanitized)\r\n+    return sanitized\r\n+\r\n+def fetch_youtube_transcript(url, use_ollama=False):\r\n+    yield (\"status\", f\"Fetching YouTube transcript for {url} with Ollama: {use_ollama}\")\r\n+    options = Options()\r\n+    options.add_argument('--disable-notifications')\r\n+    options.add_experimental_option('excludeSwitches', ['enable-logging'])\r\n+    options.add_argument('--log-level=3')\r\n+    service = ChromeService(ChromeDriverManager().install())\r\n+    driver = webdriver.Chrome(service=service, options=options)\r\n+    wait = WebDriverWait(driver, 10)  # Reduced timeout for faster failure\r\n+\r\n+    try:\r\n+        yield (\"status\", \"Step 1/8: Navigating to URL...\")\r\n+        driver.get(url)\r\n+        yield (\"status\", \"Step 1/8 completed: Page loaded.\")\r\n+\r\n+        # Handle consent popup with wait instead of sleep\r\n+        try:\r\n+            yield (\"status\", \"Step 2/8: Checking for consent popup...\")\r\n+            wait.until(EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, \"iframe[src*='consent.youtube.com']\")))\r\n+            accept_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Accept all') or contains(., 'I agree') or contains(@aria-label, 'Accept')]\")))\r\n+            try:\r\n+                accept_button.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", accept_button)\r\n+            driver.switch_to.default_content()\r\n+            yield (\"status\", \"Step 2/8 completed: Consent popup handled.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 2/8: No consent popup found or already handled.\")\r\n+\r\n+        # Expand description\r\n+        try:\r\n+            yield (\"status\", \"Step 3/8: Expanding description...\")\r\n+            expander_xpath = \"//ytd-text-inline-expander[@id='description-inline-expander']//tp-yt-paper-button[@id='expand']\"\r\n+            description_expander = wait.until(EC.element_to_be_clickable((By.XPATH, expander_xpath)))\r\n+            try:\r\n+                description_expander.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", description_expander)\r\n+            yield (\"status\", \"Step 3/8 completed: Description expanded.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 3/8: Description may already be expanded or not found.\")\r\n+\r\n+        # Click 'Show transcript'\r\n+        try:\r\n+            yield (\"status\", \"Step 4/8: Clicking 'Show transcript' button...\")\r\n+            transcript_button_xpath = \"//ytd-video-description-transcript-section-renderer//ytd-button-renderer/yt-button-shape/button\"\r\n+            transcript_button = wait.until(EC.element_to_be_clickable((By.XPATH, transcript_button_xpath)))\r\n+            try:\r\n+                transcript_button.click()\r\n+            except ElementClickInterceptedException:\r\n+                driver.execute_script(\"arguments[0].click();\", transcript_button)\r\n+            yield (\"status\", \"Step 4/8 completed: 'Show transcript' clicked.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", \"Step 4/8: No 'Show transcript' button found in description. Trying fallback method...\")\r\n+            # Fallback to more actions menu\r\n+            try:\r\n+                more_actions = wait.until(EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"More actions\"]')))\r\n+                try:\r\n+                    more_actions.click()\r\n+                except ElementClickInterceptedException:\r\n+                    driver.execute_script(\"arguments[0].click();\", more_actions)\r\n+                transcript_item = wait.until(EC.element_to_be_clickable((By.XPATH, '//tp-yt-paper-item[contains(text(), \"Show transcript\")]')))\r\n+                try:\r\n+                    transcript_item.click()\r\n+                except ElementClickInterceptedException:\r\n+                    driver.execute_script(\"arguments[0].click();\", transcript_item)\r\n+                yield (\"status\", \"Step 4/8 completed: 'Show transcript' clicked via fallback.\")\r\n+            except TimeoutException:\r\n+                yield (\"status\", f\"Error: Could not find 'Show transcript' for {url}\")\r\n+                return\r\n+\r\n+        # Wait for transcript panel\r\n+        try:\r\n+            yield (\"status\", \"Step 5/8: Waiting for transcript panel to load...\")\r\n+            transcript_title_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//yt-formatted-string[@id='title-text']\"\r\n+            wait.until(EC.visibility_of_element_located((By.XPATH, transcript_title_xpath)))\r\n+            yield (\"status\", \"Step 5/8 completed: Transcript panel loaded.\")\r\n+        except TimeoutException:\r\n+            yield (\"status\", f\"Error: Transcript panel did not load for {url}\")\r\n+            return\r\n+\r\n+        # Extract transcript\r\n+        try:\r\n+            yield (\"status\", \"Step 6/8: Extracting transcript text...\")\r\n+            transcript_elements_xpath = \"//ytd-engagement-panel-section-list-renderer[@target-id='engagement-panel-searchable-transcript']//ytd-transcript-segment-renderer//yt-formatted-string\"\r\n+            transcript_elements = driver.find_elements(By.XPATH, transcript_elements_xpath)\r\n+            if not transcript_elements:\r\n+                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".ytd-transcript-segment-renderer .ytd-transcript-segment-text\")\r\n+            if not transcript_elements:\r\n+                transcript_elements = driver.find_elements(By.CSS_SELECTOR, \".cue.style-scope.ytd-transcript-body-renderer\")\r\n+            if not transcript_elements:\r\n+                yield (\"status\", f\"Error: No transcript elements found for {url}\")\r\n+                return\r\n+            transcript_text = '\\n'.join([elem.text.strip() for elem in transcript_elements if elem.text.strip()])\r\n+            yield (\"status\", f\"Step 6/8 completed: Extracted {len(transcript_text.splitlines())} lines of transcript.\")\r\n+        except NoSuchElementException:\r\n+            yield (\"status\", f\"Error: Transcript elements not found for {url}\")\r\n+            return\r\n+\r\n+        # NLP Processing\r\n+        yield (\"status\", \"Step 7/8: Processing transcript with NLP...\")\r\n+        doc = nlp(transcript_text)\r\n+        processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.text.strip()]\r\n+        processed_text = ' '.join(processed_tokens)\r\n+        yield (\"status\", \"Step 7/8 completed: NLP processing done.\")\r\n+\r\n+        # Chunking\r\n+        yield (\"status\", \"Step 8/8: Chunking transcript...\")\r\n+        sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\r\n+        chunk_size = 200  # Words per chunk\r\n+        chunks = []\r\n+        current_chunk = []\r\n+        current_word_count = 0\r\n+        for sent in sentences:\r\n+            word_count = len(sent.split())\r\n+            if current_word_count + word_count > chunk_size:\r\n+                chunks.append(' '.join(current_chunk))\r\n+                current_chunk = [sent]\r\n+                current_word_count = word_count\r\n+            else:\r\n+                current_chunk.append(sent)\r\n+                current_word_count += word_count\r\n+        if current_chunk:\r\n+            chunks.append(' '.join(current_chunk))\r\n+        yield (\"status\", f\"Step 8 completed: Created {len(chunks)} chunks.\")\r\n+\r\n+        # Optional Ollama enhancement\r\n+        if use_ollama:\r\n+            yield (\"status\", \"Enhancing chunks with Ollama...\")\r\n+            ollama_url = \"http://localhost:11434/api/generate\"\r\n+            enhanced_chunks = []\r\n+            for i, chunk in enumerate(chunks):\r\n+                yield (\"status\", f\"Enhancing chunk {i+1}/{len(chunks)}...\")\r\n+                payload = {\r\n+                    \"model\": \"qwen2.5:7b\",\r\n+                    \"prompt\": f\"Enhance and correct this transcript chunk for clarity and accuracy: {chunk}. Include only the corrected text, do not include a summarization of the changes.\",\r\n+                    \"stream\": False\r\n+                }\r\n+                try:\r\n+                    response = requests.post(ollama_url, json=payload, timeout=30)\r\n+                    if response.status_code == 200:\r\n+                        enhanced_text = response.json()['response']\r\n+                        enhanced_chunks.append(enhanced_text)\r\n+                        yield (\"status\", f\"Chunk {i+1} enhanced.\")\r\n+                    else:\r\n+                        yield (\"status\", f\"Error enhancing chunk {i+1} with Ollama: {response.text}\")\r\n+                        enhanced_chunks.append(chunk)  # Fallback\r\n+                except requests.exceptions.RequestException as e:\r\n+                    yield (\"status\", f\"Ollama request failed for chunk {i+1}: {e}. Falling back to original chunk.\")\r\n+                    enhanced_chunks.append(chunk)\r\n+            processed_text = '\\n\\n'.join(enhanced_chunks)\r\n+            yield (\"status\", \"Step 9 completed: Ollama enhancement done.\")\r\n+        else:\r\n+            processed_text = ' '.join(processed_tokens)\r\n+\r\n+        # Save processed text to raw_contents\r\n+        prefix = \"ollama_\" if use_ollama else \"\"\r\n+        safe_filename = prefix + quote(url.replace(\"https://\", \"\").replace(\"http://\", \"\").replace(\"/\", \"_\")[:100]) + \".txt\"\r\n+        filepath = os.path.join(RAW_DIR, safe_filename)\r\n+        with open(filepath, \"w\", encoding=\"utf-8\") as f:\r\n+            f.write(processed_text)\r\n+        yield (\"status\", f\"Saved processed transcript to {filepath}\")\r\n+\r\n+        # HTML view\r\n+        html_safe_filename = safe_filename.replace(\".txt\", \".html\")\r\n+        html_filepath = os.path.join(RAW_DIR, html_safe_filename)\r\n+        escaped_text = html.escape(processed_text)\r\n+        html_content = f\"\"\"<html><head><style>body {{ font-family: sans-serif; padding: 20px; line-height: 1.6; max-width: 800px; margin: auto; }} pre {{ white-space: pre-wrap; word-wrap: break-word; }}</style></head><body><h1>Processed Transcript for {url}</h1><pre>{escaped_text}</pre></body></html>\"\"\"\r\n+        with open(html_filepath, \"w\", encoding=\"utf-8\") as f:\r\n+            f.write(html_content)\r\n+\r\n+        yield (\"transcript\", processed_text)\r\n+\r\n+    finally:\r\n+        yield (\"status\", \"Final Step: Closing browser...\")\r\n+        driver.quit()\r\n+        yield (\"status\", \"Browser closed.\")\r\n+\r\n+def run_youtube_collection(task_id, custom_name, query, url_list, max_videos, use_ollama, tasks, completed_collections):\r\n+    print(f\"Starting YouTube collection task {task_id} for query: {query} or URLs: {url_list}\")\r\n+    conn = sqlite3.connect('crawled.db')\r\n+    c = conn.cursor()\r\n+    c.execute('''CREATE TABLE IF NOT EXISTS urls\r\n+                 (url TEXT PRIMARY KEY, timestamp DATETIME, cleaned_text TEXT)''')\r\n+    c.execute('''CREATE TABLE IF NOT EXISTS chunks\r\n+                 (hash TEXT PRIMARY KEY, content TEXT, source TEXT, tag TEXT)''')\r\n+    try:\r\n+        c.execute(\"ALTER TABLE chunks ADD COLUMN tag TEXT\")\r\n+        print(\"Added 'tag' column to chunks table.\")\r\n+    except sqlite3.OperationalError as e:\r\n+        if \"duplicate column name\" not in str(e):\r\n+            raise e\r\n+        print(\"'tag' column already exists in chunks table.\")\r\n+    conn.commit()\r\n+    try:\r\n+        response = \"\"\r\n+        history = [{\"role\": \"assistant\", \"content\": \"\"}]  # Dummy\r\n+        message = query or \"custom_urls\"\r\n+        raw_tag = \"youtube_\" + message.replace(\" \", \"_\")\r\n+        tag = sanitize_tag(raw_tag)  # Sanitize to prevent invalid path characters\r\n+        print(f\"Debug: Sanitized tag from '{raw_tag}' to '{tag}'\")\r\n+        name = custom_name or f\"YouTube - {message}\"\r\n+\r\n+        if query:\r\n+            youtube_urls = search_web(query, site=\"youtube.com\")\r\n+            all_urls = list(set(youtube_urls))[:max_videos]  # Limit to max_videos\r\n+        else:\r\n+            all_urls = [url.strip() for url in url_list if url.strip()][:max_videos]  # Limit to max_videos\r\n+\r\n+        transcripts = []\r\n+        new_docs_total = 0\r\n+        for i, url in enumerate(all_urls):\r\n+            print(f\"Processing URL {i+1}/{len(all_urls)}: {url}\")\r\n+            tasks[task_id]['message'] = f\"Processing URL {i+1}/{len(all_urls)}: {url}\"\r\n+            stored = get_stored_content(conn, url)\r\n+            if stored:\r\n+                response += f\"Using stored transcript for {url}\\n\"\r\n+                transcript = stored\r\n+            else:\r\n+                gen = fetch_youtube_transcript(url, use_ollama=use_ollama)\r\n+                transcript = None\r\n+                for item in gen:\r\n+                    item_type, value = item\r\n+                    if item_type == \"status\":\r\n+                        response += value + \"\\n\"\r\n+                    elif item_type == \"transcript\":\r\n+                        transcript = value\r\n+                if transcript:\r\n+                    store_content(conn, url, transcript)\r\n+\r\n+            if transcript:\r\n+                text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\r\n+                chunks = text_splitter.split_text(transcript)\r\n+                new_docs = []\r\n+                for chunk in chunks:\r\n+                    if add_chunk_if_new(conn, chunk, url, tag=tag):\r\n+                        metadata = {\"source\": url, \"tag\": tag}\r\n+                        new_docs.append(Document(page_content=chunk, metadata=metadata))\r\n+                if new_docs:\r\n+                    with lock:\r\n+                        vs = get_vectorstore(tag)\r\n+                        vs.add_documents(new_docs)\r\n+                        print(f\"Added {len(new_docs)} documents to vectorstore for tag {tag}.\")\r\n+                    new_docs_total += len(new_docs)\r\n+\r\n+        add_collection(conn, name, tag)  # Save to DB\r\n+\r\n+        tasks[task_id]['status'] = 'completed'\r\n+        tasks[task_id]['message'] = f\"Collection completed. {new_docs_total} new chunks added. Please refresh sources in the Chat tab.\"\r\n+        tasks[task_id]['tag'] = tag\r\n+        completed_collections.append({'name': name, 'tag': tag})\r\n+        print(f\"YouTube collection task {task_id} completed.\")\r\n+    except Exception as e:\r\n+        tasks[task_id]['status'] = 'error'\r\n+        tasks[task_id]['message'] = str(e)\r\n+        print(f\"YouTube collection task {task_id} error: {e}\")\r\n+    finally:\r\n+        conn.close()\r\n+\r\n+def start_youtube_collection(custom_name, mode, query, url_list, max_videos=10, use_ollama=False, tasks=None, completed_collections=None):\r\n+    task_id = len(tasks)\r\n+    task = {'id': task_id, 'type': 'youtube', 'custom_name': custom_name, 'mode': mode, 'query': query, 'url_list': url_list, 'max_videos': max_videos, 'use_ollama': use_ollama, 'status': 'running', 'message': ''}\r\n+    tasks.append(task)\r\n+    threading.Thread(target=run_youtube_collection, args=(task_id, custom_name, query, url_list, max_videos, use_ollama, tasks, completed_collections)).start()\r\n+    return \"YouTube collection started in background.\", tasks, completed_collections\n\\ No newline at end of file\n"
                }
            ],
            "date": 1756920084523,
            "name": "Commit-0",
            "content": "import yt_dlp\r\nimport tempfile\r\nimport os\r\nimport re\r\n\r\nurl = 'https://www.youtube.com/watch?v=VxOQjqNgQ5E'\r\n\r\nwith tempfile.TemporaryDirectory() as tmpdir:\r\n    ydl_opts = {\r\n        'writesubtitles': True,\r\n        'writeautomaticsubs': True,\r\n        'subtitleslangs': ['en'],\r\n        'subtitlesformat': 'vtt',\r\n        'skip_download': True,\r\n        'quiet': True,\r\n        'outtmpl': os.path.join(tmpdir, 'transcript.%(id)s.%(ext)s'),\r\n        'impersonate': 'chrome'\r\n    }\r\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\r\n        info = ydl.extract_info(url, download=False)\r\n        video_id = info['id']\r\n        ydl.download([url])\r\n        vtt_file = os.path.join(tmpdir, f'transcript.{video_id}.en.vtt')\r\n        if os.path.exists(vtt_file):\r\n            with open(vtt_file, \"r\", encoding=\"utf-8\") as f:\r\n                vtt_content = f.read()\r\n            transcript_text = re.sub(r'^\\d+\\n\\d{2}:\\d{2}:\\d{2}\\.\\d{3} --> \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\\n', '', vtt_content)\r\n            transcript_text = re.sub(r'\\n\\n', '\\n', transcript_text).strip()\r\n            print(transcript_text)\r\n        else:\r\n            print(\"No transcript available.\")"
        }
    ]
}